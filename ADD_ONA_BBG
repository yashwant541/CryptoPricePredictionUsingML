import pdfplumber
import pandas as pd
import re
from datetime import datetime
import dataiku
import tempfile
import os

def extract_tables_from_pdf(pdf_path):
    """Extract all tables from PDF using pdfplumber"""
    tables = []
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages):
            try:
                page_tables = page.extract_tables()
                for table_num, table in enumerate(page_tables):
                    if table and any(any(cell for cell in row if cell) for row in table):
                        tables.append({
                            "page": page_num + 1,
                            "table_num": table_num + 1,
                            "data": table
                        })
            except Exception as e:
                print(f"Error processing page {page_num + 1}: {str(e)}")
                continue
    return tables

def parse_date(date_str):
    """Parse date string in various formats to datetime object"""
    if not date_str:
        return None
    
    date_str = str(date_str).strip()
    date_formats = [
        '%d/%m/%Y', '%d-%m-%Y', '%d.%m.%Y',
        '%d/%m/%y', '%d-%m-%y', '%d.%m.%y',
        '%d.%m.%Y', '%d.%m.%y'  # Added formats seen in the PDF
    ]
    
    for fmt in date_formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    return None

def find_latest_date_value(table_data, keywords):
    """Find the latest date and corresponding values for given keywords"""
    results = []
    
    # First find all date columns
    date_columns = []
    date_patterns = [
        r'\d{2}/\d{2}/\d{4}', r'\d{2}-\d{2}-\d{4}', r'\d{2}\.\d{2}\.\d{4}',
        r'\d{2}/\d{2}/\d{2}', r'\d{2}-\d{2}-\d{2}', r'\d{2}\.\d{2}\.\d{2}'
    ]
    
    # Check header row for dates
    if table_data and len(table_data) > 0:
        header_row = table_data[0]
        for col_idx, header in enumerate(header_row):
            if header:
                for pattern in date_patterns:
                    if re.search(pattern, str(header)):
                        date_columns.append(col_idx)
                        break
    
    if not date_columns:
        return results
    
    # Find the latest date column
    latest_date = None
    latest_col = None
    
    for col in date_columns:
        for row in table_data[1:]:  # Skip header
            if col < len(row) and row[col]:
                date_obj = parse_date(row[col])
                if date_obj:
                    if latest_date is None or date_obj > latest_date:
                        latest_date = date_obj
                        latest_col = col
    
    if latest_col is None:
        return results
    
    # Search for keywords in the table
    for row in table_data:
        row_text = ' '.join([str(cell) for cell in row if cell])
        for keyword in keywords:
            if keyword.lower() in row_text.lower():
                # Find the value in the latest date column
                if latest_col < len(row):
                    value = row[latest_col]
                    if value:
                        results.append({
                            "keyword": keyword,
                            "date": latest_date.strftime('%d/%m/%Y') if latest_date else None,
                            "value": value,
                            "page": table_info['page'],
                            "table": table_info['table_num'],
                            "row": table_data.index(row) + 1
                        })
    
    return results

def main():
    # Configuration
    financial_keywords = [
        "Common Equity Tier 1 ratio",
        "Total capital ratio",
        "Leverage ratio",
        "Liquidity coverage ratio"
    ]
    
    # Get input PDF from Dataiku managed folder
    folder_name = "YOUR_FOLDER_NAME"  # Replace with your folder name
    folder = dataiku.Folder(folder_name)
    
    # Find PDF file in the folder
    pdf_files = [f for f in folder.list_paths() if f.lower().endswith('.pdf')]
    
    if not pdf_files:
        raise ValueError(f"No PDF file found in the managed folder '{folder_name}'")
    if len(pdf_files) > 1:
        print(f"Warning: Multiple PDFs found. Using the first one: {pdf_files[0]}")
    
    # Create a temporary file to store the PDF
    with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp_file:
        pdf_path = tmp_file.name
    
    # Download the PDF to the temporary file
    with folder.get_download_stream(pdf_files[0]) as stream:
        with open(pdf_path, 'wb') as f:
            f.write(stream.read())
    
    try:
        # Process PDF
        print("Extracting tables from PDF...")
        tables = extract_tables_from_pdf(pdf_path)
        print(f"Found {len(tables)} tables in the PDF")
        
        print("Searching for financial keywords...")
        results = []
        
        for table_info in tables:
            table_results = find_latest_date_value(table_info['data'], financial_keywords)
            results.extend(table_results)
        
        print(f"Found {len(results)} matches")
        
        # Create DataFrame
        df = pd.DataFrame(results)
        
        if not df.empty:
            # Clean up the value column - remove percentage signs and convert to numeric
            df['clean_value'] = df['value'].str.replace('%', '').str.replace(',', '')
            df['clean_value'] = pd.to_numeric(df['clean_value'], errors='coerce')
            
            # For ratio values, divide by 100 if they're likely percentages (values between 0-100)
            df.loc[df['clean_value'].between(0, 100), 'clean_value'] = df['clean_value'] / 100
            
            # Keep only one record per keyword (the first occurrence)
            df = df.drop_duplicates('keyword', keep='first')
            
            # Sort by keyword for consistent output
            df = df.sort_values('keyword')
        
        # Add metadata
        df['source_file'] = pdf_files[0]
        df['extraction_date'] = datetime.now().strftime('%Y-%m-%d')
        
        # Select final columns
        final_columns = ['keyword', 'value', 'clean_value', 'date', 'page', 'table', 'row', 
                        'source_file', 'extraction_date']
        df = df[[col for col in final_columns if col in df.columns]]
        
        # Write to Dataiku dataset
        output_dataset = dataiku.Dataset("SCB_PDF_Pillar3")
        output_dataset.write_with_schema(df)
        print("Results written to SCB_PDF_Pillar3 dataset")
        print(df)
    
    finally:
        # Clean up the temporary file
        if os.path.exists(pdf_path):
            os.remove(pdf_path)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"Error in script execution: {str(e)}")
        raise
