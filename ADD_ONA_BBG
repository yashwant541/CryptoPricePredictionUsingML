# -*- coding: utf-8 -*-
import dataiku
import pandas as pd
import numpy as np
from dataiku import pandasutils as pdu
import pdfplumber
import re
import io
from datetime import datetime

# ---- CONFIG ----
TARGET_KEYWORDS = [
    "Common Equity Tier 1 ratio",
    "Total capital ratio",
    "Leverage ratio",
    "Liquidity coverage ratio"
]

# Match dates like 31.03.25 or 31.03.2025
DATE_PATTERN = re.compile(r"\b\d{2}[\./-]\d{2}[\./-]\d{2,4}\b")

# ---- ACCESS PDF FROM MANAGED FOLDER (e.g., HDFS/S3) ----
folder = dataiku.Folder("MPJ3zAOO")  # Replace with your actual folder ID
folder_info = folder.get_info()
file_list = folder.list_paths_in_partition()

# Filter for PDF files
pdf_files = [f for f in file_list if f.lower().endswith(".pdf")]
if len(pdf_files) != 1:
    raise Exception(f"Expected exactly one PDF file in the folder, found {len(pdf_files)}.")

pdf_filename = pdf_files[0]  # e.g., '/scb.pdf'

# Download the PDF file as a byte stream
pdf_stream = folder.get_download_stream(pdf_filename)
pdf_bytes = io.BytesIO(pdf_stream.read())

# ---- DATE PARSER ----
def try_parse_date(text):
    try:
        text = text.replace("-", ".").replace("/", ".").strip()
        return datetime.strptime(text, "%d.%m.%Y")
    except:
        try:
            return datetime.strptime(text, "%d.%m.%y")
        except:
            return None

# ---- MAIN PROCESS ----
results = []

with pdfplumber.open(pdf_bytes) as pdf:
    for page_num, page in enumerate(pdf.pages):
        tables = page.extract_tables()
        for table_idx, table in enumerate(tables):
            try:
                df = pd.DataFrame(table)
                df.dropna(how="all", inplace=True)

                if df.shape[1] < 2:
                    continue

                header_row = df.iloc[0].fillna("")
                df.columns = header_row
                df = df[1:]

                # Identify date columns
                date_cols = []
                for col in df.columns:
                    col_clean = str(col).strip()
                    if DATE_PATTERN.match(col_clean):
                        parsed = try_parse_date(col_clean)
                        if parsed:
                            date_cols.append((col_clean, parsed))

                if not date_cols:
                    continue

                date_cols.sort(key=lambda x: x[1], reverse=True)
                latest_col = date_cols[0][0]

                # For each keyword, find first non-empty value
                for keyword in TARGET_KEYWORDS:
                    matched_rows = df[df.iloc[:, 0].str.contains(keyword, case=False, na=False)]
                    for _, row in matched_rows.iterrows():
                        value = row.get(latest_col, "").strip()
                        if value:
                            results.append({
                                "Page": page_num + 1,
                                "Table": table_idx + 1,
                                "Keyword": keyword,
                                "Latest_Date": latest_col,
                                "Value": value
                            })
                            break  # only first non-empty match
            except Exception as e:
                print(f"Error on page {page_num+1}, table {table_idx+1}: {e}")
                continue

# ---- FINAL OUTPUT ----
SCB_PDF_Pillar3_df = pd.DataFrame(results)

# Write to Dataiku output dataset
SCB_PDF_Pillar3 = dataiku.Dataset("SCB_PDF_Pillar3")
SCB_PDF_Pillar3.write_with_schema(SCB_PDF_Pillar3_df)
