import pandas as pd
import json
import re
import ast

pd.set_option('display.max_columns', None)

cmreg_prepped = pd.read_csv(r'C:\Users\2011747\Desktop\DUMP_SEPTEMBER_ENDS\Continuous Monitoring\GIA_CM_Register_prepared.csv')
cmreg_prepped.rename(columns={'Title': 'Title_SCB'}, inplace=True)

def extract_contact_info(json_str):
    #print("Original JSON String:", json_str)
    json_str = json_str.replace("'", '"')
    json_str = re.sub(r'(?<!\\)"', r'"', json_str)
    
    json_str = re.sub(r',\s*(}|\])', r'\1', json_str)
    
    #json_str = re.sub(r'(?<!\\)"', r'"', json_str)
    #json_str = re.sub(r',\s*}', '}', json_str)
    #json_str = re.sub(r',\s*]', ']', json_str)
    #print("Preprocessed JSON String:", json_str)
    
    try:
        data = json.loads(json_str)
        results = data['results']
        contact_df = pd.json_normalize(results)
        return contact_df[['Name', 'Title']]
    except json.JSONDecodeError as e:
        print(f"JSON Decode Error: {e}")
        return pd.DataFrame(columns=['Name', 'Title'])
    
def process_and_merge(df):
    contact_dfs = df['Contact_x0020_for_x0020_Continuo'].apply(extract_contact_info)
    
    df['row_id'] = df.index
    contact_dfs = pd.concat(contact_dfs.tolist(), ignore_index=True)
    
    df_expanded = df.drop(columns='Contact_x0020_for_x0020_Continuo')
    contact_dfs['row_id'] = df_expanded['row_id'].repeat(contact_dfs.groupby('row_id').size().values())
    
    result_df = pd.merge(df_expanded, contact_dfs, on='row_id').drop(columns='row_id')
    
    return result_df

# Function to split rows based on semicolon-separated "Country" values
def split_rows(df, column_name):
    # Split the "Country" column into a list of countries for each row
    df[column_name] = df[column_name].str.split(',')
    
    # Explode the DataFrame so each country gets its own row
    df = df.explode(column_name)
    
    return df

###################################################################################################

contact_dfs = cmreg_prepped['Contact_x0020_for_x0020_Continuo'].apply(extract_contact_info)

result_df = pd.concat(contact_dfs.tolist(), ignore_index=True)

result_df['SCB_PSID'] = result_df['Name'].str.slice(-7)
result_df = result_df.drop(columns={'Name'})

result_df.rename(columns={'Title': 'Name'}, inplace=True)

contacts_df = result_df

cmreg_prepped['Extracted_IDs'] = cmreg_prepped['Contact_x0020_for_x0020_Continuo'].apply(lambda x: re.findall(r'\b\d{7}\b', x))
cmreg_prepped_expanded = cmreg_prepped.explode('Extracted_IDs')
final_df = pd.merge(cmreg_prepped_expanded, contacts_df, left_on = 'Extracted_IDs', right_on = 'SCB_PSID', how='left')

###################################################################################################

final_df['Risk_Themes'] = final_df['Risk_Themes'].str.replace('[', '')
final_df['Risk_Themes'] = final_df['Risk_Themes'].str.replace(']', '')
final_df['Risk_Themes'] = final_df['Risk_Themes'].str.replace('"', '')

final_df['Business_Functions'] = final_df['Business_Functions'].str.replace('[', '')
final_df['Business_Functions'] = final_df['Business_Functions'].str.replace(']', '')
final_df['Business_Functions'] = final_df['Business_Functions'].str.replace('"', '')

final_df['Business_Functions'] = final_df['Business_Functions'].str.replace('Compliance,', 'Compliance')
final_df['Business_Functions'] = final_df['Business_Functions'].str.replace('Sanctions,', 'Sanctions')
final_df['Business_Functions'] = final_df['Business_Functions'].str.replace('Affairs,', 'Affairs')
final_df['Business_Functions'] = final_df['Business_Functions'].str.replace('Governance,', 'Governance')

final_df['Auditable_Entity'] = final_df['Auditable_Entity'].str.replace('[', '')
final_df['Auditable_Entity'] = final_df['Auditable_Entity'].str.replace(']', '')
final_df['Auditable_Entity'] = final_df['Auditable_Entity'].str.replace('"', '')

final_df['Auditable_Entity'] = final_df['Auditable_Entity'].str.replace('Transformation, Technology,', 'Transformation Technology')
final_df['Auditable_Entity'] = final_df['Auditable_Entity'].str.replace('Corporate Secretariat, Legal and SIS', 'Corporate Secretariat Legal and SIS')
final_df['Auditable_Entity'] = final_df['Auditable_Entity'].str.replace('Corporate, Commercial & Institutional Banking', 'Corporate Commercial & Institutional Banking')
final_df['Auditable_Entity'] = final_df['Auditable_Entity'].str.replace('(CPM), Stressed Asset Group (SAG),', '(CPM) Stressed Asset Group (SAG)')

final_df['Risk_Themes_Original'] = final_df['Risk_Themes']
final_df['Business_Functions_Original'] = final_df['Business_Functions']
final_df['Country_Original'] = final_df['Country_x0020_impacted_results']

##############################################################################

final_dfa = split_rows(final_df, 'Business_Functions')
#final_dfb = split_rows(final_dfa, 'Risk_Themes')

##############################################################################

final_dfa['Country_x0020_impacted_results'] = final_dfa['Country_x0020_impacted_results'].str.replace('[', '')
final_dfa['Country_x0020_impacted_results'] = final_dfa['Country_x0020_impacted_results'].str.replace(']', '')
final_dfa['Country_x0020_impacted_results'] = final_dfa['Country_x0020_impacted_results'].str.replace('"', '')

final_df = final_dfa[['Id', 'Title_SCB', 'Date_event', 'Source_event', 'Created', 'Risk_Themes_Original', 'Business_Functions_Original', 'Country_Original', 'Risk_Themes', 'Business_Functions', 'Country_x0020_impacted_results', 'Name', 'SCB_PSID', 'Key_Points']]

final_df = final_df.rename(columns = {'Title_SCB':'Title', 'Date_event': 'Date_of_event', 'Source_event': 'Source_of_event', 'Country_x0020_impacted_results': 'Country'}, )

final_df = split_rows(final_df, 'Country')
final_df = split_rows(final_df, 'Risk_Themes')

##############################################################################

# Group by 'Id' and collect non-empty 'Name' and 'Pass' values in lists
grouped = final_df.groupby('Id').agg({
    'Name': lambda x: list(set(f"'{name}'" for name in x if name)),  # Filter out empty names
    'SCB_PSID': lambda x: list(set(f"'{pass_}'" for pass_ in x if pass_))  # Filter out empty passes
}).reset_index()

# Create a mapping from 'Id' to aggregated Name_Group and Pass_Group
name_pass_map = dict(zip(grouped['Id'], zip(grouped['Name'], grouped['SCB_PSID'])))

# Map the Name_Group and Pass_Group back to the original DataFrame based on 'Id'
final_df['Name_Group'] = final_df['Id'].map(lambda x: name_pass_map.get(x, ([], []))[0])
final_df['SCB_PSID_Group'] = final_df['Id'].map(lambda x: name_pass_map.get(x, ([], []))[1])

##############################################################################

final_df.to_csv(r'C:\Users\2011747\Desktop\Final_GIA_CM_Register_test.csv', index=False)
