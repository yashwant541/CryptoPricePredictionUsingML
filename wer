def append_summary_logs(logs_list: List[dict]) -> pd.DataFrame:
    """
    Append summary logs of different chats into one DataFrame.

    Args:
        logs_list: List of dictionaries containing summary logs.

    Returns:
        DataFrame containing the appended summary logs.
    """
    df_list = []
    for log in logs_list:
        # Convert each dictionary to a DataFrame
        df = pd.DataFrame.from_dict(log, orient='index', columns=['File_Name']).reset_index()
        # Add the DataFrame to the list
        df_list.append(df)

    # Concatenate the list of DataFrames along columns
    summary_df = pd.concat(df_list, axis=1)
    # Drop duplicate columns (e.g., 'File_Name')
    summary_df = summary_df.loc[:, ~summary_df.columns.duplicated()]

    return summary_df



# ... (previous code)

def run_text_analytics_chats(path: str = None, file_name: str = None) -> None:
    """
    Function to run the entire DA test for keywords analytics.

     Args:
        file_name : name of the user input file
        path : location of the user_parameters file.

    Returns:
        None
    """
    # read input data
    user_parameters, keywords_lexicon, cleaning_rules = input_data(path, file_name)

    # create the list of chat log files to process
    files_list = os.listdir(user_parameters['chat_folder_path'])

    # initialise file log number and log used to save file names with number
    file_number = 1
    file_log: dict = {}  # key - file number -> value - file name

    # List to store individual chat logs' summary
    logs_list = []

    # process each chat file
    for chat_file_name in files_list:
        # warning to inform user about the processing progress
        print(f"file {file_number} (out of {len(files_list)}) processing has started (file name: {chat_file_name}")

        file_log[file_number] = chat_file_name

        if user_parameters['file_type'] == 'B':
            df = read_bbg_chat_file(path=user_parameters['chat_folder_path'], file_name=chat_file_name)
        elif user_parameters['file_type'] == 'S':
            df = read_skype_chat_file(path=user_parameters['chat_folder_path'], file_name=chat_file_name,
                                       skype_column=user_parameters['skype_column_name'])
        else:
            sys.exit('The file_type parameter is not properly set')

        df_clean, df_excluded = flag_lines_to_exclude(df=df, exclusions_table=cleaning_rules)
        df_clean = lexicon_matching(df=df_clean, lexicon=keywords_lexicon, user_parameters=user_parameters)
        log, keywords_match_summary, exclusion_summary, same_keywords_summary = chat_file_stats_log(
            df_clean=df_clean, df_excluded=df_excluded, chat_file=chat_file_name)
        
        # Append the current log to the list
        logs_list.append(log)

        save_final_processed_files(user_parameters=user_parameters, df_clean=df_clean, df_excluded=df_excluded,
                                   file_name=chat_file_name, file_number=file_number, log=log,
                                   keywords_match_summary=keywords_match_summary, exclusions_summary=exclusion_summary,
                                   same_keywords_summary=same_keywords_summary)

        # warning to inform user about the processing progress
        print(f"file {file_number} (out of {len(files_list)}) has been processed (file name: {chat_file_name})")
        file_number += 1

    # Append the summary logs of all chats into one DataFrame
    summary_df = append_summary_logs(logs_list)

    # Save the summary logs DataFrame to Excel
    summary_df.to_excel(f"{user_parameters['output_path']}\\summary_logs.xlsx", index=False, encoding='utf-8-sig')
