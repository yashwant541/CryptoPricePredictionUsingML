import pandas as pd
import dataiku
import tempfile
import os
from datetime import datetime

# ------------------------------------------------------
# üîß Configuration ‚Äî Replace with your Dataiku folder IDs
# ------------------------------------------------------
input_folder = dataiku.Folder("XXXXXXXX")       # üì• Input folder
output_folder = dataiku.Folder("XXXXXXXX")      # üì§ Output folder

# Sheets to skip
EXCEPTION_SHEETS = ["Tracking Sheet", "FXO VOLS FBIL Realtime", "FXO VOLS Refinitiv Realtime"]

# Sheets that follow the special Bid/Ask structure (configurable)
SPECIAL_SHEETS = ["IN", "INR", "INFXO", "IN_FX", "IN_FWD"]  # you can add more names here

# ------------------------------------------------------
# üß† Helper Functions
# ------------------------------------------------------
def looks_like_date(val):
    """Check if a value looks like a date"""
    if isinstance(val, (pd.Timestamp, datetime)):
        return True
    if isinstance(val, str):
        for fmt in ("%d-%b-%y", "%d-%b-%Y", "%Y-%m-%d", "%m/%d/%Y", "%m-%d-%Y"):
            try:
                datetime.strptime(val.strip(), fmt)
                return True
            except:
                continue
    return False


def read_excel_safe(file_path):
    """Read Excel using openpyxl engine for .xlsx"""
    return pd.ExcelFile(file_path, engine="openpyxl")


def sheet_is_special(sheet_name):
    """Check if a sheet name matches any of the special identifiers"""
    return any(key.lower() in sheet_name.lower() for key in SPECIAL_SHEETS)


# ------------------------------------------------------
# üöÄ Main Execution
# ------------------------------------------------------
def main():
    input_files = input_folder.list_paths_in_partition()
    if not input_files:
        raise FileNotFoundError("‚ùå No files found in input folder!")

    for excel_file_info in input_files:
        file_name = os.path.basename(excel_file_info)

        # Download file to temporary location
        with input_folder.get_download_stream(excel_file_info) as stream:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
                tmp.write(stream.read())
                tmp_path = tmp.name

        xls = read_excel_safe(tmp_path)

        for sheet_name in xls.sheet_names:
            # Skip exception sheets
            if sheet_name in EXCEPTION_SHEETS:
                print(f"‚è© Skipping sheet '{sheet_name}' as it is in the exception list")
                continue

            print(f"\nüìÑ Processing sheet: {sheet_name}")

            # Special sheet processing
            if sheet_is_special(sheet_name):
                print(f"‚öôÔ∏è  Detected special Bid/Ask structure in sheet '{sheet_name}'")

                df_raw = pd.read_excel(tmp_path, sheet_name=sheet_name, header=None, engine="openpyxl")

                # Start reading from row 10 (index 9)
                df_data = df_raw.iloc[9:].reset_index(drop=True)

                # Identify columns that look like date, bid, ask, or value
                df_data.columns = [f"col_{i}" for i in range(df_data.shape[1])]

                tidy_data_list = []
                current_label = None
                has_bidask = False

                # Loop through columns to find data chunks separated by blank columns
                col_index = 0
                while col_index < df_data.shape[1]:
                    col_series = df_data.iloc[:, col_index]

                    # Skip fully empty columns
                    if col_series.dropna().empty:
                        col_index += 1
                        continue

                    # Try to detect a date column
                    if col_series.apply(looks_like_date).sum() > 0:
                        next_cols = df_data.iloc[:, col_index + 1:col_index + 3]
                        possible_cols = list(next_cols.columns)

                        # Case A: Date, Bid, Ask present
                        if len(possible_cols) >= 2 and not df_data[possible_cols[0]].dropna().empty and not df_data[possible_cols[1]].dropna().empty:
                            has_bidask = True
                            temp_df = pd.DataFrame({
                                "Date": df_data.iloc[:, col_index],
                                "Bid": df_data.iloc[:, col_index + 1],
                                "Ask": df_data.iloc[:, col_index + 2],
                            })

                            # Drop rows with missing dates
                            temp_df = temp_df[temp_df["Date"].notna()]

                            temp_df["Value"] = (pd.to_numeric(temp_df["Bid"], errors="coerce") + pd.to_numeric(temp_df["Ask"], errors="coerce")) / 2
                            print(f"‚úÖ Found Bid/Ask columns ‚Äî Doing average of Bid and Ask ‚Äî Average value now is ‚âà {round(temp_df['Value'].mean(skipna=True), 6)}")

                        # Case B: Date, Value only
                        else:
                            temp_df = pd.DataFrame({
                                "Date": df_data.iloc[:, col_index],
                                "Value": df_data.iloc[:, col_index + 1],
                            })
                            temp_df = temp_df[temp_df["Date"].notna()]
                            print(f"‚ö†Ô∏è No Ask column found ‚Äî using single Value column.")

                        # Assign a label name (custom if not found)
                        label_guess = f"Label_{col_index}"
                        temp_df["Label"] = label_guess
                        tidy_data_list.append(temp_df)

                        col_index += 3  # move past this chunk
                    else:
                        col_index += 1

                if not tidy_data_list:
                    print(f"‚ö†Ô∏è No valid data found in special sheet '{sheet_name}'")
                    continue

                final_df = pd.concat(tidy_data_list, ignore_index=True)
                final_df["Date"] = pd.to_datetime(final_df["Date"], errors="coerce")
                final_df = final_df.dropna(subset=["Date", "Value"]).sort_values("Date").reset_index(drop=True)

                if has_bidask:
                    print(f"‚úÖ Confirmed: Bid/Ask values were found for '{sheet_name}'")
                else:
                    print(f"‚ö†Ô∏è Bid/Ask values not found ‚Äî used single Value structure instead")

            else:
                # Normal processing (your original logic)
                df_raw = pd.read_excel(tmp_path, sheet_name=sheet_name, header=None, engine="openpyxl")

                # Row 7 (index 6) contains labels
                label_row_index = 6
                labels_row = df_raw.iloc[label_row_index]

                tidy_data_list = []
                for col in range(df_raw.shape[1]):
                    label = labels_row[col]
                    if pd.notna(label):
                        if col + 1 < df_raw.shape[1]:
                            dates = df_raw.iloc[label_row_index + 1:, col]
                            values = df_raw.iloc[label_row_index + 1:, col + 1]
                            mask = dates.notna() & values.notna()
                            dates = dates[mask]
                            values = values[mask]

                            temp_df = pd.DataFrame({
                                "Date": dates,
                                "Label": label,
                                "Value": values
                            })
                            tidy_data_list.append(temp_df)

                if not tidy_data_list:
                    print(f"‚ö†Ô∏è No valid data found in sheet '{sheet_name}'")
                    continue

                final_df = pd.concat(tidy_data_list, ignore_index=True)
                final_df["Date"] = pd.to_datetime(final_df["Date"], errors='coerce')
                final_df = final_df.sort_values("Date").reset_index(drop=True)

            # ------------------------------------------------------
            # üíæ Save the output
            # ------------------------------------------------------
            safe_sheet_name = "".join(c if c.isalnum() else "_" for c in sheet_name)
            output_filename = f"{os.path.splitext(file_name)[0]}_{safe_sheet_name}.csv"

            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False, newline='', encoding="utf-8") as tmp_file:
                final_df.to_csv(tmp_file.name, index=False)
                with open(tmp_file.name, "rb") as f:
                    output_folder.upload_stream(output_filename, f)
                os.remove(tmp_file.name)

            print(f"‚úÖ Sheet '{sheet_name}' saved as CSV: {output_filename}")

        os.remove(tmp_path)
        print(f"üèÅ Completed processing for file: {file_name}")


# ------------------------------------------------------
if __name__ == "__main__":
    main()
