import pandas as pd
import dataiku
import os
import io

# ------------------------------------------------------
# üîß Configuration ‚Äî Replace with your actual folder IDs
# ------------------------------------------------------
input_folder = dataiku.Folder("YOUR_INPUT_FOLDER_ID")   # üì• Excel files
output_folder = dataiku.Folder("YOUR_OUTPUT_FOLDER_ID") # üì§ Output CSVs

# ------------------------------------------------------
# üß† Helper: Check if a sheet is "special" (Bid/Ask)
# ------------------------------------------------------
def is_special_sheet(df):
    headers = [str(h).lower() for h in df.columns]
    return any("bid" in h for h in headers) or any("ask" in h for h in headers)

# ------------------------------------------------------
# üß† Helper: Clean numeric safely
# ------------------------------------------------------
def to_num(v):
    try:
        return float(str(v).replace(',', '').strip())
    except:
        return None

# ------------------------------------------------------
# üöÄ Main processing
# ------------------------------------------------------
for file_path in input_folder.list_paths_in_partition():
    if not file_path.lower().endswith((".xlsx", ".xls")):
        continue

    print(f"\nüìò Processing file: {os.path.basename(file_path)}")
    with input_folder.get_download_stream(file_path) as f:
        excel = pd.ExcelFile(io.BytesIO(f.read()))

    for sheet in excel.sheet_names:
        print(f"  ‚û°Ô∏è Reading sheet: {sheet}")
        df = pd.read_excel(excel, sheet_name=sheet, header=None)

        # Skip empty sheets
        if df.dropna(how="all").empty:
            print(f"    ‚ö†Ô∏è Sheet '{sheet}' is empty ‚Äî skipped.")
            continue

        # Handle special BID/ASK sheets (check header row 9)
        data_start_row = 9
        if df.shape[0] > 9:
            header_row = df.iloc[data_start_row - 1]
            data = df.iloc[data_start_row:].copy()
            data.columns = header_row
        else:
            print(f"    ‚ö†Ô∏è Sheet '{sheet}' too short to process ‚Äî skipped.")
            continue

        # Detect columns
        colnames = [str(c).strip() for c in data.columns]
        lower_cols = [c.lower() for c in colnames]

        # Try to find Date column
        date_col = None
        for c in colnames:
            if "date" in c.lower():
                date_col = c
                break

        if date_col is None:
            print(f"    ‚ö†Ô∏è No 'Date' column found in '{sheet}' ‚Äî skipped.")
            continue

        # Clean date column
        data = data[[date_col] + [c for c in colnames if c != date_col]]
        data = data.dropna(subset=[date_col])

        # Determine if special
        special = is_special_sheet(data)

        # Capture label name
        label_name = None
        if special:
            # Row 7 value (index 6 in zero-based)
            if df.shape[0] > 6:
                label_row = df.iloc[6]
                label_name = str(label_row.dropna().iloc[0]) if not label_row.dropna().empty else "Unknown_Label"
            else:
                label_name = "Unknown_Label"
        else:
            # Normal sheet ‚Üí take first non-date column name
            label_candidates = [c for c in colnames if "date" not in c.lower()]
            label_name = label_candidates[0] if label_candidates else "Unknown_Label"

        # Extract value
        output_df = pd.DataFrame()
        output_df["Date"] = data[date_col]

        if special:
            bid_col = next((c for c in colnames if "bid" in c.lower()), None)
            ask_col = next((c for c in colnames if "ask" in c.lower()), None)
            val_col = next((c for c in colnames if "value" in c.lower()), None)

            if bid_col and ask_col:
                data["Avg"] = data.apply(lambda x: (to_num(x[bid_col]) + to_num(x[ask_col])) / 2 if pd.notnull(x[bid_col]) and pd.notnull(x[ask_col]) else None, axis=1)
                output_df["Value"] = data["Avg"]
                print(f"    ‚úÖ Found Bid/Ask columns ‚Üí Averaged. Sample avg: {output_df['Value'].dropna().head(1).tolist()}")
            elif val_col:
                output_df["Value"] = data[val_col]
                print(f"    ‚ö†Ô∏è Found single 'Value' column only.")
            else:
                print(f"    ‚ö†Ô∏è No Bid/Ask/Value columns found ‚Äî skipped.")
                continue
        else:
            # Normal sheet
            val_col = [c for c in colnames if c != date_col][0]
            output_df["Value"] = data[val_col]
            print(f"    ‚úÖ Normal sheet processed. Label: {label_name}")

        # Add label column
        output_df["Label"] = label_name
        output_df = output_df[["Date", "Label", "Value"]]

        # Save output CSV named after sheet
        out_filename = f"{sheet}.csv"
        with output_folder.get_writer(out_filename) as writer:
            output_df.to_csv(writer, index=False)

        print(f"    üíæ Saved output: {out_filename}")

print("\n‚úÖ All sheets processed successfully.")
