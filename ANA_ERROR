import pandas as pd
import dataiku
import tempfile
import os
from datetime import datetime

# ------------------------------------------------------
# üîß Configuration ‚Äî Replace with your Dataiku folder IDs
# ------------------------------------------------------
input_folder = dataiku.Folder("YOUR_INPUT_FOLDER_ID")      # üì• Input folder
output_folder = dataiku.Folder("YOUR_OUTPUT_FOLDER_ID")    # üì§ Output folder

# ------------------------------------------------------
# üß† Helper Functions
# ------------------------------------------------------
def looks_like_date(val):
    if isinstance(val, (pd.Timestamp, datetime)):
        return True
    if isinstance(val, str):
        for fmt in ("%d-%b-%y", "%d-%b-%Y", "%Y-%m-%d"):
            try:
                datetime.strptime(val.strip(), fmt)
                return True
            except:
                continue
    return False

def read_excel_safe(file_path):
    """Read Excel using openpyxl engine for .xlsx"""
    return pd.ExcelFile(file_path, engine="openpyxl")

# ------------------------------------------------------
# üöÄ Main Execution
# ------------------------------------------------------
def main():
    input_files = input_folder.list_paths_in_partition()
    if not input_files:
        raise FileNotFoundError("‚ùå No files found in input folder!")

    excel_file_info = input_files[0]
    file_name = os.path.basename(excel_file_info)

    with input_folder.get_download_stream(excel_file_info) as stream:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
            tmp.write(stream.read())
            tmp_path = tmp.name

    xls = read_excel_safe(tmp_path)
    for sheet_name in xls.sheet_names:
        df_raw = pd.read_excel(tmp_path, sheet_name=sheet_name, header=None, engine="openpyxl")

        # Detect header rows by presence of date
        header_rows = [i for i in range(len(df_raw)) if any(looks_like_date(cell) for cell in df_raw.iloc[i])]
        if not header_rows:
            print(f"‚ö†Ô∏è No tables found in sheet '{sheet_name}', skipping...")
            continue

        all_tables = []
        for idx, header_row in enumerate(header_rows):
            header = df_raw.iloc[header_row].tolist()
            # Find the date in header
            date_in_header = next((cell for cell in header if looks_like_date(cell)), None)
            # Replace that header with 'Fixing Rate'
            header = ["Fixing Rate" if looks_like_date(cell) else cell for cell in header]

            next_header = header_rows[idx + 1] if idx + 1 < len(header_rows) else len(df_raw)
            data_block = df_raw.iloc[header_row + 1:next_header].dropna(how='all')
            if data_block.empty:
                continue

            data_block = data_block.iloc[:, :len(header)]
            data_block.columns = header
            # Add new 'Date' column
            data_block["Date"] = date_in_header
            all_tables.append(data_block)

        if not all_tables:
            print(f"‚ö†Ô∏è No tables extracted from sheet '{sheet_name}'")
            continue

        final_df = pd.concat(all_tables, ignore_index=True)

        # Save sheet CSV to Dataiku output folder
        with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False, newline='', encoding="utf-8") as tmp_file:
            final_df.to_csv(tmp_file.name, index=False)
            with open(tmp_file.name, "rb") as f:
                output_folder.upload_stream(f"{sheet_name}.csv", f)
            os.remove(tmp_file.name)

        print(f"‚úÖ Sheet '{sheet_name}' saved as CSV: {sheet_name}.csv")

    os.remove(tmp_path)
    print(f"‚úÖ Processing complete for file: {file_name}")

# ------------------------------------------------------
if __name__ == "__main__":
    main()

