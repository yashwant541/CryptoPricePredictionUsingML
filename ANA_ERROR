import pandas as pd
import dataiku
import tempfile
import os
import openpyxl

# ------------------------------------------------------
# üîß Configuration ‚Äî Replace with your Dataiku folder IDs
# ------------------------------------------------------
input_folder = dataiku.Folder("XXXXXXX")      # üì• Input folder with multiple files
output_folder = dataiku.Folder("XXXXXXX")     # üì§ Output folder

# ------------------------------------------------------
# üéØ Hardcoded tenor sequences per filename
# ------------------------------------------------------
tenor_sequences = {
    "FX India.csv": [
        "ATMVOL1W", "ATMVOL1M", "ATMVOL3M", "ATMVOL6M", "ATMVOL1Y",
        "RRVOL1W", "RRVOL1M", "RRVOL3M", "RRVOL6M", "RRVOL1Y",
        "BFVOL1W", "BFVOL1M", "BFVOL3M", "BFVOL6M", "BFVOL1Y"
    ],
    "HIBOR HKD&CNH.csv": ["O/N", "1W", "2W", "1M", "2M", "3M", "6M", "12M"],
    "MIBOR.csv": ["2W", "1M", "3M"]
}

# ------------------------------------------------------
# üöÄ Process each file in the order of the tenor mapping
# ------------------------------------------------------
available_paths = input_folder.list_paths_in_partition()

for filename, valid_tenors in tenor_sequences.items():
    # Match the file path in Dataiku folder
    file_path = next((p for p in available_paths if os.path.basename(p) == filename), None)
    if not file_path:
        print(f"‚ö†Ô∏è File not found in input folder: {filename}")
        continue

    print(f"üìÑ Processing: {filename}")

    # Read CSV file
    with input_folder.get_download_stream(file_path) as stream:
        df = pd.read_csv(stream, dtype=str)

    # Strip extra spaces from column names
    df.columns = df.columns.str.strip()

    # --- Ensure required columns exist ---
    required_cols = ["Tenor", "Material Variance Threshold (bps)", "Date"]
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"‚ùå Missing expected column '{col}' in {filename}")

    # Clean MVT values (remove 'vol' text and convert to numeric)
    df["Material Variance Threshold (bps)"] = (
        df["Material Variance Threshold (bps)"]
        .astype(str)
        .str.replace("vol", "", case=False)
        .str.strip()
    )
    df["Material Variance Threshold (bps)"] = pd.to_numeric(
        df["Material Variance Threshold (bps)"], errors="coerce"
    )

    # Filter for only valid tenors
    df_filtered = df[df["Tenor"].isin(valid_tenors)].copy()

    # --- Pivot the table: Date as index, Tenor as columns, MVT as values ---
    pivot = df_filtered.pivot_table(
        index="Date",
        columns="Tenor",
        values="Material Variance Threshold (bps)",
        aggfunc="first"
    )

    # Add any missing tenor columns as empty
    for tenor in valid_tenors:
        if tenor not in pivot.columns:
            pivot[tenor] = pd.NA

    # Order columns properly
    pivot = pivot.reset_index()
    pivot = pivot[["Date"] + valid_tenors]

    # ------------------------------------------------------
    # üß© Special handling for HIBOR HKD&CNH ‚Äî duplicate outputs
    # ------------------------------------------------------
    if filename == "HIBOR HKD&CNH.csv":
        fixing_indices = ["HIBOR_HKD", "HIBOR_CNH"]

        for fixing in fixing_indices:
            output_filename = f"{fixing}_Tenor_MVT.csv"
            tmp_dir = tempfile.mkdtemp()
            tmp_path = os.path.join(tmp_dir, output_filename)
            pivot.to_csv(tmp_path, index=False, encoding="utf-8")

            # Upload to Dataiku output folder
            with open(tmp_path, "rb") as f:
                output_folder.upload_stream(output_filename, f)

            print(f"‚úÖ Saved UTF-8 CSV output: {output_filename}")

        continue  # Move to next file after handling this one

    # ------------------------------------------------------
    # üß† Default processing for other files
    # ------------------------------------------------------
    output_filename = os.path.splitext(filename)[0] + "_Tenor_MVT.csv"
    tmp_dir = tempfile.mkdtemp()
    tmp_path = os.path.join(tmp_dir, output_filename)
    pivot.to_csv(tmp_path, index=False, encoding="utf-8")

    with open(tmp_path, "rb") as f:
        output_folder.upload_stream(output_filename, f)

    print(f"‚úÖ Saved UTF-8 CSV output: {output_filename}")

print("üéâ All files processed successfully.")
