import os
import re
import pandas as pd
from extract_msg import Message
from datetime import datetime

# ============================================================
# üîß CONFIGURATION
# ============================================================
USE_DATAIKU = False  # üîÑ Set True for Dataiku, False for local run

if USE_DATAIKU:
    import dataiku
    INPUT_FOLDER = "input_folder_name"      # <-- Dataiku managed input folder name
    OUTPUT_FOLDER = "output_folder_name"    # <-- Dataiku managed output folder name
else:
    INPUT_FOLDER = r"C:\Users\Yashwant\Desktop\MIBOR_TM\Input"   # <-- Local input folder path
    OUTPUT_FOLDER = r"C:\Users\Yashwant\Desktop\MIBOR_TM\Output"  # <-- Local output folder path

# ============================================================


def extract_date_from_filename(filename):
    """
    Extracts date from filename (e.g. '06-Jun-2025', '16th-June-2025', etc.)
    """
    date_pattern = re.compile(r"(\d{1,2}(?:st|nd|rd|th)?[-_ ]?[A-Za-z]{3,9}[-_ ]?\d{2,4})")
    match = date_pattern.search(filename)
    if match:
        date_str = re.sub(r"(st|nd|rd|th)", "", match.group(1))
        date_str = date_str.replace("_", "-").replace(" ", "-")
        for fmt in ("%d-%b-%Y", "%d-%B-%Y", "%d-%b-%y", "%d-%B-%y"):
            try:
                parsed_date = datetime.strptime(date_str, fmt)
                return parsed_date.strftime("%d-%b-%Y")
            except Exception:
                continue
    return "UnknownDate"


def extract_table_by_headers(text):
    """
    Detects and extracts table-like sections by looking for header lines.
    Works with plain text or HTML bodies.
    """
    # Clean and normalize
    text = re.sub(r"<[^>]+>", " ", text)
    text = re.sub(r"\s+", " ", text).strip()

    # Split into lines
    raw_lines = re.split(r"[\r\n]+", text)
    lines = [l.strip() for l in raw_lines if len(l.strip()) > 5]

    # Find header line containing time period markers
    header_pattern = re.compile(r"\b(1\s*WEEK|1\s*MONTH|3\s*MONTHS|6\s*MONTHS|12\s*MONTHS)\b", re.IGNORECASE)
    header_index = None
    for i, line in enumerate(lines):
        if header_pattern.search(line):
            header_index = i
            break

    if header_index is None:
        return None

    # Extract table rows
    header_line = lines[header_index]
    headers = re.split(r"\s{2,}|\t| (?=Bid|Ask)", header_line.strip())
    headers = [h.strip() for h in headers if h.strip()]

    data_rows = []
    for line in lines[header_index + 1:]:
        if re.search(r"Maker\s+User|Checker\s+User|End\s+of\s+Report", line, re.IGNORECASE):
            break
        if len(line.strip()) < 5:
            continue
        parts = re.split(r"\s{2,}|\t| (?=\d)", line.strip())
        if len(parts) >= 3:
            data_rows.append(parts)

    if not data_rows:
        return None

    df = pd.DataFrame(data_rows)
    df.columns = ["Column_" + str(i + 1) for i in range(len(df.columns))]
    return df


def process_msg_files():
    """
    Processes MSG files based on the USE_DATAIKU flag.
    Extracts table sections and saves them as CSV files.
    """
    if USE_DATAIKU:
        input_folder = dataiku.Folder(INPUT_FOLDER)
        output_folder = dataiku.Folder(OUTPUT_FOLDER)
        msg_files = input_folder.list_paths_in_partition()
    else:
        msg_files = [os.path.join(INPUT_FOLDER, f) for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(".msg")]

    if not msg_files:
        print("‚ùå No .msg files found in the input folder.")
        return

    for file_path in msg_files:
        if not file_path.lower().endswith(".msg"):
            continue

        # Read MSG file
        local_temp = "/tmp/temp_msg.msg"
        if USE_DATAIKU:
            with input_folder.get_download_stream(file_path) as f:
                with open(local_temp, "wb") as tmp:
                    tmp.write(f.read())
        else:
            local_temp = file_path

        try:
            msg = Message(local_temp)
            body = msg.body or msg.htmlBody
        except Exception as e:
            print(f"‚ö†Ô∏è Error reading {file_path}: {e}")
            continue

        if not body:
            print(f"‚ö†Ô∏è No email body found in {file_path}")
            continue

        df = extract_table_by_headers(body)
        if df is not None:
            date_str = extract_date_from_filename(os.path.basename(file_path))
            output_filename = f"{date_str}_table.csv"
            temp_output = os.path.join("/tmp", output_filename)
            df.to_csv(temp_output, index=False)

            if USE_DATAIKU:
                with open(temp_output, "rb") as out:
                    output_folder.upload_stream(output_filename, out)
            else:
                os.makedirs(OUTPUT_FOLDER, exist_ok=True)
                df.to_csv(os.path.join(OUTPUT_FOLDER, output_filename), index=False)

            print(f"‚úÖ Table extracted successfully: {output_filename}")
        else:
            print(f"‚ö†Ô∏è No recognizable table found in {file_path}")


if __name__ == "__main__":
    process_msg_files()
