import os
import re
import io
import pandas as pd
from extract_msg import Message
from datetime import datetime
import dataiku
import logging

# ------------------------------------------------------
# ðŸ”§ Configuration â€” Replace with your Dataiku folder names
# ------------------------------------------------------
INPUT_FOLDER_NAME = "input_msg_folder"
OUTPUT_FOLDER_NAME = "output_csv_folder"

# ------------------------------------------------------
# ðŸªµ Logging setup
# ------------------------------------------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ------------------------------------------------------
# ðŸ“… Helper: Extract date from filename
# ------------------------------------------------------
def extract_date_from_filename(filename):
    name_without_ext = os.path.splitext(filename)[0]
    pattern = r'(\d{1,2}-[A-Za-z]{3}-\d{4})'
    match = re.search(pattern, name_without_ext)
    
    if match:
        date_str = match.group(1)
        try:
            dt = datetime.strptime(date_str, '%d-%b-%Y')
            return dt.strftime('%Y-%m-%d')
        except ValueError:
            logger.warning(f"Could not parse date: {date_str}")
    
    alt_patterns = [
        r'(\d{4}-\d{1,2}-\d{1,2})',  # YYYY-MM-DD
        r'(\d{1,2}-\d{1,2}-\d{4})',  # MM-DD-YYYY
    ]
    for pattern in alt_patterns:
        match = re.search(pattern, name_without_ext)
        if match:
            return match.group(1)
    
    logger.warning(f"Could not extract date from filename: {filename}")
    return "unknown_date"

# ------------------------------------------------------
# ðŸ“„ Extract tables from HTML or text content
# ------------------------------------------------------
def extract_table_from_html(html_content):
    try:
        tables = pd.read_html(html_content)
        if tables:
            return tables[0]
    except Exception as e:
        logger.error(f"Error extracting table from HTML: {e}")
    return None

def extract_table_from_text(text_content):
    lines = text_content.split('\n')
    table_data = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if '\t' in line:
            row = [cell.strip() for cell in line.split('\t') if cell.strip()]
        elif re.search(r',\s*\w', line) and len(line.split(',')) > 2:
            row = [cell.strip() for cell in line.split(',') if cell.strip()]
        else:
            cells = re.split(r'\s{2,}', line)
            row = [cell.strip() for cell in cells if cell.strip()]
        if len(row) > 1:
            table_data.append(row)
    
    if len(table_data) > 1:
        try:
            df = pd.DataFrame(table_data[1:], columns=table_data[0])
            return df
        except Exception as e:
            logger.error(f"Error creating DataFrame from text: {e}")
    return None

# ------------------------------------------------------
# ðŸ“¬ Process a single MSG file (in-memory)
# ------------------------------------------------------
def process_msg_stream(file_name, file_bytes, output_folder):
    try:
        msg = Message(io.BytesIO(file_bytes))
        date_str = extract_date_from_filename(file_name)
        logger.info(f"Processing {file_name} | Date: {date_str}")

        table_df = None
        if msg.htmlBody:
            table_df = extract_table_from_html(msg.htmlBody)
        if table_df is None and msg.body:
            table_df = extract_table_from_text(msg.body)
        
        if table_df is not None:
            output_filename = f"{date_str}_table.csv"
            with output_folder.upload_stream(output_filename) as out:
                table_df.to_csv(out, index=False)
            logger.info(f"âœ… Saved {output_filename} | Shape: {table_df.shape}")
            return True
        else:
            logger.warning(f"âœ— No table found in {file_name}")
            return False
    except Exception as e:
        logger.error(f"Error processing {file_name}: {e}")
        return False

# ------------------------------------------------------
# ðŸš€ Main execution for Dataiku
# ------------------------------------------------------
def main():
    input_folder = dataiku.Folder(INPUT_FOLDER_NAME)
    output_folder = dataiku.Folder(OUTPUT_FOLDER_NAME)

    file_list = input_folder.list_paths_in_partition()
    msg_files = [f for f in file_list if f.lower().endswith('.msg')]

    if not msg_files:
        logger.warning("No MSG files found in input folder.")
        return

    logger.info(f"Found {len(msg_files)} MSG files to process.")

    success_count = 0
    for i, file_path in enumerate(msg_files, start=1):
        logger.info(f"\n[{i}/{len(msg_files)}] Processing: {file_path}")
        with input_folder.get_download_stream(file_path) as stream:
            file_bytes = stream.read()
            if process_msg_stream(os.path.basename(file_path), file_bytes, output_folder):
                success_count += 1

    logger.info("=" * 60)
    logger.info(f"Processing complete. Extracted tables from {success_count}/{len(msg_files)} files.")

# ------------------------------------------------------
if __name__ == "__main__":
    main()
