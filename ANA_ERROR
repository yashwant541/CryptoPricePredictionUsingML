import dataiku
import re
import io
import os
from datetime import datetime
import pandas as pd

# ------------------------------------------------------------
# ðŸ•’ Force UTC timezone to avoid timestamp/timezone conflicts
# ------------------------------------------------------------
os.environ["TZ"] = "UTC"
try:
    import time
    time.tzset()
except Exception:
    pass

# -------------------------------
# ðŸ”§ Configuration: Dataiku folders
# -------------------------------
input_folder = dataiku.Folder("INPUT_FOLDER_ID")   # Replace with your input folder ID
output_folder = dataiku.Folder("OUTPUT_FOLDER_ID") # Replace with your output folder ID

# -------------------------------
# Print all files in input folder
# -------------------------------
all_files = input_folder.list_paths_in_partition()
if not all_files:
    print("No files found in the input folder!")
else:
    print(f"Found {len(all_files)} files in the input folder:\n")
    for f in all_files:
        print(f)
print("="*50)

# Regex to match dates in filename (ordinals or 6-digit numbers)
date_pattern = re.compile(
    r'(\d{1,2}(?:st|nd|rd|th)?[- ]?[A-Za-z]{3,9}[- ]\d{4}|\b\d{6}\b)',
    re.IGNORECASE
)

# -------------------------------
# Helper: Normalize date string
# -------------------------------
def normalize_date(date_str):
    if re.fullmatch(r'\d{6}', date_str):
        dt = datetime.strptime(date_str, "%d%m%y")
        return dt.strftime("%d-%b-%Y")
    else:
        date_str = re.sub(r'(st|nd|rd|th)', '', date_str, flags=re.IGNORECASE)
        date_str = date_str.replace(' ', '-')
        return date_str

# -------------------------------
# Helper: Extract table from text content
# -------------------------------
def extract_table_from_text(text_content):
    lines = text_content.split('\n')
    table_data = []

    for line in lines:
        line = line.strip()
        if not line:
            continue
        # Tab-separated
        if '\t' in line:
            row = [c.strip() for c in line.split('\t') if c.strip()]
        # Comma-separated
        elif ',' in line and len(line.split(',')) > 1:
            row = [c.strip() for c in line.split(',') if c.strip()]
        # Space-separated (2+ spaces)
        else:
            row = [c.strip() for c in re.split(r'\s{2,}', line) if c.strip()]
        if len(row) > 1:
            table_data.append(row)

    if len(table_data) > 1:
        try:
            df = pd.DataFrame(table_data[1:], columns=table_data[0])
            return df
        except Exception as e:
            print(f"Error creating DataFrame from text: {e}")
    return None

# -------------------------------
# Process all TXT files
# -------------------------------
txt_files_found = False

for file_info in all_files:
    # Case-insensitive check for TXT files
    if not file_info.lower().endswith(".txt"):
        continue

    txt_files_found = True

    try:
        # Read TXT content
        with input_folder.get_download_stream(file_info) as f:
            txt_bytes = f.read()
            txt_content = txt_bytes.decode('utf-8', errors='ignore')

        # Extract date from filename
        match = date_pattern.search(file_info)
        file_date = normalize_date(match.group(0)) if match else "UnknownDate"

        # Extract table from TXT content
        table_df = extract_table_from_text(txt_content)

        # Save table if found using upload stream
        if table_df is not None:
            table_name = f"{file_date}_table.csv"
            with output_folder.get_upload_stream(table_name) as out_f:
                out_f.write(table_df.to_csv(index=False).encode('utf-8'))
            print(f"Saved table {table_name} from {file_info}")
        else:
            print(f"No table found in {file_info}")

    except Exception as e:
        print(f"Failed to process {file_info}: {e}")

if not txt_files_found:
    print("No TXT files found in the input folder.")
