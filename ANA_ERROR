import pandas as pd
import dataiku
import tempfile
import os
import re

# ------------------------------------------------------
# üîß Configuration ‚Äî Replace with your Dataiku folder IDs
# ------------------------------------------------------
input_folder_1 = dataiku.Folder("XXXXXXX")     # üì• Folder 1 (e.g. old rates)
input_folder_2 = dataiku.Folder("XXXXXXX")     # üì• Folder 2 (e.g. new rates)
output_folder = dataiku.Folder("XXXXXXX")      # üì§ Output folder

# ------------------------------------------------------
# üß† Global Variables ‚Äî Edit for your run
# ------------------------------------------------------
FILE1_ID = "OLD_FILE"             # Identifier for File 1 (rename if needed)
FILE2_ID = "NEW_FILE"             # Identifier for File 2 (rename if needed)

file_1_name = "HIBOR_CNH.csv"           # File in folder 1
file_2_name = "HIBOR HKD&CNH.csv"       # File in folder 2

# Columns for file 1
date_col_1 = "Date"
type_col_1 = "Currency"
tenure_col_1 = "Tenure"
rate_col_1 = "Value"

# Columns for file 2
date_col_2 = "Date"
type_col_2 = "Fixing Index"
tenure_col_2 = "Tenor"
rate_col_2 = "Fixing Rate"

# ------------------------------------------------------
# üìÖ Dummy Public Holiday List (MM/DD/YYYY format)
# ------------------------------------------------------
public_holidays = pd.to_datetime([
    "01/01/2024",
    "02/10/2024",
    "03/29/2024",
    "05/01/2024",
    "12/25/2024"
])

# ------------------------------------------------------
# üß© Helper Function ‚Äî Normalize Tenure
# ------------------------------------------------------
def normalize_tenure(val):
    """Normalize Tenure strings like 'O/N' ‚Üí 'ON', 'T/N' ‚Üí 'TN', '1Y' ‚Üí '12M', etc."""
    if pd.isna(val):
        return None
    val = str(val).strip().upper()
    val = re.sub(r'[^A-Z0-9]', '', val)  # remove special chars like '/', '-', etc.

    mapping = {
        "ON": ["ON", "O/N", "1D", "DAY1", "OD", "OVERNIGHT", "SPOT"],
        "TN": ["TN", "T/N", "TOMNEXT", "TOMORROWNEXT"],
        "1W": ["1W", "7D", "ONEWEEK"],
        "2W": ["2W", "14D", "TWOWEEK"],
        "1M": ["1M", "30D", "ONEMONTH"],
        "2M": ["2M", "60D", "TWOMONTH"],
        "3M": ["3M", "90D", "THREEMONTH"],
        "6M": ["6M", "180D", "SIXMONTH"],
        "9M": ["9M", "270D", "NINEMONTH"],
        "12M": ["12M", "1Y", "1YR", "1YEAR", "ONEYEAR"],
        "24M": ["24M", "2Y", "2YR", "2YEAR", "TWOYEAR"]
    }

    for norm, variants in mapping.items():
        if val in variants:
            return norm

    return val

# ------------------------------------------------------
# üöÄ Main Execution
# ------------------------------------------------------
def main():
    # -------------------------------
    # üì• Load files from both folders
    # -------------------------------
    def load_file(folder, filename):
        for path in folder.list_paths_in_partition():
            if os.path.basename(path) == filename:
                with folder.get_download_stream(path) as stream:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(filename)[1]) as tmp:
                        tmp.write(stream.read())
                        tmp_path = tmp.name
                if filename.lower().endswith(".csv"):
                    df = pd.read_csv(tmp_path)
                elif filename.lower().endswith((".xls", ".xlsx")):
                    df = pd.read_excel(tmp_path)
                else:
                    raise ValueError(f"Unsupported file type: {filename}")
                os.remove(tmp_path)
                return df
        raise FileNotFoundError(f"‚ùå File '{filename}' not found in folder {folder.get_id()}!")

    print("üìÇ Reading files...")
    df1 = load_file(input_folder_1, file_1_name)
    df2 = load_file(input_folder_2, file_2_name)

    # -------------------------------
    # üßπ Clean + Normalize Columns
    # -------------------------------
    df1["__Date"] = pd.to_datetime(df1[date_col_1], errors="coerce")
    df2["__Date"] = pd.to_datetime(df2[date_col_2], errors="coerce")

    df1["__Type"] = df1[type_col_1].astype(str).str.strip().str.upper()
    df2["__Type"] = df2[type_col_2].astype(str).str.strip().str.upper()

    df1["__Tenure"] = df1[tenure_col_1].apply(normalize_tenure)
    df2["__Tenure"] = df2[tenure_col_2].apply(normalize_tenure)

    df1["__Rate"] = pd.to_numeric(df1[rate_col_1], errors="coerce").round(3)
    df2["__Rate"] = pd.to_numeric(df2[rate_col_2], errors="coerce").round(3)

    # -------------------------------
    # üîó Merge and Compare
    # -------------------------------
    merged_df = pd.merge(
        df1,
        df2,
        how="outer",
        left_on=["__Date", "__Type", "__Tenure"],
        right_on=["__Date", "__Type", "__Tenure"],
        suffixes=(f"_{FILE1_ID}", f"_{FILE2_ID}")
    )

    # ‚úÖ Compare rounded rates
    merged_df["Match"] = merged_df[f"__Rate_{FILE1_ID}"].eq(merged_df[f"__Rate_{FILE2_ID}"])

    # ‚ûï Add rate difference column (3 decimal precision)
    merged_df["Rate Difference"] = (
        (merged_df[f"__Rate_{FILE2_ID}"] - merged_df[f"__Rate_{FILE1_ID}"])
        .round(3)
    )

    # ------------------------------------------------------
    # üí¨ Add DA_Comment for Unmatched Rows
    # ------------------------------------------------------
    def da_comment(row):
        if pd.isna(row["__Date"]):
            return "Missing Date"
        if row["__Date"] in public_holidays:
            return "Public Holiday"
        if pd.isna(row[f"__Rate_{FILE1_ID}"]) and not pd.isna(row[f"__Rate_{FILE2_ID}"]):
            return f"Missing in {FILE1_ID}"
        if pd.isna(row[f"__Rate_{FILE2_ID}"]) and not pd.isna(row[f"__Rate_{FILE1_ID}"]):
            return f"Missing in {FILE2_ID}"
        if not row["Match"]:
            return "Rate Mismatch"
        return ""

    merged_df["DA_Comment"] = merged_df.apply(da_comment, axis=1)

    # -------------------------------
    # üíæ Save result to Dataiku output
    # -------------------------------
    output_filename = "comparison_result.csv"
    with tempfile.NamedTemporaryFile(mode="w+b", suffix=".csv", delete=False) as tmp_out:
        merged_df.to_csv(tmp_out.name, index=False, encoding="utf-8-sig")
        with open(tmp_out.name, "rb") as f:
            output_folder.upload_stream(output_filename, f)
        os.remove(tmp_out.name)

    print(f"‚úÖ Comparison completed and saved to output folder as '{output_filename}'!")

# ------------------------------------------------------
if __name__ == "__main__":
    main()
