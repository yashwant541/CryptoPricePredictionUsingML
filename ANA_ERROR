import pandas as pd
import dataiku
import tempfile
import os

# ------------------------------------------------------
# üîß Configuration ‚Äî Replace with your Dataiku folder IDs
# ------------------------------------------------------
input_folder = dataiku.Folder("IEHxZtxh")      # üì• Input folder
output_folder = dataiku.Folder("dyonHS8r")     # üì§ Output folder

# ------------------------------------------------------
# üß© Helper Function
# ------------------------------------------------------
def clean_table(df):
    """Cleans, fills merged cells, and prepares final structured table"""

    # Drop completely empty rows & columns
    df = df.dropna(how="all").dropna(axis=1, how="all")

    # Strip column names
    df.columns = df.columns.astype(str).str.strip()

    # üîπ Forward-fill Period and Benchmark(s)
    cols_to_ffill = [col for col in ["Period", "Benchmark(s)"] if col in df.columns]
    df[cols_to_ffill] = df[cols_to_ffill].ffill()

    # üîπ Approval Date ‚Üí fill down only within each Period group
    if "Period" in df.columns and "Approval Date" in df.columns:
        df["Approval Date"] = df.groupby("Period")["Approval Date"].ffill()

    # üîπ Drop rows where all key fields are missing
    key_cols = [c for c in ["Tenor", "MVT", "MVT (Before)"] if c in df.columns]
    if key_cols:
        df = df.dropna(subset=key_cols, how="all")

    return df

# ------------------------------------------------------
# üöÄ Main Execution
# ------------------------------------------------------
def main():
    input_files = input_folder.list_paths_in_partition()
    if not input_files:
        raise FileNotFoundError("‚ùå No Excel files found in input folder!")

    for file_path in input_files:
        file_name = os.path.basename(file_path)
        base_name = os.path.splitext(file_name)[0]
        print(f"\nüìÑ Processing file: {file_name}")

        # Download Excel file temporarily
        with input_folder.get_download_stream(file_path) as stream:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
                tmp.write(stream.read())
                tmp_path = tmp.name

        # Load Excel workbook
        xls = pd.ExcelFile(tmp_path, engine="openpyxl")
        print(f"üìò Found sheets: {xls.sheet_names}")

        for sheet_name in xls.sheet_names:
            print(f"üîπ Reading sheet: {sheet_name}")

            # Read Excel (skip first empty row)
            df_raw = pd.read_excel(tmp_path, sheet_name=sheet_name, skiprows=1, engine="openpyxl")

            # Drop first column if it's blank
            if df_raw.shape[1] > 0 and df_raw.iloc[:, 0].isna().all():
                df_raw = df_raw.drop(df_raw.columns[0], axis=1)

            # Skip empty sheets
            if df_raw.empty:
                print(f"‚ö†Ô∏è Sheet '{sheet_name}' is empty, skipping.")
                continue

            # Clean and structure
            df_clean = clean_table(df_raw)

            if df_clean.empty:
                print(f"‚ö†Ô∏è No valid data found in sheet '{sheet_name}', skipping.")
                continue

            # Output file name ‚Üí filename + sheet name
            safe_sheet_name = "".join(c if c.isalnum() else "_" for c in sheet_name)
            output_filename = f"{base_name}_{safe_sheet_name}_cleaned.csv"

            # Save cleaned output to Dataiku folder
            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False, newline='', encoding="utf-8") as tmp_csv:
                df_clean.to_csv(tmp_csv.name, index=False)
                tmp_csv.close()
                with open(tmp_csv.name, "rb") as f:
                    output_folder.upload_stream(output_filename, f)
                os.remove(tmp_csv.name)

            print(f"‚úÖ Saved cleaned sheet ‚Üí {output_filename}")

        os.remove(tmp_path)
        print(f"üèÅ Completed processing file: {file_name}")

    print("\nüéâ All Excel sheets processed and saved successfully!")

# ------------------------------------------------------
if __name__ == "__main__":
    main()
