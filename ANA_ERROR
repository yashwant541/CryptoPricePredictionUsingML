
import pandas as pd
import dataiku
import tempfile
import os

# ------------------------------------------------------
# üîß Configuration (replace with your Dataiku folder IDs)
# ------------------------------------------------------
input_folder = dataiku.Folder("XXXXXXX")       # Folder containing maker_checker_summary.csv
output_folder = dataiku.Folder("XXXXXXX")      # Folder to save success/fail results

# ------------------------------------------------------
# üß† Helper Function
# ------------------------------------------------------
def evaluate_maker_checker(df):
    """
    Evaluate maker-checker logic per file for each Benchmark + Date combination:
    1. Ensure each file has exactly 4 rows
    2. Ensure maker ‚â† checker
    """
    success_records = []
    fail_records = []

    # Drop fully blank rows
    df = df.dropna(how='all')

    # Clean column names
    df.columns = [c.strip() for c in df.columns]

    # Group by Benchmark + Date
    for (benchmark, date_in_file), group in df.groupby(["Benchmark", "Date (in file)"]):
        # Iterate over files within this combination
        for file_name, file_grp in group.groupby("FileName"):
            file_grp = file_grp.copy()  # Avoid SettingWithCopyWarning

            # Rule 1: exactly 4 rows
            if len(file_grp) != 4:
                file_grp["FailReason"] = "Row count != 4"
                fail_records.append(file_grp)
                continue

            # Identify maker and checker users
            maker_users = set(file_grp[file_grp["Status"].isin(["Calculated", "Proposed"])]["USER"].dropna())
            checker_users = set(file_grp[file_grp["Status"].isin(["Approved", "Submitted"])]["USER"].dropna())

            # Rule 2: maker ‚â† checker
            if maker_users and checker_users and not maker_users.intersection(checker_users):
                success_records.append(file_grp)
            else:
                file_grp["FailReason"] = "Maker and checker overlap or missing users"
                fail_records.append(file_grp)

    df_success = pd.concat(success_records, ignore_index=True) if success_records else pd.DataFrame(columns=df.columns)
    df_fail = pd.concat(fail_records, ignore_index=True) if fail_records else pd.DataFrame(columns=df.columns)

    return df_success, df_fail

# ------------------------------------------------------
# üöÄ Main Execution
# ------------------------------------------------------
def main():
    print("üîç Reading maker_checker_summary.csv from Dataiku input folder...")

    # Locate the summary file
    files = [f for f in input_folder.list_paths_in_partition() if f.lower().endswith(".csv")]
    if not files:
        raise Exception("‚ùå No CSV found in MakerChecker summary input folder.")
    summary_path = files[0]

    # Read file
    with input_folder.get_download_stream(summary_path) as stream:
        df_summary = pd.read_csv(stream)

    # Evaluate
    df_success, df_fail = evaluate_maker_checker(df_summary)

    # Save results to Dataiku output folder
    for df, filename in [(df_success, "MakerChecker_Success.csv"), (df_fail, "MakerChecker_Fails.csv")]:
        with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False, newline='', encoding="utf-8") as tmp_file:
            df.to_csv(tmp_file.name, index=False)
            with open(tmp_file.name, "rb") as f:
                output_folder.upload_stream(filename, f)
            os.remove(tmp_file.name)  # Clean up temp file

    print(f"‚úÖ Evaluation complete: {len(df_success)} success rows, {len(df_fail)} fail rows.")

# ------------------------------------------------------
# Entry point
# ------------------------------------------------------
if __name__ == "__main__":
    main()
