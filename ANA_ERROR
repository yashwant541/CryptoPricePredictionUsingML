# ============================================================
#      NOMINEE NAME VALIDATION (DATAIKU VERSION)
#      OPTIMIZED AND CLEANED FULL VERSION
# ============================================================

import dataiku
import pandas as pd
import re
from rapidfuzz import fuzz

# ------------------------------------------------------------
# READ INPUT DATASET
# ------------------------------------------------------------
input_ds = dataiku.Dataset("DepAuditAcc_CASA_stacked_joined")  
df = input_ds.get_dataframe()

REL_COL = "relationshipno"
ACC_COL = "accountno"
NOM_COL = "name"
ACC_HOLDER_COL = "shortname"

# ------------------------------------------------------------
# HELPER FUNCTIONS
# ------------------------------------------------------------

def clean_text_basic(text):
    """Lowercase, remove special chars, normalize spaces."""
    if not isinstance(text, str):
        return ""
    text = text.lower()
    text = re.sub(r'[^a-z0-9 ]', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    return text.strip()


def is_one_word_name(name):
    if not isinstance(name, str):
        return False
    parts = name.strip().split()
    return len(parts) == 1 and len(parts[0]) >= 2


RANDOM_WORDS = {
    "nomination","nominee","nominated","nominatn",
    "qwerty","asdf","zxcv","xyz","abc","abcd","lmnop"
}

GIBBERISH_PATTERN = re.compile(r"^[A-Za-z]{5,}$")
VOWEL_RATIO_THRESHOLD = 0.10


def is_random_or_nonsense(name):
    if not isinstance(name, str):
        return False

    clean = name.strip().lower()

    if clean in RANDOM_WORDS:
        return True

    # repeated letters e.g. "aaaaa"
    if len(set(clean)) == 1 and len(clean) >= 3:
        return True

    # gibberish pattern
    if GIBBERISH_PATTERN.match(clean):
        vowels = sum(ch in "aeiou" for ch in clean)
        if vowels / (len(clean)+1e-6) < VOWEL_RATIO_THRESHOLD:
            return True

    return False


RELATIONSHIP_WORDS = [
    "mother","mom","mummy","ma",
    "father","dad","papa",
    "son","daughter","child","children",
    "wife","husband","spouse",
    "brother","sister","sibling",
    "uncle","aunt","aunty","nephew","niece",
    "grandmother","grandfather","grandma","grandpa",
    "guardian","caretaker"
]

PLACEHOLDERS = ["na","n/a","none","null","-","--","self","unknown"]

# ------------------------------------------------------------
# FUZZY SIMILARITY CHECK
# ------------------------------------------------------------
def fuzzy_similarity_check(nominee_name, account_holder_name):
    results = []
    if not isinstance(nominee_name, str) or not isinstance(account_holder_name, str):
        return results

    nom = nominee_name.lower().strip()
    acc = account_holder_name.lower().strip()
    acc_tokens = acc.split()

    # 1️⃣ token substring
    for token in acc_tokens:
        if token in nom:
            results.append(f"Account holder token '{token}' found in nominee name")
            break

    # 2️⃣ fuzzy full match
    ratio = fuzz.partial_ratio(acc, nom)
    if ratio >= 80:
        results.append(f"High similarity to account holder name ({ratio}%)")

    # 3️⃣ token-level fuzzy
    for token in acc_tokens:
        score = fuzz.partial_ratio(token, nom)
        if score >= 85:
            results.append(f"Token-level fuzzy similarity ({token}: {score}%)")
            break

    return results


# ------------------------------------------------------------
# MAIN VALIDATION
# ------------------------------------------------------------
def validate_nominee_name(nominee_name):
    issues = []

    if not isinstance(nominee_name, str) or not nominee_name.strip():
        return ["Missing or empty name"]

    name = nominee_name.strip()
    name_lower = name.lower()
    name_cleaned = clean_text_basic(name_lower)

    # Placeholder / invalid
    if name_cleaned in PLACEHOLDERS:
        issues.append("Placeholder / invalid word")

    # One word
    if is_one_word_name(name):
        issues.append("One-word name (possibly incomplete)")

    # Digits
    if re.search(r"\d", name):
        issues.append("Contains digits")

    # Special chars (excluding . ' -)
    if re.search(r"[^\w\s.'-]", name):
        issues.append("Contains special characters")

    # Initial-only
    if re.fullmatch(r"[A-Za-z]\.?", name):
        issues.append("Initials only")

    # Random / nonsense
    if is_random_or_nonsense(name):
        issues.append("Random or nonsensical name")

    # Relationship words
    if any(re.search(rf"\b{rel}\b", name_lower) for rel in RELATIONSHIP_WORDS):
        issues.append("Relationship word used instead of name")

    # --------------------------------------------------------
    # NOM / NOMINEE / NOMINATION / REGISTERED SUBSTRING LOGIC
    # --------------------------------------------------------
    nom_keywords = [
        "nom",
        "nomi",
        "nomine",
        "nominee",
        "nominat",
        "nomination",
        "nominee registered",
        "registered nominee",
    ]

    if any(k in name_cleaned for k in nom_keywords):
        issues.append("Contains nomination-related pattern")

    # Length checks
    if len(name) < 2:
        issues.append("Name too short")
    if len(name) > 70:
        issues.append("Name too long")

    return issues


# ------------------------------------------------------------
# APPLY VALIDATION
# ------------------------------------------------------------
df["nominee_issues"] = df[NOM_COL].apply(validate_nominee_name)
df["issue_count"] = df["nominee_issues"].apply(len)

df["fuzzy_similarity_issues"] = df.apply(
    lambda x: fuzzy_similarity_check(x[NOM_COL], x[ACC_HOLDER_COL]), axis=1
)

# boolean flags
df["has_nom_pattern"] = df["nominee_issues"].apply(
    lambda issues: any("nomination-related" in i.lower() for i in issues)
)

df["has_relationship_word"] = df["nominee_issues"].apply(
    lambda issues: any("relationship word" in i.lower() for i in issues)
)

df["is_nonsense"] = df["nominee_issues"].apply(
    lambda issues: any("nonsensical" in i.lower() for i in issues)
)

df["is_one_word"] = df["nominee_issues"].apply(
    lambda issues: any("one-word" in i.lower() for i in issues)
)

df["has_digits"] = df["nominee_issues"].apply(
    lambda issues: any("digits" in i.lower() for i in issues)
)

df["has_special_chars"] = df["nominee_issues"].apply(
    lambda issues: any("special characters" in i.lower() for i in issues)
)

df["is_initial_only"] = df["nominee_issues"].apply(
    lambda issues: any("initials only" in i.lower() for i in issues)
)

df["is_placeholder"] = df["nominee_issues"].apply(
    lambda issues: any("placeholder" in i.lower() for i in issues)
)

df["is_missing"] = df["nominee_issues"].apply(
    lambda issues: any("missing" in i.lower() for i in issues)
)

# ------------------------------------------------------------
# WRITE OUTPUT DATASET
# ------------------------------------------------------------
output_ds = dataiku.Dataset("AccRelNo_AgainstNominationChecks")
output_ds.write_with_schema(df)
