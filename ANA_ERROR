import pandas as pd
import os
import io
import re
import dataiku

# ------------------------------------------------------
# ⚙️ CONFIGURATION
# ------------------------------------------------------
use_dataiku = True  # 🔄 Switch between Dataiku and local

if use_dataiku:
    input_folder = dataiku.Folder("XXXXXXXX")    # Input folder = previous output (AAA, AA+ etc.)
    output_folder = dataiku.Folder("XXXXXXXX")   # Output folder for long-format CSVs
else:
    input_folder_path = r"C:\path\to\rating_level_output"
    output_folder_path = r"C:\path\to\long_output"

# ------------------------------------------------------
# 🧩 Helper Function: Extract date between 3rd and 4th "_"
# ------------------------------------------------------
def extract_date_from_filename(filename):
    """
    Extracts the date between the 3rd and 4th underscore ("_") in the filename.
    Expected format: 01-Aug-25 or similar.
    Returns the date string if found, else empty string.
    """
    parts = filename.split("_")
    if len(parts) >= 4:
        date_part = parts[3].split(".")[0]
        if re.match(r"\d{1,2}-[A-Za-z]{3}-\d{2,4}", date_part):
            return date_part
    return ""

# ------------------------------------------------------
# 🧠 FUNCTION TO PROCESS FILE
# ------------------------------------------------------
def process_file(file_path, file_name):
    df = pd.read_csv(file_path)

    # Rename "Tenor/Rating" → "Tenor" (if needed)
    if "Tenor/Rating" in df.columns:
        df = df.rename(columns={"Tenor/Rating": "Tenor"})

    # Identify ratings (AAA, AA+, AA, AA-) and their category columns
    rating_cols = ["AAA", "AA+", "AA", "AA-"]
    category_cols = [f"{r} Category" for r in rating_cols]

    # Melt wide → long for each rating
    long_frames = []
    for rating, cat_col in zip(rating_cols, category_cols):
        temp = df[["Tenor", rating, cat_col]].copy()
        temp = temp.rename(columns={rating: "Value", cat_col: "Category"})
        temp["Rating"] = rating
        long_frames.append(temp)

    # Combine all into one long DataFrame
    long_df = pd.concat(long_frames, ignore_index=True)

    # Add file date from filename
    long_df["FileDate"] = extract_date_from_filename(file_name)

    # Output file name
    output_file_name = os.path.splitext(file_name)[0] + "_long.csv"

    # Save output
    if use_dataiku:
        buffer = io.StringIO()
        long_df.to_csv(buffer, index=False)
        output_folder.upload_stream(output_file_name, io.BytesIO(buffer.getvalue().encode("utf-8")))
    else:
        os.makedirs(output_folder_path, exist_ok=True)
        long_df.to_csv(os.path.join(output_folder_path, output_file_name), index=False)

    print(f"✅ {file_name}: {len(long_df)} rows processed (Date: {long_df['FileDate'].iloc[0] if not long_df.empty else 'N/A'})")

# ------------------------------------------------------
# 🚀 MAIN EXECUTION
# ------------------------------------------------------
if use_dataiku:
    for path in input_folder.list_paths_in_partition():
        if path.endswith(".csv"):
            file_name = os.path.basename(path)
            with input_folder.get_download_stream(path) as f:
                df = pd.read_csv(f)
                temp_path = f"/tmp/{file_name}"
                df.to_csv(temp_path, index=False)
                process_file(temp_path, file_name)
else:
    for filename in os.listdir(input_folder_path):
        if filename.endswith(".csv"):
            process_file(os.path.join(input_folder_path, filename), filename)
