import re
import os
import sys
import shutil
import tempfile
import pandas as pd
import dataiku
from openpyxl import load_workbook

# ------------------------------------------------------
# üîß CONFIGURATION
# ------------------------------------------------------
SHEET_NAME_PATTERN = r'COMPUTED[_ ]?DATA'

input_folder = dataiku.Folder("XXXXXXX")     # üìÇ Replace with your input folder ID
output_folder = dataiku.Folder("XXXXXXX")    # üìÇ Replace with your output folder ID

# ------------------------------------------------------
# üß† HELPER FUNCTIONS
# ------------------------------------------------------
def log(msg):
    print(f"[LOG] {msg}", file=sys.stderr, flush=True)


def extract_date_from_filename(filename):
    """Extract date pattern like 01-Aug-25"""
    match = re.search(r'\d{2}-[A-Za-z]{3}-\d{2}', filename)
    return match.group(0) if match else ""


def get_cell_address(row_idx, col_idx):
    """Convert numeric indices to Excel-style cell address"""
    from openpyxl.utils import get_column_letter
    return f"{get_column_letter(col_idx + 1)}{row_idx + 1}"


# ------------------------------------------------------
# üìÑ MAIN EXCEL PARSING FUNCTION
# ------------------------------------------------------
def analyze_computed_data(filepath, filename, file_date):
    wb = load_workbook(filepath, data_only=True)
    sheet_name = None

    for name in wb.sheetnames:
        if re.search(SHEET_NAME_PATTERN, name, re.IGNORECASE):
            sheet_name = name
            break

    if not sheet_name:
        log(f"‚ö†Ô∏è {filename}: No 'COMPUTED DATA' sheet found.")
        return []

    ws = wb[sheet_name]

    records = []
    df5_flag = False

    # We want rows 2, 3, 4 (Excel) ‚Üí indexes 1, 2, 3
    for r_idx in [1, 2, 3]:
        row = ws[r_idx]
        for c_idx, cell in enumerate(row):
            value = str(cell.value).strip() if cell.value is not None else ""
            if value:
                cell_address = get_cell_address(r_idx, c_idx)
                records.append({
                    "FileName": filename,
                    "FileDate": file_date,
                    "RowNumber": r_idx + 1,
                    "CellLocation": cell_address,
                    "Value": value
                })

        # Check for DF-5 keyword presence
        row_values = [str(c.value).upper() if c.value else "" for c in row]
        if "DF-5" in "".join(row_values):
            df5_flag = True

    # Add one summary line per file
    records.append({
        "FileName": filename,
        "FileDate": file_date,
        "RowNumber": "",
        "CellLocation": "",
        "Value": "",
        "DF-5 Flag": df5_flag
    })

    return records


# ------------------------------------------------------
# üöÄ MAIN FUNCTION
# ------------------------------------------------------
def main():
    try:
        log("üîç Scanning top-level input folder for ORIGAMI Excel files...")

        all_files = input_folder.list_paths_in_partition()
        excel_files = [
            f for f in all_files
            if "/" not in f.strip("/")
            and os.path.basename(f).startswith("ORIGAMI")
            and f.lower().endswith((".xlsx", ".xls"))
        ]

        if not excel_files:
            raise Exception("‚ùå No ORIGAMI Excel files found at top level.")

        all_records = []

        for path in excel_files:
            file_name = os.path.basename(path)
            log(f"üìò Processing: {file_name}")

            with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
                with input_folder.get_download_stream(path) as stream:
                    shutil.copyfileobj(stream, tmp_file)
                tmp_path = tmp_file.name

            file_date = extract_date_from_filename(file_name)
            file_records = analyze_computed_data(tmp_path, file_name, file_date)
            all_records.extend(file_records)

            os.remove(tmp_path)

        if not all_records:
            log("‚ö†Ô∏è No data extracted from any file.")
            return

        df_out = pd.DataFrame(all_records)

        # Ensure consistent column ordering
        columns = ["FileName", "FileDate", "RowNumber", "CellLocation", "Value", "DF-5 Flag"]
        for col in columns:
            if col not in df_out.columns:
                df_out[col] = ""
        df_out = df_out[columns]

        # Save consolidated CSV
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8', newline='') as tmp_csv:
            df_out.to_csv(tmp_csv.name, index=False)
            out_name = "computed_data_flags_summary.csv"
            with open(tmp_csv.name, 'rb') as f_out:
                output_folder.upload_stream(out_name, f_out)
            os.remove(tmp_csv.name)

        log(f"‚úÖ Consolidated summary saved: {out_name} ({len(df_out)} rows)")

    except Exception as e:
        log(f"üî• ERROR: {str(e)}")
        raise


# ------------------------------------------------------
# üèÅ ENTRYPOINT
# ------------------------------------------------------
if __name__ == "__main__":
    main()
