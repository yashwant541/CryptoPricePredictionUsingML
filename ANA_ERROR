import re
import os
import sys
import shutil
import tempfile
import pandas as pd
import dataiku
from openpyxl import load_workbook

SHEET_NAME_PATTERN = r'COMPUTED[_ ]?DATA'

# -----------------------------
# Fixed Dataiku Folder Handles
# -----------------------------
input_folder = dataiku.Folder("DCfYhFp0")      # üìÇ Replace with your input folder ID
output_folder_tables = dataiku.Folder("GwwHsyzO")  # üìÇ Replace with your output folder ID for tables
output_folder_summary = dataiku.Folder("k3NfXo0Q") # üìÇ Replace with your output folder ID for summary CSV
# -----------------------------
# Logging Helper
# -----------------------------
def log(message):
    print(f"[LOG] {message}", file=sys.stderr, flush=True)

# -----------------------------
# Utility Functions
# -----------------------------
def extract_date_from_filename(filename):
    """Extract date pattern like 01-Aug-25"""
    match = re.search(r'\d{2}-[A-Za-z]{3}-\d{2}', filename)
    return match.group(0) if match else ""


def read_excel_tab(filepath):
    """Read Origami 'COMPUTED DATA' sheet (multi-row header)
       Hardcode renames:
         - DF-1: between Tenor/Rating and DF-3
         - DF-4: between DF-3 and DF-5
         - Final: after DF-5 (8 columns)
    """
    wb = load_workbook(filepath, data_only=True)
    sheet_name = None

    for name in wb.sheetnames:
        if re.search(SHEET_NAME_PATTERN, name, re.IGNORECASE):
            sheet_name = name
            break
    if not sheet_name:
        log("‚ö†Ô∏è 'COMPUTED DATA' sheet not found.")
        return None, None

    ws = wb[sheet_name]
    all_rows = [list(r) for r in ws.iter_rows(values_only=True) if any(r)]
    if len(all_rows) < 3:
        log("‚ö†Ô∏è Not enough rows for table.")
        return None, None

    # Detect header row
    start_row_idx = None
    for i, row in enumerate(all_rows):
        row_str = " ".join([str(c) for c in row if c]).strip().lower()
        if "category" in row_str and "tenor" in row_str:
            start_row_idx = i
            break
    if start_row_idx is None:
        log("‚ö†Ô∏è Table header not found.")
        return None, None

    header_row_1 = [str(x).strip() if x else "" for x in all_rows[start_row_idx]]
    header_row_2 = [str(x).strip() if x else "" for x in all_rows[start_row_idx + 1]]

    # Combine headers
    combined_headers = []
    for h1, h2 in zip(header_row_1, header_row_2):
        clean_h1 = re.sub(r'\s+', ' ', re.sub(r'[\(\)]', '', h1)).strip()
        clean_h2 = re.sub(r'\s+', ' ', re.sub(r'[\(\)]', '', h2)).strip()
        combined_headers.append(f"{clean_h1} {clean_h2}".strip() if clean_h1 and clean_h2 else (clean_h1 or clean_h2))

    # Data rows
    start_idx = start_row_idx + 2
    end_idx = len(all_rows)
    for i, row in enumerate(all_rows[start_idx:], start=start_idx):
        text = " ".join([str(c) for c in row if c]).strip()
        if any(x in text for x in ["USER:", "Benchmark:", "Status", "Date:"]):
            end_idx = i
            break
    table_rows = all_rows[start_idx:end_idx]
    if not table_rows:
        log("‚ö†Ô∏è No data rows found.")
        return None, None

    df_table = pd.DataFrame(table_rows, columns=combined_headers)

    # -------------------------------------------------------
    # Robust column renaming
    # -------------------------------------------------------
    def find_col_index(keywords):
        key_lower = [k.lower() for k in keywords]
        for idx, ch in enumerate(combined_headers):
            if any(k in str(ch).lower() for k in key_lower):
                return idx
        return None

    tenor_idx = find_col_index(["tenor", "tenor/rating"])
    df3_idx = find_col_index(["DF-3", "DF3"])
    df5_idx = find_col_index(["DF-5", "DF5"])

    rename_map = {}

    # DF-1: between Tenor/Rating and DF-3
    if tenor_idx is not None and df3_idx is not None:
        df1_cols = list(range(tenor_idx + 1, df3_idx))
        df1_names = ["DF-1 AAA", "DF-1 AA+", "DF-1 AA", "DF-1 AA-"]
        for i, name in zip(df1_cols, df1_names):
            if i < len(df_table.columns):
                rename_map[df_table.columns[i]] = name

    # DF-4: between DF-3 and DF-5
    if df3_idx is not None and df5_idx is not None:
        df4_cols = list(range(df3_idx + 1, df5_idx))
        df4_names = ["DF-4 AAA", "DF-4 AA+", "DF-4 AA", "DF-4 AA-"]
        for i, name in zip(df4_cols, df4_names):
            if i < len(df_table.columns):
                rename_map[df_table.columns[i]] = name

    # Final: 8 columns after DF-5
    if df5_idx is not None:
        final_cols = list(range(df5_idx + 1, df5_idx + 9))
        final_names = [
            "Final AAA", "Final AAA Source",
            "Final AA+", "Final AA+ Source",
            "Final AA", "Final AA Source",
            "Final AA-", "Final AA- Source"
        ]
        for i, name in zip(final_cols, final_names):
            if i < len(df_table.columns):
                rename_map[df_table.columns[i]] = name

    # Apply renames
    if rename_map:
        df_table.rename(columns=rename_map, inplace=True)
        log(f"‚ÑπÔ∏è Applied hardcoded rename map: {rename_map}")
    else:
        log("‚ÑπÔ∏è No renames applied (rename_map empty).")

    # -------------------------------------------------------
    # Parse summary section
    # -------------------------------------------------------
    summary_rows = all_rows[end_idx:]
    summary_texts = [" ".join([str(c) for c in row if c]).strip() for row in summary_rows if any(row)]
    metadata = []
    current = {}
    for line in summary_texts:
        line = line.strip()
        if re.search(r'\bUSER\b', line):
            if current: metadata.append(current); current = {}
            match = re.search(r'USER[:\s]*(.*)', line)
            current["USER"] = match.group(1).strip() if match else ""
        elif re.search(r'\bBenchmark\b', line):
            match = re.search(r'Benchmark[:\s]*(.*)', line)
            current["Benchmark"] = match.group(1).strip() if match else ""
        elif re.search(r'\bDate\b', line):
            match = re.search(r'Date[:\s]*(.*)', line)
            current["Date (in file)"] = match.group(1).strip() if match else ""
        elif re.search(r'\bStatus\b', line) and "Status Time" not in line:
            match = re.search(r'Status[:\s]*(.*)', line)
            current["Status"] = match.group(1).strip() if match else ""
        elif re.search(r'\bStatus Time\b', line):
            match = re.search(r'Status Time[:\s]*(.*)', line)
            current["Status Time"] = match.group(1).strip() if match else ""
    if current: metadata.append(current)

    return df_table, metadata

# -----------------------------
# Main Processing
# -----------------------------
def main():
    try:
        log("üîç Scanning top-level of input folder for ORIGAMI Excel files...")

        all_files = input_folder.list_paths_in_partition()
        excel_files = [
            f for f in all_files
            if "/" not in f.strip("/")  # ensures top-level only
            and os.path.basename(f).startswith("ORIGAMI")
            and f.lower().endswith((".xlsx", ".xls"))
        ]

        if not excel_files:
            raise Exception("‚ùå No ORIGAMI Excel files found in the top level of the input folder.")

        summary_records = []

        for path in excel_files:
            file_name = os.path.basename(path)
            log(f"üìÑ Processing: {file_name}")

            # Download to temporary file
            with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
                tmp_file_path = tmp_file.name
                with input_folder.get_download_stream(path) as stream:
                    shutil.copyfileobj(stream, tmp_file)

            # Extract date from filename
            file_date = extract_date_from_filename(file_name)

            # Parse Excel
            df_table, metadata_list = read_excel_tab(tmp_file_path)
            os.remove(tmp_file_path)

            if df_table is None:
                log(f"‚ö†Ô∏è Skipped {file_name}: No valid 'Excel Tab' or table found.")
                continue

            # Save main table to output folder
            with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_out:
                df_table.to_excel(tmp_out.name, index=False)
                out_name = file_name.replace(".xlsx", "_table.xlsx")
                with open(tmp_out.name, "rb") as f_out:
                    output_folder_tables.upload_stream(out_name, f_out)
                os.remove(tmp_out.name)
                log(f"‚úÖ Saved table: {out_name}")

            # Add metadata info to summary
            if metadata_list:
                for meta in metadata_list:
                    summary_records.append({
                        "FileName": file_name,
                        "FileDate": file_date,
                        "USER": meta.get("USER", ""),
                        "Benchmark": meta.get("Benchmark", ""),
                        "Date (in file)": meta.get("Date (in file)", ""),
                        "Status": meta.get("Status", ""),
                        "Status Time": meta.get("Status Time", "")
                    })
            else:
                summary_records.append({
                    "FileName": file_name,
                    "FileDate": file_date,
                    "USER": "", "Benchmark": "", "Date (in file)": "",
                    "Status": "", "Status Time": ""
                })

        # Save summary CSV
        if summary_records:
            df_summary = pd.DataFrame(summary_records)
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8', newline='') as tmp_csv:
                df_summary.to_csv(tmp_csv.name, index=False)
                csv_name = "maker_checker_summary.csv"
                with open(tmp_csv.name, 'rb') as f:
                    output_folder_summary.upload_stream(csv_name, f)
                os.remove(tmp_csv.name)
            log(f"‚úÖ Summary written to {csv_name} ({len(summary_records)} rows)")
        else:
            log("‚ö†Ô∏è No metadata found to include in summary.")

    except Exception as e:
        log(f"üî• ERROR: {str(e)}")
        raise

# -----------------------------
# Entrypoint
# -----------------------------
if __name__ == "__main__":
    main()
