import pandas as pd
import dataiku
import tempfile
import os
import re
from openpyxl import load_workbook

# ------------------------------------------------------
# ‚öôÔ∏è CONFIGURATION
# ------------------------------------------------------
input_folder = dataiku.Folder("XXXXXXX")   # Input folder with Excel files
output_folder = dataiku.Folder("XXXXXXX")  # Output folder for consolidated result

SHEET_NAME_PATTERN = r"COMPUTED\s*DATA"  # Match Computed Data sheet name

# ------------------------------------------------------
# üß† Helper Functions
# ------------------------------------------------------
def get_cell_address(row_idx, col_idx):
    """Return Excel-style cell address (A1, B2, etc.)."""
    letters = ""
    col = col_idx + 1
    while col:
        col, remainder = divmod(col - 1, 26)
        letters = chr(65 + remainder) + letters
    return f"{letters}{row_idx + 1}"

def log(msg):
    print(msg)

def extract_file_date(filename):
    """Extract date pattern from filename like 01-Aug-25."""
    match = re.search(r"(\d{1,2}-[A-Za-z]{3}-\d{2,4})", filename)
    return match.group(1) if match else None

# ------------------------------------------------------
# üîç Main Extraction Logic
# ------------------------------------------------------
def analyze_computed_data(filepath, filename, file_date):
    wb = load_workbook(filepath, data_only=True)
    sheet_name = None

    for name in wb.sheetnames:
        if re.search(SHEET_NAME_PATTERN, name, re.IGNORECASE):
            sheet_name = name
            break

    if not sheet_name:
        log(f"‚ö†Ô∏è {filename}: No 'COMPUTED DATA' sheet found.")
        return []

    ws = wb[sheet_name]
    records = []

    # Rows 2, 3, 4 ‚Üí zero-based indices 1, 2, 3
    for r_idx in [1, 2, 3]:
        row = ws[r_idx]
        for c_idx, cell in enumerate(row):
            value = str(cell.value).strip() if cell.value is not None else ""
            if value:
                cell_address = get_cell_address(r_idx, c_idx)

                # ‚úÖ DF-5 Flag Logic:
                # True if the cell value matches "DF-5" (case-insensitive) and is in Excel row 2
                df5_flag = (value.strip().upper() == "DF-5" and (r_idx + 1 == 2))

                records.append({
                    "FileName": filename,
                    "FileDate": file_date,
                    "RowNumber": r_idx + 1,
                    "CellLocation": cell_address,
                    "Value": value,
                    "DF-5 Flag": df5_flag
                })

    return records

# ------------------------------------------------------
# üöÄ Main Execution
# ------------------------------------------------------
def main():
    all_records = []

    for path in input_folder.list_paths_in_partition():
        if path.lower().endswith(".xlsx"):
            with input_folder.get_download_stream(path) as stream:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx")
                temp_file.write(stream.read())
                temp_file.close()

                filename = os.path.basename(path)
                file_date = extract_file_date(filename)

                records = analyze_computed_data(temp_file.name, filename, file_date)
                all_records.extend(records)
                os.remove(temp_file.name)

    # Create consolidated DataFrame
    df = pd.DataFrame(all_records)

    if not df.empty:
        output_path = os.path.join(tempfile.gettempdir(), "computed_data_summary.csv")
        df.to_csv(output_path, index=False, encoding="utf-8-sig")

        # Save to Dataiku output folder
        with open(output_path, "rb") as f:
            output_folder.upload_stream("computed_data_summary.csv", f)

        log(f"‚úÖ Consolidated file saved to Dataiku output folder.")
    else:
        log("‚ö†Ô∏è No valid data found across all files.")

# ------------------------------------------------------
# üèÅ Run
# ------------------------------------------------------
if __name__ == "__main__":
    main()
