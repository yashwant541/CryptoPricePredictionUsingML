import os
import re
import pandas as pd
from extract_msg import Message
from datetime import datetime

# ---------------------------------------------------------------------
# CONFIGURATION
# ---------------------------------------------------------------------
USE_DATAIKU = True  # Set to False for local testing

if USE_DATAIKU:
    import dataiku
    input_folder = dataiku.Folder("your_input_folder_id")
    output_folder = dataiku.Folder("your_output_folder_id")
else:
    input_folder = r"C:\path\to\input_folder"
    output_folder = r"C:\path\to\output_folder"

# Define start and end markers
start_text = "VALUES (in %)"
end_text = "Maker User No:"

# ---------------------------------------------------------------------
# HELPER FUNCTIONS
# ---------------------------------------------------------------------
def extract_between_markers(text, start_marker, end_marker):
    """
    Extracts section including start_marker and excluding end_marker.
    """
    pattern = re.escape(start_marker) + r"(.*?)" + re.escape(end_marker)
    match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
    if match:
        return start_marker + match.group(1).strip()
    return None


def extract_date_from_text_or_filename(text, filename):
    """Extract date like 06-Jun-2025 or 16th June 2025 from email or filename."""
    patterns = [
        r"\b\d{1,2}[-_/](?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[-_/]\d{4}\b",
        r"\b\d{1,2}(?:st|nd|rd|th)?\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\s+\d{4}\b"
    ]
    for pat in patterns:
        match = re.search(pat, text, re.IGNORECASE)
        if match:
            date_str = re.sub(r"(st|nd|rd|th)", "", match.group(0))
            for fmt in ("%d %b %Y", "%d-%b-%Y"):
                try:
                    return datetime.strptime(date_str.strip(), fmt).strftime("%d-%b-%Y")
                except ValueError:
                    pass
    # fallback to filename
    for pat in patterns:
        match = re.search(pat, filename, re.IGNORECASE)
        if match:
            return re.sub(r"[ /]", "-", match.group(0))
    return None


def build_table_from_text(raw_text):
    """
    Attempts to rebuild a DataFrame from plain text table layout.
    """
    lines = [l.strip() for l in raw_text.splitlines() if l.strip()]
    text = re.sub(r"\s+", " ", " ".join(lines))

    # Identify known row patterns
    row_labels = ["AVERAGE ATM VOL", "25D_RR", "25D_STR"]
    rows = []
    for label in row_labels:
        match = re.search(label + r"(.*?)((?=" + "|".join(row_labels) + r"|$))", text)
        if match:
            values = re.split(r"\s+", match.group(1).strip())
            rows.append([label] + values)

    # Find headers
    header_match = re.search(r"1 WEEK.*?12 MONTHS", text)
    if header_match:
        header_text = header_match.group(0)
        parts = re.split(r"\s+", header_text)
        expanded_headers = []
        for part in parts:
            if part.upper() in ["BID", "ASK"]:
                continue
            expanded_headers.extend([part + " Bid", part + " Ask"])
    else:
        expanded_headers = []

    if rows:
        df = pd.DataFrame(rows)
        if expanded_headers and len(expanded_headers) + 1 == len(df.columns):
            df.columns = ["Metric"] + expanded_headers
        else:
            df.columns = ["Metric"] + [f"Col_{i}" for i in range(1, len(df.columns))]
        return df
    else:
        # fallback: generic splitting
        data = [re.split(r"\s{2,}", l) for l in lines if len(l.split()) > 1]
        if not data:
            return None
        return pd.DataFrame(data)


def process_msg_file(file_source, file_name):
    msg = Message(file_source)
    body = msg.body or msg.htmlBody or ""
    if not body:
        return None, None

    extracted_text = extract_between_markers(body, start_text, end_text)
    if not extracted_text:
        print(f"⚠️ No table section found in {file_name}")
        return None, None

    df = build_table_from_text(extracted_text)
    date_str = extract_date_from_text_or_filename(body, file_name)
    if df is not None:
        df.insert(0, "Source_File", file_name)
    return df, date_str


# ---------------------------------------------------------------------
# MAIN EXECUTION
# ---------------------------------------------------------------------
if USE_DATAIKU:
    for path in input_folder.list_paths_in_partition():
        if path.lower().endswith(".msg"):
            with input_folder.get_download_stream(path) as stream:
                df, date_str = process_msg_file(stream, os.path.basename(path))
                if df is not None:
                    date_part = date_str or os.path.splitext(os.path.basename(path))[0]
                    output_name = f"extracted_table_{date_part}.csv"
                    with output_folder.get_writer(output_name) as writer:
                        df.to_csv(writer, index=False)
else:
    os.makedirs(output_folder, exist_ok=True)
    for file in os.listdir(input_folder):
        if file.lower().endswith(".msg"):
            df, date_str = process_msg_file(os.path.join(input_folder, file), file)
            if df is not None:
                date_part = date_str or os.path.splitext(file)[0]
                output_path = os.path.join(output_folder, f"extracted_table_{date_part}.csv")
                df.to_csv(output_path, index=False)
                print(f"✅ Saved: {output_path}")

print("✅ Extraction complete.")
