import pandas as pd
import re
from collections import defaultdict

# Built-in stopwords
STOPWORDS = {
    'a', 'an', 'the', 'and', 'or', 'but', 'if', 'because', 'as', 'when',
    'what', 'where', 'from', 'how', 'of', 'for', 'to', 'at', 'in', 'on',
    'that', 'this', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
    'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'should',
    'can', 'could', 'may', 'might', 'must', 'shall', 'which', 'who', 'whom',
    'whose', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her',
    'us', 'them', 'my', 'your', 'his', 'its', 'our', 'their', 'mine', 'yours',
    'hers', 'ours', 'theirs', 'myself', 'yourself', 'himself', 'herself',
    'itself', 'ourselves', 'yourselves', 'themselves'
}

def get_file_columns(df, file_type):
    """Show columns and let user select one"""
    print(f"\nColumns in {file_type} file:")
    for i, col in enumerate(df.columns, 1):
        print(f"{i}. {col}")
    
    while True:
        try:
            col_num = int(input(f"Enter {file_type} column number to use: ")) - 1
            if 0 <= col_num < len(df.columns):
                return df.columns[col_num]
            print("Invalid column number. Try again.")
        except ValueError:
            print("Please enter a valid number.")

def tokenize(text):
    """Advanced tokenizer that handles contractions and hyphenated words"""
    return re.findall(r"\b[\w'-]+\b", str(text).lower())

def analyze_text(text, keywords):
    """Internal sentence analysis with stopword filtering"""
    words = tokenize(text)
    matches = set()
    found_stopwords = set()
    clean_words = []
    
    for word in words:
        if word in STOPWORDS:
            found_stopwords.add(word)
            continue
        
        clean_words.append(word)
        if word in keywords:
            matches.add(word)
    
    # Check for partial matches in remaining text
    clean_text = ' '.join(clean_words)
    for keyword in keywords:
        if len(keyword) > 2 and keyword in clean_text and keyword not in matches:
            matches.add(f"{keyword}*")  # Asterisk indicates partial match
    
    return {
        'matches': sorted(matches),
        'stopwords': sorted(found_stopwords),
        'word_count': len(words),
        'clean_word_count': len(clean_words)
    }

def main():
    print("üîç Advanced Keyword Analyzer")
    print("===========================")
    
    # File input
    data_file = input("Enter main data file path: ")
    keywords_file = input("Enter keywords file path: ")
    
    try:
        # Load data
        df_data = pd.read_excel(data_file)
        df_keywords = pd.read_excel(keywords_file)
        
        # Column selection
        data_col = get_file_columns(df_data, "data")
        keyword_col = get_file_columns(df_keywords, "keywords")
        
        # Prepare keywords
        keywords = {str(k).lower() for k in df_keywords[keyword_col].dropna() if str(k).strip()}
        keywords = keywords - STOPWORDS  # Remove stopwords from keywords
        
        # Process data
        results = []
        stopword_stats = defaultdict(int)
        
        for _, row in df_data.iterrows():
            text = row[data_col]
            analysis = analyze_text(text, keywords)
            
            # Update statistics
            for sw in analysis['stopwords']:
                stopword_stats[sw] += 1
            
            results.append({
                'Original_Text': text,
                'Has_Match': bool(analysis['matches']),
                'Matches': ', '.join(analysis['matches']) if analysis['matches'] else None,
                'Stopwords_Found': ', '.join(analysis['stopwords']) if analysis['stopwords'] else None,
                'Match_Count': len(analysis['matches']),
                'Stopword_Count': len(analysis['stopwords']),
                'Word_Count': analysis['word_count'],
                'Clean_Word_Count': analysis['clean_word_count']
            })
        
        # Create output DataFrames
        df_results = pd.concat([
            df_data,
            pd.DataFrame(results)[['Has_Match', 'Matches', 'Stopwords_Found', 
                                  'Match_Count', 'Stopword_Count', 
                                  'Word_Count', 'Clean_Word_Count']]
        ], axis=1)
        
        df_stopwords = pd.DataFrame(
            sorted(stopword_stats.items(), key=lambda x: (-x[1], x[0])),
            columns=['Stopword', 'Frequency']
        )
        
        # Save outputs
        output_name = input("\nEnter output file base name (without extension): ")
        df_results.to_excel(f"{output_name}_results.xlsx", index=False)
        df_stopwords.to_excel(f"{output_name}_stopwords.xlsx", index=False)
        
        # Summary
        total_matches = df_results['Has_Match'].sum()
        match_rate = total_matches / len(df_results) * 100
        
        print("\nüìä Analysis Complete")
        print("===================")
        print(f"Processed {len(df_results)} records")
        print(f"Match rate: {match_rate:.1f}% ({total_matches} records)")
        print(f"Unique stopwords found: {len(df_stopwords)}")
        print(f"\nOutput files created:")
        print(f"- {output_name}_results.xlsx (Main results)")
        print(f"- {output_name}_stopwords.xlsx (Stopword statistics)")
        
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")

if __name__ == "__main__":
    main()
