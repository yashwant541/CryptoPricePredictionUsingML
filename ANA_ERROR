import pandas as pd
import dataiku
import tempfile
import os
import re
from datetime import datetime

# ------------------------------------------------------
# üîß Configuration ‚Äî Replace with your Dataiku folder IDs
# ------------------------------------------------------
input_folder = dataiku.Folder("XXXXXXXX")      # üì• Input folder
output_folder = dataiku.Folder("XXXXXXXX")    # üì§ Output folder

# List of sheet names to skip
EXCEPTION_SHEETS = [
    "Tracking Sheet", "FXO VOLS FBIL Realtime", "FXO VOLS Refinitiv Realtime"
]


# ------------------------------------------------------
# üß† Helper Functions
# ------------------------------------------------------
def looks_like_date(val):
    """Check if a value looks like a date"""
    if isinstance(val, (pd.Timestamp, datetime)):
        return True
    if isinstance(val, str):
        for fmt in ("%d-%b-%y", "%d-%b-%Y", "%Y-%m-%d", "%m/%d/%Y", "%m-%d-%Y"):
            try:
                datetime.strptime(val.strip(), fmt)
                return True
            except:
                continue
    return False


def read_excel_safe(file_path):
    """Read Excel using openpyxl engine for .xlsx"""
    return pd.ExcelFile(file_path, engine="openpyxl")


# ------------------------------------------------------
# üöÄ Main Execution
# ------------------------------------------------------
def main():
    input_files = input_folder.list_paths_in_partition()
    if not input_files:
        raise FileNotFoundError("‚ùå No files found in input folder!")

    for excel_file_info in input_files:
        file_name = os.path.basename(excel_file_info)

        # Download file to temporary location
        with input_folder.get_download_stream(excel_file_info) as stream:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp:
                tmp.write(stream.read())
                tmp_path = tmp.name

        xls = read_excel_safe(tmp_path)

        for sheet_name in xls.sheet_names:
            # Skip exception sheets
            if sheet_name in EXCEPTION_SHEETS:
                print(f"‚è© Skipping sheet '{sheet_name}' as it is in the exception list")
                continue

            print(f"\nüìÑ Processing sheet: {sheet_name}")
            df_raw = pd.read_excel(tmp_path, sheet_name=sheet_name, header=None, engine="openpyxl")

            # --- Detect Bid/Ask pattern ---
            header_row = df_raw.iloc[8:10].astype(str).apply(lambda x: x.str.lower())
            is_bid_ask = any(header_row.apply(lambda col: col.str.contains("bid").any() and col.str.contains("ask").any()))

            if is_bid_ask:
                print(f"üîπ Detected Bid/Ask format in sheet '{sheet_name}'")
                df_data = df_raw.iloc[9:].reset_index(drop=True)
                df_data.columns = df_raw.iloc[8].astype(str).str.strip()
                df_data = df_data.dropna(axis=1, how='all')

                # Identify Date, Bid, Ask columns
                date_col = next((c for c in df_data.columns if "date" in c.lower()), None)
                bid_col = next((c for c in df_data.columns if "bid" in c.lower()), None)
                ask_col = next((c for c in df_data.columns if "ask" in c.lower()), None)

                if not date_col or not bid_col or not ask_col:
                    print(f"‚ö†Ô∏è Skipping '{sheet_name}': missing Bid/Ask columns")
                    continue

                # Compute average
                df_data[bid_col] = pd.to_numeric(df_data[bid_col], errors='coerce')
                df_data[ask_col] = pd.to_numeric(df_data[ask_col], errors='coerce')
                df_data["Value"] = df_data[[bid_col, ask_col]].mean(axis=1)

                non_null_count = df_data["Value"].notna().sum()
                if non_null_count > 0:
                    sample = df_data["Value"].dropna().head(3).tolist()
                    print(f"‚úÖ Doing average of Bid and Ask for {non_null_count} rows.")
                    print(f"üí° Average value sample: {sample}")
                else:
                    print(f"‚ö†Ô∏è Found empty Bid/Ask values for '{sheet_name}'")

                # Pick Label from above (row 7)
                label_row = df_raw.iloc[6].dropna()
                label = str(label_row.iloc[0]) if not label_row.empty else sheet_name

                final_df = pd.DataFrame({
                    "Date": pd.to_datetime(df_data[date_col], errors='coerce'),
                    "Label": label,
                    "Value": df_data["Value"]
                })

            else:
                # Normal sheet (same as your existing logic)
                label_row_index = 6
                labels_row = df_raw.iloc[label_row_index]
                tidy_data_list = []

                for col in range(df_raw.shape[1]):
                    label = labels_row[col]
                    if pd.notna(label) and col + 1 < df_raw.shape[1]:
                        dates = df_raw.iloc[label_row_index + 1:, col]
                        values = df_raw.iloc[label_row_index + 1:, col + 1]
                        mask = dates.notna() & values.notna()
                        if mask.any():
                            temp_df = pd.DataFrame({
                                "Date": dates[mask],
                                "Label": label,
                                "Value": values[mask]
                            })
                            tidy_data_list.append(temp_df)

                if not tidy_data_list:
                    print(f"‚ö†Ô∏è No valid data found in sheet '{sheet_name}'")
                    continue

                final_df = pd.concat(tidy_data_list, ignore_index=True)
                final_df["Date"] = pd.to_datetime(final_df["Date"], errors='coerce')
                final_df = final_df.sort_values("Date").reset_index(drop=True)

            # Save output
            safe_sheet_name = "".join(c if c.isalnum() else "_" for c in sheet_name)
            out_name = f"{os.path.splitext(file_name)[0]}_{safe_sheet_name}.csv"
            with tempfile.NamedTemporaryFile(mode="w", suffix=".csv", delete=False, newline='', encoding="utf-8") as tmp_file:
                final_df.to_csv(tmp_file.name, index=False)
                with open(tmp_file.name, "rb") as f:
                    output_folder.upload_stream(out_name, f)
                os.remove(tmp_file.name)

            print(f"‚úÖ Sheet '{sheet_name}' saved as CSV: {out_name}")

        os.remove(tmp_path)
        print(f"‚úÖ Completed processing for file: {file_name}")


# ------------------------------------------------------
if __name__ == "__main__":
    main()
