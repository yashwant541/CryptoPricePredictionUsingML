import os
import re
import sys
import csv
import math
import shutil
import tempfile
from datetime import datetime
import dataiku
from fuzzywuzzy import fuzz
import base64

# -----------------------------
# Enhanced Configuration
# -----------------------------
class Config:
    SCORE_WEIGHTS = {
        'keyword_presence': 25,
        'semantic_patterns': 30,
        'temporal_position': 20,
        'conversation_flow': 15,
        'hierarchy_analysis': 10
    }
    
    CONFIDENCE_THRESHOLDS = {
        'very_high': 0.5,
        'high': 0.3,
        'medium': 0.2,
        'low': 0.0
    }

# Enhanced keyword dictionaries with weights
APPROVER_KEYWORDS = {
    "approved": 100, "granted": 95, "confirmed": 90, "accepted": 90,
    "authorized": 95, "approve": 80, "confirm": 80, "accept": 80,
    "approval": 50, "clearance": 70, "endorsed": 75, "signed off": 85,
    "cleared": 80, "validated": 85, "ratified": 90, "sanctioned": 90,
    "permission granted": 95, "fully supported": 85, "completely endorse": 80,
    "ok": 40, "yes": 40, "agreed": 70, "go ahead": 80
}

REQUESTER_KEYWORDS = {
    "request": 100, "require": 95, "seek approval": 90, "need approval": 90,
    "asking": 80, "petition": 75, "approval": 30, "pending": 60,
    "remind": 70, "follow up": 65, "submitted": 85, "application": 80,
    "awaiting": 75, "seeking": 85, "would like to request": 95,
    "please approve": 90, "kindly approve": 90, "require authorization": 85,
    "please review": 85, "need your input": 70, "looking for approval": 80, "requesting": 90
}

# -----------------------------
# Enhanced Helper Functions
# -----------------------------
def log(message):
    print(f"[LOG] {message}", file=sys.stderr, flush=True)

def clean_email_addresses(text):
    """Remove email addresses with leading whitespace from text"""
    pattern = r'\s*<[^>]*@[^>]*>'
    cleaned_text = re.sub(pattern, '', text)
    return cleaned_text

def split_emails(raw_text):
    parts = re.split(r"(?=^From: )", raw_text, flags=re.IGNORECASE | re.MULTILINE)
    if parts and not parts[0].strip().lower().startswith("from:"):
        first = parts.pop(0)
        parts = [first] + parts
    return parts

def extract_field(email, field):
    pattern = rf"{field}:(.*)"
    match = re.search(pattern, email, re.IGNORECASE)
    if match:
        field_content = match.group(1).strip()
        return clean_email_addresses(field_content)
    return ""

def parse_date_time(date_str):
    if not date_str:
        return None
    try:
        return datetime.strptime(date_str.strip(), "%A, %B %d, %Y %I:%M %p")
    except Exception:
        return None

def extract_body(email):
    split_point = re.search(r"\n\s*\n", email)
    body = email[split_point.end():].strip() if split_point else ""
    return clean_email_addresses(body)

def clean_participant_name(raw_name):
    if not raw_name:
        return ""
    cleaned = re.sub(r'\s*<[^>]*@[^>]*>', '', raw_name)
    cleaned = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '', cleaned)
    cleaned = re.sub(r'[;"\']', '', cleaned)
    cleaned = ' '.join(cleaned.split()).strip()
    cleaned = cleaned.rstrip(',')
    return cleaned

def find_matching_statement(email_body, keywords, threshold=80):
    sentences = re.split(r'(?<=[.!?])\s+', email_body.strip())
    exact_matches, fuzzy_matches = [], []
    for sentence in sentences:
        clean_sentence = sentence.lower()
        for kw in keywords:
            if kw in clean_sentence:
                exact_matches.append(sentence.strip())
            else:
                ratio = fuzz.partial_ratio(kw, clean_sentence)
                if ratio >= threshold:
                    fuzzy_matches.append((sentence.strip(), kw, ratio))
    if exact_matches:
        return "; ".join(exact_matches), "exact"
    elif fuzzy_matches:
        best_match = max(fuzzy_matches, key=lambda x: x[2])
        return best_match[0], "fuzzy"
    return "", ""

# -----------------------------
# Enhanced Linguistic Analysis
# -----------------------------
def extract_semantic_patterns(email_body):
    """Extract more sophisticated linguistic patterns"""
    patterns = {
        "explicit_approval": [
            r"(?:I\s+)?(?:hereby\s+)?approve(?:\s+the\s+request)?",
            r"(?:request|application)\s+(?:is\s+)?approved",
            r"grant(?:ed|ing)\s+(?:the\s+)?(?:request|permission)",
            r"fully\s+supported|completely\s+endorse"
        ],
        "conditional_approval": [
            r"approved\s+subject\s+to|conditional\s+approval",
            r"pending\s+[^.]*approval"
        ],
        "explicit_request": [
            r"(?:I\s+)?(?:would\s+like\s+to\s+)?request(?:\s+approval)?",
            r"seeking\s+(?:your\s+)?approval",
            r"please\s+approve|kindly\s+approve",
            r"require\s+(?:your\s+)?authorization",
            r"please\s+review"
        ],
        "delegated_authority": [
            r"on\s+behalf\s+of|acting\s+for",
            r"delegated\s+authority"
        ],
        "conditional_request": [
            r"if\s+you\s+could\s+approve",
            r"would\s+appreciate\s+approval",
            r"looking\s+forward\s+to\s+your\s+approval"
        ]
    }
    
    found_patterns = {}
    for pattern_type, regex_list in patterns.items():
        for regex in regex_list:
            if re.search(regex, email_body, re.IGNORECASE):
                found_patterns[pattern_type] = found_patterns.get(pattern_type, 0) + 1
    return found_patterns

# -----------------------------
# Enhanced Email Parsing
# -----------------------------
def parse_email_chain(text):
    email_chunks = split_emails(text)
    parsed = []
    
    for i, email in enumerate(email_chunks):
        try:
            sender = extract_field(email, "From")
            receiver = extract_field(email, "To")
            cc = extract_field(email, "Cc")
            bcc = extract_field(email, "Bcc")
            subject = extract_field(email, "Subject")
            date_raw = extract_field(email, "Sent")
            
            dt = parse_date_time(date_raw)
            date_str = dt.date().isoformat() if dt else ""
            time_str = dt.time().isoformat() if dt else ""
            
            body = extract_body(email)
            
            approval_statement, approval_type = find_matching_statement(body, APPROVER_KEYWORDS.keys())
            request_statement, request_type = find_matching_statement(body, REQUESTER_KEYWORDS.keys())
            
            semantic_patterns = extract_semantic_patterns(body)
            
            parsed.append({
                "Email Sequence": i + 1,
                "Sender": sender,
                "Receiver": receiver,
                "cc": cc,
                "bcc": bcc,
                "subject": subject,
                "email body": body,
                "approval statement": approval_statement or "",
                "approval match type": approval_type or "",
                "request statement": request_statement or "",
                "request match type": request_type or "",
                "semantic_patterns": str(semantic_patterns),
                "datetime": dt,
                "date": date_str,
                "time": time_str
            })
        except Exception as e:
            log(f"⚠️ Error parsing email {i+1}: {str(e)}")
            continue
    
    parsed = sorted(parsed, key=lambda x: x["datetime"] if x["datetime"] else datetime.min)
    
    for i, email in enumerate(parsed):
        email["Email Sequence"] = i + 1
    
    return parsed

def extract_all_participants(parsed_emails):
    participants = set()
    for email in parsed_emails:
        sender = clean_participant_name(email.get("Sender", ""))
        if sender: participants.add(sender)
        
        receiver_field = email.get("Receiver", "")
        receivers = [clean_participant_name(r) for r in receiver_field.split(',')] if receiver_field else []
        participants.update([r for r in receivers if r])
        
        cc_field = email.get("cc", "")
        cc = [clean_participant_name(c) for c in cc_field.split(',')] if cc_field else []
        participants.update([c for c in cc if c])
        
        bcc_field = email.get("bcc", "")
        bcc = [clean_participant_name(b) for b in bcc_field.split(',')] if bcc_field else []
        participants.update([b for b in bcc if b])
    return sorted(participants)

# -----------------------------
# Sequential Analysis Functions
# -----------------------------
def analyze_email_sequentially(parsed_emails):
    """
    Analyze emails sequentially from oldest to newest, tracking potential makers/checkers
    """
    # Sort emails by date to ensure chronological processing
    sorted_emails = sorted(parsed_emails, key=lambda x: x["datetime"] if x["datetime"] else datetime.min)
    
    # Track potential makers and checkers throughout the conversation
    potential_makers = {}
    potential_checkers = {}
    conversation_history = []
    
    for i, email in enumerate(sorted_emails):
        email_analysis = analyze_single_email(email, conversation_history, i, len(sorted_emails))
        conversation_history.append(email_analysis)
        
        # Update potential makers and checkers based on this email
        update_potential_roles(email_analysis, potential_makers, potential_checkers)
    
    # Determine final roles with conflict resolution
    final_maker, final_checker, resolution_method = determine_final_roles(potential_makers, potential_checkers)
    
    return {
        "conversation_history": conversation_history,
        "potential_makers": potential_makers,
        "potential_checkers": potential_checkers,
        "final_maker": final_maker,
        "final_checker": final_checker,
        "resolution_method": resolution_method
    }

def analyze_single_email(email, previous_history, current_index, total_emails):
    """
    Analyze a single email against all rules
    """
    sender = clean_participant_name(email.get("Sender", ""))
    receiver_field = email.get("Receiver", "")
    receivers = [clean_participant_name(r.strip()) for r in receiver_field.split(';') if r.strip()]
    
    analysis = {
        "date": email.get("date", ""),
        "time": email.get("time", ""),
        "datetime": email.get("datetime"),
        "sender": sender,
        "receivers": receivers,
        "email_sequence": email.get("Email Sequence", 0),
        "can_be_maker": False,
        "can_be_checker": False,
        "maker_score": 0,
        "checker_score": 0,
        "role_restrictions": [],
        "maker_keywords_found": [],
        "checker_keywords_found": [],
        "maker_semantic_patterns": [],
        "checker_semantic_patterns": []
    }
    
    # Rule 1: Basic Role Restrictions
    role_analysis = analyze_role_restrictions_single(sender, receivers, email)
    analysis["role_restrictions"] = role_analysis["restrictions"]
    analysis["can_be_maker"] = role_analysis["can_be_maker"]
    analysis["can_be_checker"] = role_analysis["can_be_checker"]
    
    if analysis["can_be_maker"]:
        maker_score, maker_details = calculate_maker_score_single(email, previous_history, current_index, total_emails)
        analysis["maker_score"] = maker_score
        analysis["maker_keywords_found"] = maker_details.get("keywords_found", [])
        analysis["maker_semantic_patterns"] = maker_details.get("semantic_patterns", [])
    
    if analysis["can_be_checker"]:
        checker_score, checker_details = calculate_checker_score_single(email, previous_history, current_index, total_emails)
        analysis["checker_score"] = checker_score
        analysis["checker_keywords_found"] = checker_details.get("keywords_found", [])
        analysis["checker_semantic_patterns"] = checker_details.get("semantic_patterns", [])
    
    return analysis

def analyze_role_restrictions_single(sender, receivers, email):
    """
    Determine if sender can be maker/checker based on role restrictions for single email
    """
    restrictions = []
    can_be_maker = True
    can_be_checker = True
    
    # Check if sender is only in CC/BCC (not in To field)
    cc_field = email.get("cc", "")
    bcc_field = email.get("bcc", "")
    cc_list = [clean_participant_name(c.strip()) for c in cc_field.split(';')] if cc_field else []
    bcc_list = [clean_participant_name(b.strip()) for b in bcc_field.split(';')] if bcc_field else []
    
    # If sender is only in CC/BCC and not in receivers, restrict roles
    if sender in cc_list and sender not in receivers:
        restrictions.append("CC-only participant")
        can_be_maker = False
        can_be_checker = False
    
    if sender in bcc_list and sender not in receivers:
        restrictions.append("BCC-only participant") 
        can_be_maker = False
        can_be_checker = False
    
    return {
        "restrictions": restrictions,
        "can_be_maker": can_be_maker,
        "can_be_checker": can_be_checker
    }

def calculate_maker_score_single(email, previous_history, current_index, total_emails):
    """
    Calculate maker score for this specific email
    """
    score = 0
    email_body = email.get("email body", "").lower()
    keywords_found = []
    semantic_patterns_found = []
    
    # Rule 1: Request Keywords
    for keyword, weight in REQUESTER_KEYWORDS.items():
        if keyword in email_body:
            score += weight
            keywords_found.append(f"{keyword}({weight})")
    
    # Rule 2: Semantic Patterns for Requests
    semantic_patterns = extract_semantic_patterns(email_body)
    if "explicit_request" in semantic_patterns:
        score += 80
        semantic_patterns_found.append("explicit_request")
    if "conditional_request" in semantic_patterns:
        score += 60
        semantic_patterns_found.append("conditional_request")
    
    # Rule 3: Temporal Position (first email gets bonus)
    if current_index == 0:  # This is the first email
        score += 100
    
    # Rule 4: Conversation Flow - Initiator pattern
    if is_conversation_initiator(current_index):
        score += 50
    
    return score, {
        "keywords_found": keywords_found,
        "semantic_patterns": semantic_patterns_found
    }

def calculate_checker_score_single(email, previous_history, current_index, total_emails):
    """
    Calculate checker score for this specific email
    """
    score = 0
    email_body = email.get("email body", "").lower()
    keywords_found = []
    semantic_patterns_found = []
    
    # Rule 1: Approval Keywords
    for keyword, weight in APPROVER_KEYWORDS.items():
        if keyword in email_body:
            score += weight
            keywords_found.append(f"{keyword}({weight})")
    
    # Rule 2: Semantic Patterns for Approval
    semantic_patterns = extract_semantic_patterns(email_body)
    if "explicit_approval" in semantic_patterns:
        score += 80
        semantic_patterns_found.append("explicit_approval")
    if "conditional_approval" in semantic_patterns:
        score += 60
        semantic_patterns_found.append("conditional_approval")
    if "delegated_authority" in semantic_patterns:
        score += 40
        semantic_patterns_found.append("delegated_authority")
    
    # Rule 3: Temporal Position (last email gets bonus)
    if current_index == total_emails - 1:  # Last email
        score += 100
    
    # Rule 4: Response to Request
    if is_responding_to_request_single(email, previous_history):
        score += 70
    
    # Rule 5: Hierarchy Indicators
    hierarchy_score = analyze_hierarchy_indicators_single(email_body)
    score += hierarchy_score
    
    return score, {
        "keywords_found": keywords_found,
        "semantic_patterns": semantic_patterns_found
    }

def is_conversation_initiator(current_index):
    return current_index == 0

def is_responding_to_request_single(email, previous_history):
    """Check if this email is responding to a previous request"""
    if not previous_history:
        return False
    
    for prev_analysis in previous_history[-3:]:
        if prev_analysis.get("maker_score", 0) > 50:
            return True
    return False

def analyze_hierarchy_indicators_single(email_body):
    """Analyze hierarchy indicators in email body"""
    score = 0
    superior_indicators = [
        "please review", "for your approval", "seeking your guidance", 
        "your decision", "awaiting your input", "kindly approve",
        "request your approval", "need your authorization"
    ]
    
    for indicator in superior_indicators:
        if indicator in email_body.lower():
            score += 20
    
    return min(score, 100)

def update_potential_roles(email_analysis, potential_makers, potential_checkers):
    """Update potential roles based on current email analysis"""
    sender = email_analysis["sender"]
    
    # Update potential makers
    if email_analysis["can_be_maker"] and email_analysis["maker_score"] > 0:
        if sender not in potential_makers:
            potential_makers[sender] = {
                "total_score": 0,
                "email_count": 0,
                "highest_score": 0,
                "average_score": 0
            }
        
        potential_makers[sender]["total_score"] += email_analysis["maker_score"]
        potential_makers[sender]["email_count"] += 1
        potential_makers[sender]["highest_score"] = max(
            potential_makers[sender]["highest_score"], 
            email_analysis["maker_score"]
        )
        potential_makers[sender]["average_score"] = potential_makers[sender]["total_score"] / potential_makers[sender]["email_count"]
    
    # Update potential checkers
    if email_analysis["can_be_checker"] and email_analysis["checker_score"] > 0:
        if sender not in potential_checkers:
            potential_checkers[sender] = {
                "total_score": 0,
                "email_count": 0,
                "highest_score": 0,
                "average_score": 0
            }
        
        potential_checkers[sender]["total_score"] += email_analysis["checker_score"]
        potential_checkers[sender]["email_count"] += 1
        potential_checkers[sender]["highest_score"] = max(
            potential_checkers[sender]["highest_score"], 
            email_analysis["checker_score"]
        )
        potential_checkers[sender]["average_score"] = potential_checkers[sender]["total_score"] / potential_checkers[sender]["email_count"]

def determine_final_roles(potential_makers, potential_checkers):
    """
    Determine final roles with conflict resolution when same person is top candidate for both
    """
    # Get top candidates for each role
    top_maker = get_top_candidate(potential_makers, 30)
    top_checker = get_top_candidate(potential_checkers, 30)
    
    # If different people, return them
    if top_maker != top_checker:
        return top_maker, top_checker, "different_participants"
    
    # If same person is top for both roles, resolve conflict
    if top_maker and top_maker == top_checker:
        return resolve_role_conflict(potential_makers, potential_checkers, top_maker)
    
    # If no clear candidates
    return None, None, "no_clear_candidates"

def get_top_candidate(candidates_dict, min_threshold):
    """Get top candidate from a dictionary of candidates"""
    if not candidates_dict:
        return None
    
    best_candidate = None
    best_score = 0
    
    for participant, data in candidates_dict.items():
        avg_score = data["average_score"]
        if avg_score > best_score and avg_score > min_threshold:
            best_candidate = participant
            best_score = avg_score
    
    return best_candidate

def resolve_role_conflict(potential_makers, potential_checkers, conflicted_person):
    """
    Resolve when the same person is top candidate for both maker and checker
    Uses HIGHEST single score for conflict resolution
    """
    maker_data = potential_makers.get(conflicted_person, {})
    checker_data = potential_checkers.get(conflicted_person, {})
    
    # Use HIGHEST score (peak performance) for conflict resolution
    maker_highest = maker_data.get("highest_score", 0)
    checker_highest = checker_data.get("highest_score", 0)
    
    # Assign the role where the person has the higher peak score
    if maker_highest >= checker_highest:
        # Person becomes maker, find next best checker
        final_maker = conflicted_person
        final_checker = get_second_best_candidate_by_highest(potential_checkers, conflicted_person, 30)
        resolution_method = f"conflict_resolution_maker_highest_peak({maker_highest:.1f} vs {checker_highest:.1f})"
    else:
        # Person becomes checker, find next best maker
        final_checker = conflicted_person
        final_maker = get_second_best_candidate_by_highest(potential_makers, conflicted_person, 30)
        resolution_method = f"conflict_resolution_checker_highest_peak({checker_highest:.1f} vs {maker_highest:.1f})"
    
    return final_maker, final_checker, resolution_method

def get_second_best_candidate_by_highest(candidates_dict, exclude_person, min_threshold):
    """Get second best candidate based on HIGHEST score excluding a specific person"""
    if not candidates_dict:
        return None
    
    best_candidate = None
    best_score = 0
    
    for participant, data in candidates_dict.items():
        if participant == exclude_person:
            continue
            
        highest_score = data.get("highest_score", 0)
        if highest_score > best_score and highest_score > min_threshold:
            best_candidate = participant
            best_score = highest_score
    
    return best_candidate

# -----------------------------
# WebApp Endpoints
# -----------------------------
def do(payload, config, plugin_config, inputs):
    """Main webapp endpoint"""
    return {"status": "ready"}

def do_parse_file(payload, config, plugin_config, inputs):
    """Endpoint to preview uploaded file content"""
    try:
        file_data = payload.get('file_data', '')
        file_name = payload.get('file_name', 'uploaded_file.txt')
        
        if not file_data:
            return {"error": "No file uploaded"}
        
        # Decode base64 file data
        if ',' in file_data:
            file_data = file_data.split(',')[1]
        
        file_content = base64.b64decode(file_data).decode('utf-8')
        
        # Clean and parse emails for preview
        email_text = clean_email_addresses(file_content)
        parsed_emails = parse_email_chain(email_text)
        
        if not parsed_emails:
            return {"error": "No emails could be parsed from the uploaded file"}
        
        participants = extract_all_participants(parsed_emails)
        
        return {
            "success": True,
            "file_name": file_name,
            "file_size": len(file_content),
            "parsed_emails_count": len(parsed_emails),
            "participants": list(participants),
            "email_preview": [{
                "sequence": email["Email Sequence"],
                "sender": email["Sender"],
                "receivers": email["Receiver"],
                "subject": email["subject"],
                "date": email["date"],
                "body_preview": (email["email body"][:100] + "...") if len(email["email body"]) > 100 else email["email body"]
            } for email in parsed_emails[:3]]
        }
        
    except Exception as e:
        return {"error": f"File parsing failed: {str(e)}"}

def do_analyze_emails(payload, config, plugin_config, inputs):
    """Endpoint to perform full analysis from uploaded file"""
    try:
        # Get the uploaded file data
        file_data = payload.get('file_data', '')
        file_name = payload.get('file_name', 'uploaded_file.txt')
        
        if not file_data:
            return {"error": "No file uploaded"}
        
        # Decode base64 file data
        if ',' in file_data:
            file_data = file_data.split(',')[1]
        
        file_content = base64.b64decode(file_data).decode('utf-8')
        
        # Clean and parse emails
        email_text = clean_email_addresses(file_content)
        parsed_emails = parse_email_chain(email_text)
        
        if not parsed_emails:
            return {"error": "No emails could be parsed from the uploaded file"}
        
        # Perform sequential analysis
        sequential_analysis = analyze_email_sequentially(parsed_emails)
        
        # Format results for web display
        results = format_results_for_web(sequential_analysis, parsed_emails)
        
        return {
            "success": True,
            "results": results,
            "file_name": file_name
        }
        
    except Exception as e:
        return {"error": f"Analysis failed: {str(e)}"}

def format_results_for_web(analysis, parsed_emails):
    """Format analysis results for web display"""
    return {
        "final_maker": analysis["final_maker"] or "Not identified",
        "final_checker": analysis["final_checker"] or "Not identified",
        "resolution_method": analysis.get("resolution_method", "standard"),
        "stats": {
            "total_emails": len(parsed_emails),
            "total_participants": len(extract_all_participants(parsed_emails)),
            "potential_makers_count": len(analysis["potential_makers"]),
            "potential_checkers_count": len(analysis["potential_checkers"])
        },
        "potential_makers": [
            {
                "participant": participant,
                "average_score": round(data["average_score"], 1),
                "highest_score": round(data["highest_score"], 1),
                "email_count": data["email_count"]
            }
            for participant, data in analysis["potential_makers"].items()
        ],
        "potential_checkers": [
            {
                "participant": participant,
                "average_score": round(data["average_score"], 1),
                "highest_score": round(data["highest_score"], 1),
                "email_count": data["email_count"]
            }
            for participant, data in analysis["potential_checkers"].items()
        ],
        "email_analysis": [
            {
                "sequence": email_analysis["email_sequence"],
                "sender": email_analysis["sender"],
                "date": email_analysis["date"],
                "time": email_analysis["time"],
                "maker_score": round(email_analysis["maker_score"], 1),
                "checker_score": round(email_analysis["checker_score"], 1),
                "can_be_maker": email_analysis["can_be_maker"],
                "can_be_checker": email_analysis["can_be_checker"],
                "receivers": ", ".join(email_analysis["receivers"])
            }
            for email_analysis in analysis["conversation_history"]
        ]
    }
