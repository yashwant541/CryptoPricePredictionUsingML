import re
import os
import sys
import shutil
import tempfile
import pandas as pd
import dataiku
from openpyxl import load_workbook

# -----------------------------
# Fixed Dataiku Folder Handles
# -----------------------------
input_folder = dataiku.Folder("Tw4EvbUb")        # üìÇ Replace with your input folder ID
output_folder_tables = dataiku.Folder("pwBGEpop")   # üìÇ Replace with your output folder ID for tables
output_folder_summary = dataiku.Folder("PwHZQ7jA")  # üìÇ Replace with your output folder ID for summary CSV

# -----------------------------
# Logging Helper
# -----------------------------
def log(message):
    print(f"[LOG] {message}", file=sys.stderr, flush=True)

# -----------------------------
# Utility Functions
# -----------------------------
def extract_date_from_filename(filename):
    """Extract date pattern like 01-Aug-25"""
    match = re.search(r'\d{2}-[A-Za-z]{3}-\d{2}', filename)
    return match.group(0) if match else ""

def read_excel_tab(filepath):
    """Read 'Excel Tab' sheet and split into main table + maker-checker summary"""
    wb = load_workbook(filepath, data_only=True)
    sheet_name = None

    # Try to find sheet named similar to "Excel Tab"
    for name in wb.sheetnames:
        if re.search(r'excel[_ ]?tab', name, re.IGNORECASE):
            sheet_name = name
            break

    if not sheet_name:
        log("‚ö†Ô∏è 'Excel Tab' not found in workbook.")
        return None, None

    ws = wb[sheet_name]
    data_rows = []
    summary_rows = []
    found_summary = False

    # Split main table and summary area
    for row in ws.iter_rows(values_only=True):
        if not found_summary:
            # Detect start of summary by presence of "USER:" or "Benchmark:" text
            row_text = " ".join([str(c) for c in row if c]).strip()
            if any(x in row_text for x in ["USER:", "Benchmark:", "Status", "Date:"]):
                found_summary = True
                summary_rows.append(row)
            else:
                data_rows.append(row)
        else:
            summary_rows.append(row)

    # Filter out empty rows from table
    data_rows = [r for r in data_rows if any(r)]
    if not data_rows:
        return None, None

    df_table = pd.DataFrame(data_rows[1:], columns=data_rows[0])

    # Parse maker-checker summary
    summary_texts = [" ".join([str(c) for c in row if c]).strip() for row in summary_rows if any(row)]
    metadata = []
    current = {}

    for line in summary_texts:
        if "USER:" in line:
            if current:
                metadata.append(current)
                current = {}
            current["USER"] = line.split("USER:")[1].strip()

        elif "Benchmark:" in line:
            current["Benchmark"] = line.split("Benchmark:")[1].strip()

        elif re.search(r"\bDate[:\s]", line):
            date_val = line.split("Date:")[1].strip() if "Date:" in line else ""
            current["Date (in file)"] = date_val

        elif line.startswith("Status "):
            current["Status"] = line.replace("Status", "").strip()

        elif "Status Time" in line:
            current["Status Time"] = line.replace("Status Time", "").strip()

    if current:
        metadata.append(current)

    return df_table, metadata

# -----------------------------
# Main Processing
# -----------------------------
def main():
    try:
        log("üîç Scanning top-level of input folder for ORIGAMI Excel files...")

        all_files = input_folder.list_paths_in_partition()
        excel_files = [
            f for f in all_files
            if "/" not in f.strip("/")  # ensures top-level only
            and os.path.basename(f).startswith("ORIGAMI")
            and f.lower().endswith((".xlsx", ".xls"))
        ]

        if not excel_files:
            raise Exception("‚ùå No ORIGAMI Excel files found in the top level of the input folder.")

        summary_records = []

        for path in excel_files:
            file_name = os.path.basename(path)
            log(f"üìÑ Processing: {file_name}")

            # Download to temporary file
            with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_file:
                tmp_file_path = tmp_file.name
                with input_folder.get_download_stream(path) as stream:
                    shutil.copyfileobj(stream, tmp_file)

            # Extract date from filename
            file_date = extract_date_from_filename(file_name)

            # Parse Excel
            df_table, metadata_list = read_excel_tab(tmp_file_path)
            os.remove(tmp_file_path)

            if df_table is None:
                log(f"‚ö†Ô∏è Skipped {file_name}: No valid 'Excel Tab' or table found.")
                continue

            # Save main table to output folder
            with tempfile.NamedTemporaryFile(suffix=".xlsx", delete=False) as tmp_out:
                df_table.to_excel(tmp_out.name, index=False)
                out_name = file_name.replace(".xlsx", "_table.xlsx")
                with open(tmp_out.name, "rb") as f_out:
                    output_folder_tables.upload_stream(out_name, f_out)
                os.remove(tmp_out.name)
                log(f"‚úÖ Saved table: {out_name}")

            # Add metadata info to summary
            if metadata_list:
                for meta in metadata_list:
                    summary_records.append({
                        "FileName": file_name,
                        "FileDate": file_date,
                        "USER": meta.get("USER", ""),
                        "Benchmark": meta.get("Benchmark", ""),
                        "Date (in file)": meta.get("Date (in file)", ""),
                        "Status": meta.get("Status", ""),
                        "Status Time": meta.get("Status Time", "")
                    })
            else:
                summary_records.append({
                    "FileName": file_name,
                    "FileDate": file_date,
                    "USER": "", "Benchmark": "", "Date (in file)": "",
                    "Status": "", "Status Time": ""
                })

        # Save summary CSV
        if summary_records:
            df_summary = pd.DataFrame(summary_records)
            with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8', newline='') as tmp_csv:
                df_summary.to_csv(tmp_csv.name, index=False)
                csv_name = "maker_checker_summary.csv"
                with open(tmp_csv.name, 'rb') as f:
                    output_folder_summary.upload_stream(csv_name, f)
                os.remove(tmp_csv.name)
            log(f"‚úÖ Summary written to {csv_name} ({len(summary_records)} rows)")
        else:
            log("‚ö†Ô∏è No metadata found to include in summary.")

    except Exception as e:
        log(f"üî• ERROR: {str(e)}")
        raise

# -----------------------------
# Entrypoint
# -----------------------------
if __name__ == "__main__":
    main()
