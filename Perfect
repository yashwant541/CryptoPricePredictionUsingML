Is this correct backend code - complete ? import os
import re
import sys
import csv
import math
import shutil
import tempfile
from datetime import datetime
import dataiku
from fuzzywuzzy import fuzz

# -----------------------------
# Enhanced Configuration
# -----------------------------
class Config:
    SCORE_WEIGHTS = {
        'keyword_presence': 25,
        'semantic_patterns': 30,
        'temporal_position': 20,
        'conversation_flow': 15,
        'hierarchy_analysis': 10
    }
    
    CONFIDENCE_THRESHOLDS = {
        'very_high': 0.5,
        'high': 0.3,
        'medium': 0.2,
        'low': 0.0
    }

# Enhanced keyword dictionaries with weights
APPROVER_KEYWORDS = {
    "approved": 100, "granted": 95, "confirmed": 90, "accepted": 90,
    "authorized": 95, "approve": 80, "confirm": 80, "accept": 80,
    "approval": 50, "clearance": 70, "endorsed": 75, "signed off": 85,
    "cleared": 80, "validated": 85, "ratified": 90, "sanctioned": 90,
    "permission granted": 95, "fully supported": 85, "completely endorse": 80
}

REQUESTER_KEYWORDS = {
    "request": 100, "require": 95, "seek approval": 90, "need approval": 90,
    "asking": 80, "petition": 75, "approval": 30, "pending": 60,
    "remind": 70, "follow up": 65, "submitted": 85, "application": 80,
    "awaiting": 75, "seeking": 85, "would like to request": 95,
    "please approve": 90, "kindly approve": 90, "require authorization": 85
}

# -----------------------------
# Enhanced Helper Functions
# -----------------------------
def log(message):
    print(f"[LOG] {message}", file=sys.stderr, flush=True)

def clean_email_addresses(text):
    """Remove email addresses with leading whitespace from text"""
    # More comprehensive pattern to match any email address within <>
    pattern = r'\s*<[^>]*@[^>]*>'
    cleaned_text = re.sub(pattern, '', text)
    return cleaned_text

def split_emails(raw_text):
    parts = re.split(r"(?=^From: )", raw_text, flags=re.IGNORECASE | re.MULTILINE)
    if parts and not parts[0].strip().lower().startswith("from:"):
        first = parts.pop(0)
        parts = [first] + parts
    return parts

def extract_field(email, field):
    pattern = rf"{field}:(.*)"
    match = re.search(pattern, email, re.IGNORECASE)
    if match:
        field_content = match.group(1).strip()
        # Clean email addresses from the field content
        return clean_email_addresses(field_content)
    return ""

def parse_date_time(date_str):
    if not date_str:
        return None
    try:
        return datetime.strptime(date_str.strip(), "%A, %B %d, %Y %I:%M %p")
    except Exception:
        return None

def extract_body(email):
    split_point = re.search(r"\n\s*\n", email)
    body = email[split_point.end():].strip() if split_point else ""
    # Clean email addresses from the body as well
    return clean_email_addresses(body)

def clean_participant_name(raw_name):
    if not raw_name:
        return ""
    
    # First remove email addresses with the pattern you specified
    # More comprehensive email removal
    cleaned = re.sub(r'\s*<[^>]*@[^>]*>', '', raw_name)  # Remove <email> patterns
    cleaned = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '', cleaned)  # Remove standalone emails
    cleaned = re.sub(r'[;"\']', '', cleaned)  # Remove special characters
    cleaned = ' '.join(cleaned.split()).strip()  # Normalize whitespace
    cleaned = cleaned.rstrip(',')  # Remove trailing commas
    
    return cleaned

def find_matching_statement(email_body, keywords, threshold=80):
    sentences = re.split(r'(?<=[.!?])\s+', email_body.strip())
    exact_matches, fuzzy_matches = [], []
    for sentence in sentences:
        clean_sentence = sentence.lower()
        for kw in keywords:
            if kw in clean_sentence:
                exact_matches.append(sentence.strip())
            else:
                ratio = fuzz.partial_ratio(kw, clean_sentence)
                if ratio >= threshold:
                    fuzzy_matches.append((sentence.strip(), kw, ratio))
    if exact_matches:
        return "; ".join(exact_matches), "exact"
    elif fuzzy_matches:
        best_match = max(fuzzy_matches, key=lambda x: x[2])
        return best_match[0], "fuzzy"
    return "", ""

# -----------------------------
# Enhanced Linguistic Analysis
# -----------------------------
def extract_semantic_patterns(email_body):
    """Extract more sophisticated linguistic patterns"""
    patterns = {
        "explicit_approval": [
            r"(?:I\s+)?(?:hereby\s+)?approve(?:\s+the\s+request)?",
            r"(?:request|application)\s+(?:is\s+)?approved",
            r"grant(?:ed|ing)\s+(?:the\s+)?(?:request|permission)",
            r"fully\s+supported|completely\s+endorse"
        ],
        "conditional_approval": [
            r"approved\s+subject\s+to|conditional\s+approval",
            r"pending\s+[^.]*approval"
        ],
        "explicit_request": [
            r"(?:I\s+)?(?:would\s+like\s+to\s+)?request(?:\s+approval)?",
            r"seeking\s+(?:your\s+)?approval",
            r"please\s+approve|kindly\s+approve",
            r"require\s+(?:your\s+)?authorization"
        ],
        "delegated_authority": [
            r"on\s+behalf\s+of|acting\s+for",
            r"delegated\s+authority"
        ]
    }
    
    found_patterns = {}
    for pattern_type, regex_list in patterns.items():
        for regex in regex_list:
            if re.search(regex, email_body, re.IGNORECASE):
                found_patterns[pattern_type] = found_patterns.get(pattern_type, 0) + 1
    
    return found_patterns

# -----------------------------
# Enhanced Conversation Flow Analysis
# -----------------------------
def analyze_conversation_flow(parsed_emails):
    """Analyze the flow and structure of the conversation"""
    flow_analysis = {
        "initiator": "",
        "finalizer": "",
        "turn_taking": {},
        "response_times": [],
        "dominant_speakers": []
    }
    
    if not parsed_emails:
        return flow_analysis
    
    # Identify initiator and finalizer
    flow_analysis["initiator"] = clean_participant_name(parsed_emails[0].get("Sender", ""))
    flow_analysis["finalizer"] = clean_participant_name(parsed_emails[-1].get("Sender", ""))
    
    # Analyze turn-taking patterns
    speakers = []
    for email in parsed_emails:
        sender = clean_participant_name(email.get("Sender", ""))
        speakers.append(sender)
        flow_analysis["turn_taking"][sender] = flow_analysis["turn_taking"].get(sender, 0) + 1
    
    # Calculate response times
    for i in range(1, len(parsed_emails)):
        if parsed_emails[i].get("datetime") and parsed_emails[i-1].get("datetime"):
            response_time = (parsed_emails[i]["datetime"] - parsed_emails[i-1]["datetime"]).total_seconds() / 3600  # hours
            flow_analysis["response_times"].append({
                "responder": clean_participant_name(parsed_emails[i].get("Sender", "")),
                "response_time_hours": response_time,
                "previous_sender": clean_participant_name(parsed_emails[i-1].get("Sender", ""))
            })
    
    # Identify dominant speakers (more than 30% of emails)
    total_emails = len(parsed_emails)
    flow_analysis["dominant_speakers"] = [
        speaker for speaker, count in flow_analysis["turn_taking"].items()
        if count / total_emails > 0.3
    ]
    
    return flow_analysis

# -----------------------------
# Hierarchy and Authority Detection
# -----------------------------
def detect_organizational_hierarchy(parsed_emails, participants):
    """Use linguistic cues to infer hierarchy"""
    hierarchy_indicators = {
        "superior_indicators": [
            r"reporting\s+to", "my\s+team", "my\s+department",
            r"please\s+review", "for\s+your\s+approval", "seeking\s+your\s+guidance",
            r"your\s+decision", "awaiting\s+your\s+input"
        ],
        "subordinate_indicators": [
            r"as\s+you\s+requested", "per\s+your\s+instruction",
            r"following\s+up", "awaiting\s+your\s+decision",
            r"will\s+implement", "as\s+directed"
        ],
        "formal_address": [
            r"dear\s+(mr|mrs|ms|dr)\.?\s+[A-Z]", "respectfully",
            r"yours\s+sincerely", "best\s+regards"
        ]
    }
    
    hierarchy_scores = {participant: {"maker": 0, "checker": 0} for participant in participants}
    
    for email in parsed_emails:
        sender = clean_participant_name(email.get("Sender", ""))
        if not sender: continue
        
        # Safe access to email body
        body_lower = email.get("email body", "").lower()
        
        # Superior indicators in emails sent by this person
        for indicator in hierarchy_indicators["superior_indicators"]:
            if re.search(indicator, body_lower):
                hierarchy_scores[sender]["checker"] += 2
        
        # Subordinate indicators reduce hierarchy score (more likely to be maker)
        for indicator in hierarchy_indicators["subordinate_indicators"]:
            if re.search(indicator, body_lower):
                hierarchy_scores[sender]["maker"] += 1
    
    return hierarchy_scores

# -----------------------------
# Contextual Analysis
# -----------------------------
def analyze_email_context(parsed_emails):
    """Analyze contextual factors that influence role identification"""
    context = {
        "urgency_indicators": 0,
        "formality_level": "medium",
        "decision_complexity": "medium",
        "multi_party_negotiation": False,
        "total_participants": 0
    }
    
    urgency_keywords = ["urgent", "asap", "immediate", "deadline", "time-sensitive"]
    formal_keywords = ["respectfully", "sincerely", "dear", "regards", "cordially"]
    informal_keywords = ["thanks", "cheers", "hi", "hello", "hey"]
    
    total_emails = len(parsed_emails)
    formal_count = 0
    informal_count = 0
    urgency_count = 0
    
    for email in parsed_emails:
        body_lower = email.get("email body", "").lower()
        
        # Urgency analysis
        for word in urgency_keywords:
            if word in body_lower:
                urgency_count += 1
                break
        
        # Formality analysis
        for word in formal_keywords:
            if word in body_lower:
                formal_count += 1
                break
        
        for word in informal_keywords:
            if word in body_lower:
                informal_count += 1
                break
    
    participants = extract_all_participants(parsed_emails)
    
    context["urgency_indicators"] = urgency_count / total_emails if total_emails > 0 else 0
    context["formality_level"] = "high" if formal_count > informal_count else "low" if informal_count > formal_count else "medium"
    context["multi_party_negotiation"] = len(participants) > 3
    context["total_participants"] = len(participants)
    
    return context

# -----------------------------
# Participant Role Analysis
# -----------------------------
def analyze_participant_roles(parsed_emails):
    """Analyze each participant's role throughout the email chain"""
    participants = {}
    
    for email in parsed_emails:
        email_sequence = email.get("Email Sequence", 0)
        
        # Track sender
        sender = clean_participant_name(email.get("Sender", ""))
        if sender:
            if sender not in participants:
                participants[sender] = {
                    "Total_Emails": 0, "As_Sender": 0, "As_Receiver": 0, 
                    "As_CC": 0, "As_BCC": 0, "First_Email_Sender": False,
                    "First_Email_Receiver": False, "Email_Sequences": []
                }
            participants[sender]["As_Sender"] += 1
            participants[sender]["Total_Emails"] += 1
            participants[sender]["Email_Sequences"].append(email_sequence)
            
            # Check if first email sender
            if email_sequence == 1:
                participants[sender]["First_Email_Sender"] = True
        
        # Track receivers (To field)
        receiver_field = email.get("Receiver", "")
        receivers = [clean_participant_name(r) for r in receiver_field.split(',') if receiver_field]
        for receiver in receivers:
            if receiver:
                if receiver not in participants:
                    participants[receiver] = {
                        "Total_Emails": 0, "As_Sender": 0, "As_Receiver": 0, 
                        "As_CC": 0, "As_BCC": 0, "First_Email_Sender": False,
                        "First_Email_Receiver": False, "Email_Sequences": []
                    }
                participants[receiver]["As_Receiver"] += 1
                participants[receiver]["Total_Emails"] += 1
                participants[receiver]["Email_Sequences"].append(email_sequence)
                
                # Check if first email receiver
                if email_sequence == 1:
                    participants[receiver]["First_Email_Receiver"] = True
        
        # Track CC participants
        cc_field = email.get("cc", "")
        cc_list = [clean_participant_name(c) for c in cc_field.split(',')] if cc_field else []
        for cc_person in cc_list:
            if cc_person:
                if cc_person not in participants:
                    participants[cc_person] = {
                        "Total_Emails": 0, "As_Sender": 0, "As_Receiver": 0, 
                        "As_CC": 0, "As_BCC": 0, "First_Email_Sender": False,
                        "First_Email_Receiver": False, "Email_Sequences": []
                    }
                participants[cc_person]["As_CC"] += 1
                participants[cc_person]["Total_Emails"] += 1
                participants[cc_person]["Email_Sequences"].append(email_sequence)
        
        # Track BCC participants
        bcc_field = email.get("bcc", "")
        bcc_list = [clean_participant_name(b) for b in bcc_field.split(',')] if bcc_field else []
        for bcc_person in bcc_list:
            if bcc_person:
                if bcc_person not in participants:
                    participants[bcc_person] = {
                        "Total_Emails": 0, "As_Sender": 0, "As_Receiver": 0, 
                        "As_CC": 0, "As_BCC": 0, "First_Email_Sender": False,
                        "First_Email_Receiver": False, "Email_Sequences": []
                    }
                participants[bcc_person]["As_BCC"] += 1
                participants[bcc_person]["Total_Emails"] += 1
                participants[bcc_person]["Email_Sequences"].append(email_sequence)
    
    return participants

def extract_participants_with_roles(parsed_emails):
    """Extract participants with their roles in the conversation"""
    participants = {}
    
    for email in parsed_emails:
        # Sender
        sender = clean_participant_name(email.get("Sender", ""))
        if sender and sender not in participants:
            participants[sender] = {"roles": set(["sender"]), "first_sender": False, "first_receiver": False}
        
        # Mark first sender
        if email.get("Email Sequence", 0) == 1 and sender in participants:
            participants[sender]["first_sender"] = True
        
        # Direct receivers (To field)
        receiver_field = email.get("Receiver", "")
        receivers = [clean_participant_name(r) for r in receiver_field.split(',')] if receiver_field else []
        for receiver in receivers:
            if receiver and receiver not in participants:
                participants[receiver] = {"roles": set(["receiver"]), "first_sender": False, "first_receiver": False}
            elif receiver in participants:
                participants[receiver]["roles"].add("receiver")
            
            # Mark first receiver
            if email.get("Email Sequence", 0) == 1 and receiver in participants:
                participants[receiver]["first_receiver"] = True
        
        # CC participants
        cc_field = email.get("cc", "")
        cc_list = [clean_participant_name(c) for c in cc_field.split(',')] if cc_field else []
        for cc_person in cc_list:
            if cc_person and cc_person not in participants:
                participants[cc_person] = {"roles": set(["cc"]), "first_sender": False, "first_receiver": False}
            elif cc_person in participants:
                participants[cc_person]["roles"].add("cc")
        
        # BCC participants
        bcc_field = email.get("bcc", "")
        bcc_list = [clean_participant_name(b) for b in bcc_field.split(',')] if bcc_field else []
        for bcc_person in bcc_list:
            if bcc_person and bcc_person not in participants:
                participants[bcc_person] = {"roles": set(["bcc"]), "first_sender": False, "first_receiver": False}
            elif bcc_person in participants:
                participants[bcc_person]["roles"].add("bcc")
    
    return participants

def calculate_role_restrictions(participants_with_roles):
    """Apply restrictions based on participant roles"""
    restrictions = {}
    
    for participant, data in participants_with_roles.items():
        roles = data["roles"]
        restrictions[participant] = {
            "can_be_maker": True,
            "can_be_checker": True,
            "restriction_reason": ""
        }
        
        # CC/BCC only participants cannot be maker or checker
        if roles == {"cc"} or roles == {"bcc"}:
            restrictions[participant]["can_be_maker"] = False
            restrictions[participant]["can_be_checker"] = False
            restrictions[participant]["restriction_reason"] = "CC/BCC only participant"
        
        # First sender bonus for maker
        if data["first_sender"]:
            restrictions[participant]["maker_bonus"] = 50
            if restrictions[participant]["restriction_reason"]:
                restrictions[participant]["restriction_reason"] += " | First sender"
            else:
                restrictions[participant]["restriction_reason"] = "First sender"
        
        # First receiver bonus for checker
        if data["first_receiver"]:
            restrictions[participant]["checker_bonus"] = 50
            if restrictions[participant]["restriction_reason"]:
                restrictions[participant]["restriction_reason"] += " | First receiver"
            else:
                restrictions[participant]["restriction_reason"] = "First receiver"
    
    return restrictions

# -----------------------------
# Enhanced Scoring Engine (FIXED)
# -----------------------------
class AdvancedScoringEngine:
    def __init__(self):
        self.weights = Config.SCORE_WEIGHTS
    
    def _calculate_keyword_scores(self, parsed_emails):
        """Calculate scores based on keyword presence"""
        participants = extract_all_participants(parsed_emails)
        scores = {p: {"maker": 0, "checker": 0} for p in participants}
        
        for email in parsed_emails:
            sender = clean_participant_name(email.get("Sender", ""))
            if not sender: continue
            
            # Approval keywords - with safe access
            approval_statement = email.get("approval_statement", "")
            if approval_statement:
                for keyword, weight in APPROVER_KEYWORDS.items():
                    if keyword in approval_statement.lower():
                        scores[sender]["checker"] += weight
                        break
            
            # Request keywords - with safe access
            request_statement = email.get("request_statement", "")
            if request_statement:
                for keyword, weight in REQUESTER_KEYWORDS.items():
                    if keyword in request_statement.lower():
                        scores[sender]["maker"] += weight
                        break
        
        return scores
    
    def _calculate_semantic_scores(self, parsed_emails):
        """Calculate scores based on semantic patterns"""
        participants = extract_all_participants(parsed_emails)
        scores = {p: {"maker": 0, "checker": 0} for p in participants}
        
        for email in parsed_emails:
            sender = clean_participant_name(email.get("Sender", ""))
            if not sender: continue
            
            # Safe access to email body
            email_body = email.get("email body", "")
            patterns = extract_semantic_patterns(email_body)
            
            # Semantic pattern scoring
            if "explicit_approval" in patterns:
                scores[sender]["checker"] += 80
            if "conditional_approval" in patterns:
                scores[sender]["checker"] += 60
            if "explicit_request" in patterns:
                scores[sender]["maker"] += 80
            if "delegated_authority" in patterns:
                scores[sender]["checker"] += 40
        
        return scores
    
    def _calculate_temporal_scores(self, parsed_emails):
        """Calculate scores based on temporal position"""
        participants = extract_all_participants(parsed_emails)
        scores = {p: {"maker": 0, "checker": 0} for p in participants}
        total_emails = len(parsed_emails)
        
        for i, email in enumerate(parsed_emails):
            sender = clean_participant_name(email.get("Sender", ""))
            if not sender: continue
            
            # First email gets high maker score
            if i == 0:
                scores[sender]["maker"] += 100
            
            # Last email gets high checker score
            if i == total_emails - 1:
                scores[sender]["checker"] += 100
            
            # Middle positions get weighted scores
            pos_weight_maker = max(0, 1 - i / total_emails) * 50
            pos_weight_checker = min(1, i / total_emails) * 50
            
            scores[sender]["maker"] += pos_weight_maker
            scores[sender]["checker"] += pos_weight_checker
        
        return scores
    
    def _calculate_flow_scores(self, parsed_emails):
        """Calculate scores based on conversation flow"""
        participants = extract_all_participants(parsed_emails)
        scores = {p: {"maker": 0, "checker": 0} for p in participants}
        flow_analysis = analyze_conversation_flow(parsed_emails)
        
        # Initiator gets maker points
        if flow_analysis["initiator"] in scores:
            scores[flow_analysis["initiator"]]["maker"] += 80
        
        # Finalizer gets checker points
        if flow_analysis["finalizer"] in scores:
            scores[flow_analysis["finalizer"]]["checker"] += 80
        
        # Dominant speakers get checker points (they control conversation)
        for speaker in flow_analysis["dominant_speakers"]:
            if speaker in scores:
                scores[speaker]["checker"] += 30
        
        return scores
    
    def _calculate_hierarchy_scores(self, parsed_emails, participants):
        """Calculate scores based on hierarchy detection"""
        hierarchy_scores = detect_organizational_hierarchy(parsed_emails, participants)
        return hierarchy_scores
    
    def calculate_comprehensive_scores(self, parsed_emails):
        participants = extract_all_participants(parsed_emails)
        scores = {p: {"maker": 0, "checker": 0, "breakdown": {}} for p in participants}
        
        # Calculate all score components
        keyword_scores = self._calculate_keyword_scores(parsed_emails)
        semantic_scores = self._calculate_semantic_scores(parsed_emails)
        temporal_scores = self._calculate_temporal_scores(parsed_emails)
        flow_scores = self._calculate_flow_scores(parsed_emails)
        hierarchy_scores = self._calculate_hierarchy_scores(parsed_emails, participants)
        
        # Combine all scores with weights
        for participant in participants:
            # Normalize and combine scores
            maker_score = (
                keyword_scores[participant]["maker"] * self.weights['keyword_presence'] +
                semantic_scores[participant]["maker"] * self.weights['semantic_patterns'] +
                temporal_scores[participant]["maker"] * self.weights['temporal_position'] +
                flow_scores[participant]["maker"] * self.weights['conversation_flow'] +
                hierarchy_scores[participant]["maker"] * self.weights['hierarchy_analysis']
            ) / sum(self.weights.values())
            
            checker_score = (
                keyword_scores[participant]["checker"] * self.weights['keyword_presence'] +
                semantic_scores[participant]["checker"] * self.weights['semantic_patterns'] +
                temporal_scores[participant]["checker"] * self.weights['temporal_position'] +
                flow_scores[participant]["checker"] * self.weights['conversation_flow'] +
                hierarchy_scores[participant]["checker"] * self.weights['hierarchy_analysis']
            ) / sum(self.weights.values())
            
            scores[participant]["maker"] = maker_score
            scores[participant]["checker"] = checker_score
            
            # Store breakdown for transparency
            scores[participant]["breakdown"] = {
                "keyword": keyword_scores[participant],
                "semantic": semantic_scores[participant],
                "temporal": temporal_scores[participant],
                "flow": flow_scores[participant],
                "hierarchy": hierarchy_scores[participant]
            }
        
        return scores

# -----------------------------
# Enhanced Decision Confidence Scoring
# -----------------------------
def calculate_decision_confidence(maker, checker, scores, parsed_emails):
    """Calculate how confident we are in the maker-checker identification"""
    confidence_factors = {
        "score_differential": 0,
        "clear_winner": False,
        "supporting_evidence": 0,
        "contradictory_evidence": 0
    }
    
    if not maker or not checker:
        return "Very Low", confidence_factors
    
    # Get all candidates sorted by scores
    maker_candidates = sorted([(p, s["maker"]) for p, s in scores.items()], key=lambda x: x[1], reverse=True)
    checker_candidates = sorted([(p, s["checker"]) for p, s in scores.items()], key=lambda x: x[1], reverse=True)
    
    # Calculate score differentials
    if len(maker_candidates) > 1:
        score_diff_maker = (maker_candidates[0][1] - maker_candidates[1][1]) / max(maker_candidates[0][1], 1)
    else:
        score_diff_maker = 1.0  # Only one candidate
    
    if len(checker_candidates) > 1:
        score_diff_checker = (checker_candidates[0][1] - checker_candidates[1][1]) / max(checker_candidates[0][1], 1)
    else:
        score_diff_checker = 1.0  # Only one candidate
    
    confidence_factors["score_differential"] = (score_diff_maker + score_diff_checker) / 2
    confidence_factors["clear_winner"] = confidence_factors["score_differential"] > Config.CONFIDENCE_THRESHOLDS['high']
    
    # Determine confidence level
    if confidence_factors["clear_winner"] and confidence_factors["score_differential"] > Config.CONFIDENCE_THRESHOLDS['very_high']:
        return "Very High", confidence_factors
    elif confidence_factors["clear_winner"]:
        return "High", confidence_factors
    elif confidence_factors["score_differential"] > Config.CONFIDENCE_THRESHOLDS['medium']:
        return "Medium", confidence_factors
    else:
        return "Low", confidence_factors

# -----------------------------
# Enhanced Fallback Strategies
# -----------------------------
def apply_fallback_strategies(parsed_emails, initial_maker, initial_checker, scores):
    """Apply fallback strategies when primary identification is weak"""
    participants = extract_all_participants(parsed_emails)
    
    # Strategy 1: First-last rule
    if not initial_maker or not initial_checker:
        first_sender = clean_participant_name(parsed_emails[0].get("Sender", ""))
        last_sender = clean_participant_name(parsed_emails[-1].get("Sender", ""))
        
        if first_sender != last_sender:
            return first_sender, last_sender, "first_last_fallback"
    
    # Strategy 2: Most active participant as checker
    if not initial_checker:
        email_counts = {}
        for email in parsed_emails:
            sender = clean_participant_name(email.get("Sender", ""))
            email_counts[sender] = email_counts.get(sender, 0) + 1
        
        most_active = max(email_counts.items(), key=lambda x: x[1])[0] if email_counts else ""
        if most_active and most_active != initial_maker:
            return initial_maker, most_active, "activity_fallback"
    
    # Strategy 3: External participant as checker
    if len(participants) == 2:
        other_participant = [p for p in participants if p != initial_maker]
        if other_participant:
            return initial_maker, other_participant[0], "two_party_fallback"
    
    return initial_maker, initial_checker, "primary_method"

# -----------------------------
# Enhanced Email Parsing (FIXED)
# -----------------------------
def parse_email_chain(text):
    email_chunks = split_emails(text)
    parsed = []
    for i, email in enumerate(email_chunks):
        try:
            sender = extract_field(email, "From")
            receiver = extract_field(email, "To")
            cc = extract_field(email, "Cc")
            bcc = extract_field(email, "Bcc")
            subject = extract_field(email, "Subject")
            date_raw = extract_field(email, "Sent")
            dt = parse_date_time(date_raw)
            date_str = dt.date().isoformat() if dt else ""
            time_str = dt.time().isoformat() if dt else ""
            body = extract_body(email)
            
            # Ensure we always have these fields, even if empty
            approval_statement, approval_type = find_matching_statement(body, APPROVER_KEYWORDS.keys())
            request_statement, request_type = find_matching_statement(body, REQUESTER_KEYWORDS.keys())
            
            # Extract semantic patterns
            semantic_patterns = extract_semantic_patterns(body)
            
            parsed.append({
                "Email Sequence": i + 1,
                "Sender": sender,
                "Receiver": receiver,
                "cc": cc,
                "bcc": bcc,
                "subject": subject,
                "email body": body,
                "approval statement": approval_statement or "",  # Ensure it's never None
                "approval match type": approval_type or "",
                "request statement": request_statement or "",    # Ensure it's never None
                "request match type": request_type or "",
                "semantic_patterns": str(semantic_patterns),
                "datetime": dt,
                "date": date_str,
                "time": time_str
            })
        except Exception as e:
            log(f"⚠️ Error parsing email {i+1}: {str(e)}")
            continue
    
    # Sort by datetime
    parsed = sorted(parsed, key=lambda x: x["datetime"] if x["datetime"] else datetime.min)
    for i, email in enumerate(parsed):
        email["Email Sequence"] = i + 1
    
    return parsed

def extract_all_participants(parsed_emails):
    participants = set()
    for email in parsed_emails:
        sender = clean_participant_name(email.get("Sender", ""))
        if sender: participants.add(sender)
        
        receiver_field = email.get("Receiver", "")
        receivers = [clean_participant_name(r) for r in receiver_field.split(',')] if receiver_field else []
        participants.update([r for r in receivers if r])
        
        cc_field = email.get("cc", "")
        cc = [clean_participant_name(c) for c in cc_field.split(',')] if cc_field else []
        participants.update([c for c in cc if c])
        
        bcc_field = email.get("bcc", "")
        bcc = [clean_participant_name(b) for b in bcc_field.split(',')] if bcc_field else []
        participants.update([b for b in bcc if b])
    return sorted(participants)

# -----------------------------
# Enhanced Maker-Checker Identification with Restrictions
# -----------------------------
def identify_maker_checker_with_restrictions(parsed_emails):
    if not parsed_emails: 
        return "", "", {}, [], "Very Low", {}, {}, "", {}
    
    # Get participants with roles and restrictions
    participants_with_roles = extract_participants_with_roles(parsed_emails)
    restrictions = calculate_role_restrictions(participants_with_roles)
    
    # Use advanced scoring engine
    scoring_engine = AdvancedScoringEngine()
    scores = scoring_engine.calculate_comprehensive_scores(parsed_emails)
    
    # Apply restrictions and bonuses
    for participant in list(scores.keys()):  # Use list to avoid modification during iteration
        if participant in restrictions:
            # Apply CC/BCC restrictions
            if not restrictions[participant]["can_be_maker"]:
                scores[participant]["maker"] = 0
            if not restrictions[participant]["can_be_checker"]:
                scores[participant]["checker"] = 0
            
            # Apply bonuses
            if "maker_bonus" in restrictions[participant]:
                scores[participant]["maker"] += restrictions[participant]["maker_bonus"]
            if "checker_bonus" in restrictions[participant]:
                scores[participant]["checker"] += restrictions[participant]["checker_bonus"]
    
    # Find maker (requester) - highest maker score
    valid_maker_candidates = [(p, s["maker"]) for p, s in scores.items() 
                             if s["maker"] > 0 and (p in restrictions and restrictions[p]["can_be_maker"])]
    valid_checker_candidates = [(p, s["checker"]) for p, s in scores.items() 
                               if s["checker"] > 0 and (p in restrictions and restrictions[p]["can_be_checker"])]
    
    valid_maker_candidates.sort(key=lambda x: x[1], reverse=True)
    valid_checker_candidates.sort(key=lambda x: x[1], reverse=True)
    
    # Get initial identification
    initial_maker = valid_maker_candidates[0][0] if valid_maker_candidates else ""
    initial_checker = valid_checker_candidates[0][0] if valid_checker_candidates else ""
    
    # Apply fallback strategies if needed
    maker, checker, method_used = apply_fallback_strategies(parsed_emails, initial_maker, initial_checker, scores)
    
    # Calculate confidence
    confidence, confidence_factors = calculate_decision_confidence(maker, checker, scores, parsed_emails)
    
    # Get context analysis
    context = analyze_email_context(parsed_emails)
    
    return maker, checker, scores, valid_maker_candidates, confidence, confidence_factors, context, method_used, restrictions

# -----------------------------
# Sequential Analysis Functions (ADD THESE)
# -----------------------------
def analyze_email_sequentially(parsed_emails):
    """
    Analyze emails sequentially from oldest to newest, tracking potential makers/checkers
    """
    # Sort emails by date to ensure chronological processing
    sorted_emails = sorted(parsed_emails, key=lambda x: x["datetime"] if x["datetime"] else datetime.min)
    
    # Track potential makers and checkers throughout the conversation
    potential_makers = {}
    potential_checkers = {}
    conversation_history = []
    
    for i, email in enumerate(sorted_emails):
        email_analysis = analyze_single_email(email, conversation_history, i, len(sorted_emails))
        conversation_history.append(email_analysis)
        
        # Update potential makers and checkers based on this email
        update_potential_roles(email_analysis, potential_makers, potential_checkers)
    
    # Determine final roles with conflict resolution
    final_maker, final_checker, resolution_method = determine_final_roles(potential_makers, potential_checkers)
    
    return {
        "conversation_history": conversation_history,
        "potential_makers": potential_makers,
        "potential_checkers": potential_checkers,
        "final_maker": final_maker,
        "final_checker": final_checker,
        "resolution_method": resolution_method
    }

def analyze_single_email(email, previous_history, current_index, total_emails):
    """
    Analyze a single email against all rules
    """
    sender = clean_participant_name(email.get("Sender", ""))
    receiver_field = email.get("Receiver", "")
    receivers = [clean_participant_name(r.strip()) for r in receiver_field.split(';') if r.strip()]
    
    analysis = {
        "date": email.get("date", ""),
        "time": email.get("time", ""),
        "datetime": email.get("datetime"),
        "sender": sender,
        "receivers": receivers,
        "email_sequence": email.get("Email Sequence", 0),
        "can_be_maker": False,
        "can_be_checker": False,
        "maker_score": 0,
        "checker_score": 0,
        "role_restrictions": []
    }
    
    # Rule 1: Basic Role Restrictions
    role_analysis = analyze_role_restrictions_single(sender, receivers, email)
    analysis["role_restrictions"] = role_analysis["restrictions"]
    analysis["can_be_maker"] = role_analysis["can_be_maker"]
    analysis["can_be_checker"] = role_analysis["can_be_checker"]
    
    if analysis["can_be_maker"]:
        maker_score, maker_details = calculate_maker_score_single(email, previous_history, current_index, total_emails)
        analysis["maker_score"] = maker_score
        analysis["maker_keywords_found"] = maker_details.get("keywords_found", [])
        analysis["maker_semantic_patterns"] = maker_details.get("semantic_patterns", [])
    
    if analysis["can_be_checker"]:
        checker_score, checker_details = calculate_checker_score_single(email, previous_history, current_index, total_emails)
        analysis["checker_score"] = checker_score
        analysis["checker_keywords_found"] = checker_details.get("keywords_found", [])
        analysis["checker_semantic_patterns"] = checker_details.get("semantic_patterns", [])
    
    return analysis

def analyze_role_restrictions_single(sender, receivers, email):
    """
    Determine if sender can be maker/checker based on role restrictions for single email
    """
    restrictions = []
    can_be_maker = True
    can_be_checker = True
    
    # Check if sender is only in CC/BCC (not in To field)
    cc_field = email.get("cc", "")
    bcc_field = email.get("bcc", "")
    cc_list = [clean_participant_name(c.strip()) for c in cc_field.split(';')] if cc_field else []
    bcc_list = [clean_participant_name(b.strip()) for b in bcc_field.split(';')] if bcc_field else []
    
    # If sender is only in CC/BCC and not in receivers, restrict roles
    if sender in cc_list and sender not in receivers:
        restrictions.append("CC-only participant")
        can_be_maker = False
        can_be_checker = False
    
    if sender in bcc_list and sender not in receivers:
        restrictions.append("BCC-only participant") 
        can_be_maker = False
        can_be_checker = False
    
    return {
        "restrictions": restrictions,
        "can_be_maker": can_be_maker,
        "can_be_checker": can_be_checker
    }

def calculate_maker_score_single(email, previous_history, current_index, total_emails):
    """
    Calculate maker score for this specific email
    """
    score = 0
    email_body = email.get("email body", "").lower()
    keywords_found = []
    semantic_patterns_found = []
    
    # Rule 1: Request Keywords
    for keyword, weight in REQUESTER_KEYWORDS.items():
        if keyword in email_body:
            score += weight
            keywords_found.append(f"{keyword}({weight})")
    
    # Rule 2: Semantic Patterns for Requests
    semantic_patterns = extract_semantic_patterns(email_body)
    if "explicit_request" in semantic_patterns:
        score += 80
        semantic_patterns_found.append("explicit_request")
    if "conditional_request" in semantic_patterns:
        score += 60
        semantic_patterns_found.append("conditional_request")
    
    # Rule 3: Temporal Position (first email gets bonus)
    if current_index == 0:  # This is the first email
        score += 100
    
    # Rule 4: Conversation Flow - Initiator pattern
    if is_conversation_initiator(current_index):
        score += 50
    
    return score, {
        "keywords_found": keywords_found,
        "semantic_patterns": semantic_patterns_found
    }

def calculate_checker_score_single(email, previous_history, current_index, total_emails):
    """
    Calculate checker score for this specific email
    """
    score = 0
    email_body = email.get("email body", "").lower()
    keywords_found = []
    semantic_patterns_found = []
    
    # Rule 1: Approval Keywords
    for keyword, weight in APPROVER_KEYWORDS.items():
        if keyword in email_body:
            score += weight
            keywords_found.append(f"{keyword}({weight})")
    
    # Rule 2: Semantic Patterns for Approval
    semantic_patterns = extract_semantic_patterns(email_body)
    if "explicit_approval" in semantic_patterns:
        score += 80
        semantic_patterns_found.append("explicit_approval")
    if "conditional_approval" in semantic_patterns:
        score += 60
        semantic_patterns_found.append("conditional_approval")
    if "delegated_authority" in semantic_patterns:
        score += 40
        semantic_patterns_found.append("delegated_authority")
    
    # Rule 3: Temporal Position (last email gets bonus)
    if current_index == total_emails - 1:  # Last email
        score += 100
    
    # Rule 4: Response to Request
    if is_responding_to_request_single(email, previous_history):
        score += 70
    
    # Rule 5: Hierarchy Indicators
    hierarchy_score = analyze_hierarchy_indicators_single(email_body)
    score += hierarchy_score
    
    return score, {
        "keywords_found": keywords_found,
        "semantic_patterns": semantic_patterns_found
    }

def is_conversation_initiator(current_index):
    return current_index == 0

def is_responding_to_request_single(email, previous_history):
    """Check if this email is responding to a previous request"""
    if not previous_history:
        return False
    
    for prev_analysis in previous_history[-3:]:
        if prev_analysis.get("maker_score", 0) > 50:
            return True
    return False

def analyze_hierarchy_indicators_single(email_body):
    """Analyze hierarchy indicators in email body"""
    score = 0
    superior_indicators = [
        "please review", "for your approval", "seeking your guidance", 
        "your decision", "awaiting your input", "kindly approve",
        "request your approval", "need your authorization"
    ]
    
    for indicator in superior_indicators:
        if indicator in email_body.lower():
            score += 20
    
    return min(score, 100)

def update_potential_roles(email_analysis, potential_makers, potential_checkers):
    """Update potential roles based on current email analysis"""
    sender = email_analysis["sender"]
    
    # Update potential makers
    if email_analysis["can_be_maker"] and email_analysis["maker_score"] > 0:
        if sender not in potential_makers:
            potential_makers[sender] = {
                "total_score": 0,
                "email_count": 0,
                "highest_score": 0,
                "average_score": 0,
                "emails": []
            }
        
        potential_makers[sender]["total_score"] += email_analysis["maker_score"]
        potential_makers[sender]["email_count"] += 1
        potential_makers[sender]["highest_score"] = max(
            potential_makers[sender]["highest_score"], 
            email_analysis["maker_score"]
        )
        potential_makers[sender]["average_score"] = potential_makers[sender]["total_score"] / potential_makers[sender]["email_count"]
    
    # Update potential checkers
    if email_analysis["can_be_checker"] and email_analysis["checker_score"] > 0:
        if sender not in potential_checkers:
            potential_checkers[sender] = {
                "total_score": 0,
                "email_count": 0,
                "highest_score": 0,
                "average_score": 0,
                "emails": []
            }
        
        potential_checkers[sender]["total_score"] += email_analysis["checker_score"]
        potential_checkers[sender]["email_count"] += 1
        potential_checkers[sender]["highest_score"] = max(
            potential_checkers[sender]["highest_score"], 
            email_analysis["checker_score"]
        )
        potential_checkers[sender]["average_score"] = potential_checkers[sender]["total_score"] / potential_checkers[sender]["email_count"]

def determine_final_roles(potential_makers, potential_checkers):
    """
    Determine final roles with conflict resolution when same person is top candidate for both
    """
    # Get top candidates for each role
    top_maker = get_top_candidate(potential_makers, 30)
    top_checker = get_top_candidate(potential_checkers, 30)
    
    # If different people, return them
    if top_maker != top_checker:
        return top_maker, top_checker, "different_participants"
    
    # If same person is top for both roles, resolve conflict
    if top_maker and top_maker == top_checker:
        return resolve_role_conflict(potential_makers, potential_checkers, top_maker)
    
    # If no clear candidates
    return None, None, "no_clear_candidates"

def get_top_candidate(candidates_dict, min_threshold):
    """Get top candidate from a dictionary of candidates"""
    if not candidates_dict:
        return None
    
    best_candidate = None
    best_score = 0
    
    for participant, data in candidates_dict.items():
        avg_score = data["average_score"]
        if avg_score > best_score and avg_score > min_threshold:
            best_candidate = participant
            best_score = avg_score
    
    return best_candidate

def resolve_role_conflict(potential_makers, potential_checkers, conflicted_person):
    """
    Resolve when the same person is top candidate for both maker and checker
    Uses HIGHEST single score for conflict resolution
    """
    maker_data = potential_makers.get(conflicted_person, {})
    checker_data = potential_checkers.get(conflicted_person, {})
    
    # Use HIGHEST score (peak performance) for conflict resolution
    maker_highest = maker_data.get("highest_score", 0)
    checker_highest = checker_data.get("highest_score", 0)
    
    # Assign the role where the person has the higher peak score
    if maker_highest >= checker_highest:
        # Person becomes maker, find next best checker
        final_maker = conflicted_person
        final_checker = get_second_best_candidate_by_highest(potential_checkers, conflicted_person, 30)
        resolution_method = f"conflict_resolution_maker_highest_peak({maker_highest:.1f} vs {checker_highest:.1f})"
    else:
        # Person becomes checker, find next best maker
        final_checker = conflicted_person
        final_maker = get_second_best_candidate_by_highest(potential_makers, conflicted_person, 30)
        resolution_method = f"conflict_resolution_checker_highest_peak({checker_highest:.1f} vs {maker_highest:.1f})"
    
    return final_maker, final_checker, resolution_method

def get_second_best_candidate_by_highest(candidates_dict, exclude_person, min_threshold):
    """Get second best candidate based on HIGHEST score excluding a specific person"""
    if not candidates_dict:
        return None
    
    best_candidate = None
    best_score = 0
    
    for participant, data in candidates_dict.items():
        if participant == exclude_person:
            continue
            
        highest_score = data.get("highest_score", 0)
        if highest_score > best_score and highest_score > min_threshold:
            best_candidate = participant
            best_score = highest_score
    
    return best_candidate


# -----------------------------
# WebApp Endpoints (ADD THESE AT THE END)
# -----------------------------
import base64

def do(payload, config, plugin_config, inputs):
    """Main webapp endpoint"""
    return {"status": "ready"}

def do_analyze_emails(payload, config, plugin_config, inputs):
    """Endpoint to perform full analysis from uploaded file"""
    try:
        # Get the uploaded file data
        file_data = payload.get('file_data', '')
        file_name = payload.get('file_name', 'uploaded_file.txt')
        
        if not file_data:
            return {"error": "No file uploaded"}
        
        # Decode base64 file data
        if ',' in file_data:
            file_data = file_data.split(',')[1]
        
        file_content = base64.b64decode(file_data).decode('utf-8')
        
        # Clean and parse emails
        email_text = clean_email_addresses(file_content)
        parsed_emails = parse_email_chain(email_text)
        
        if not parsed_emails:
            return {"error": "No emails could be parsed from the uploaded file"}
        
        # Perform sequential analysis
        sequential_analysis = analyze_email_sequentially(parsed_emails)
        
        # Format results for web display
        results = format_results_for_web(sequential_analysis, parsed_emails)
        
        return {
            "success": True,
            "results": results,
            "file_name": file_name
        }
        
    except Exception as e:
        return {"error": f"Analysis failed: {str(e)}"}

def format_results_for_web(analysis, parsed_emails):
    """Format analysis results for web display"""
    return {
        "final_maker": analysis["final_maker"] or "Not identified",
        "final_checker": analysis["final_checker"] or "Not identified",
        "resolution_method": analysis.get("resolution_method", "standard"),
        "stats": {
            "total_emails": len(parsed_emails),
            "total_participants": len(extract_all_participants(parsed_emails)),
            "potential_makers_count": len(analysis["potential_makers"]),
            "potential_checkers_count": len(analysis["potential_checkers"])
        },
        "potential_makers": [
            {
                "participant": participant,
                "average_score": round(data["average_score"], 1),
                "highest_score": round(data["highest_score"], 1),
                "email_count": data["email_count"]
            }
            for participant, data in analysis["potential_makers"].items()
        ],
        "potential_checkers": [
            {
                "participant": participant,
                "average_score": round(data["average_score"], 1),
                "highest_score": round(data["highest_score"], 1),
                "email_count": data["email_count"]
            }
            for participant, data in analysis["potential_checkers"].items()
        ],
        "email_analysis": [
            {
                "sequence": email_analysis["email_sequence"],
                "sender": email_analysis["sender"],
                "date": email_analysis["date"],
                "time": email_analysis["time"],
                "maker_score": round(email_analysis["maker_score"], 1),
                "checker_score": round(email_analysis["checker_score"], 1),
                "can_be_maker": email_analysis["can_be_maker"],
                "can_be_checker": email_analysis["can_be_checker"],
                "receivers": ", ".join(email_analysis["receivers"])
            }
            for email_analysis in analysis["conversation_history"]
        ]
    }
