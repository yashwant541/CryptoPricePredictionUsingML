import re
import csv
import sys
import os
from datetime import datetime
from fuzzywuzzy import fuzz
import nltk
from nltk import word_tokenize, pos_tag

# Download once
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

def split_emails(raw_text):
    parts = re.split(r"(?=^From: )", raw_text, flags=re.IGNORECASE | re.MULTILINE)
    if not parts[0].strip().lower().startswith("from:"):
        first = parts.pop(0)
        parts = [first] + parts
    return parts

def extract_field(email, field):
    pattern = rf"{field}:(.*)"
    match = re.search(pattern, email, re.IGNORECASE)
    return match.group(1).strip() if match else ""

def parse_date_time(date_str):
    if not date_str:
        return "", ""
    try:
        dt = datetime.strptime(date_str.strip(), "%A, %B %d, %Y %I:%M %p")
        return dt.date().isoformat(), dt.time().isoformat()
    except:
        return date_str.strip(), ""

def extract_body(email):
    split_point = re.search(r"\n\s*\n", email)
    if split_point:
        return email[split_point.end():].strip()
    return ""

def find_matching_statement(email_body, keywords, threshold=80):
    sentences = re.split(r'(?<=[.!?])\s+', email_body.strip())
    exact_matches = []
    fuzzy_matches = []

    for sentence in sentences:
        clean_sentence = sentence.strip().lower()
        for kw in keywords:
            if kw in clean_sentence:
                exact_matches.append(sentence.strip())
            elif fuzz.partial_ratio(kw, clean_sentence) >= threshold:
                fuzzy_matches.append((sentence.strip(), kw, fuzz.partial_ratio(kw, clean_sentence)))

    if exact_matches:
        return "; ".join(exact_matches), "exact"
    elif fuzzy_matches:
        best_match = max(fuzzy_matches, key=lambda x: x[2])
        return best_match[0], "fuzzy"
    else:
        return "", ""

def parse_email_chain(text):
    email_chunks = split_emails(text)

    approval_keywords = [
        "approved", "looks good", "go ahead", "i'm fine", "agree", "sounds good",
        "please proceed", "okay", "ok", "fine with me", "noted", "approved by me"
    ]
    request_keywords = [
        "please review", "can you approve", "requesting", "need your approval",
        "could you review", "seeking approval", "for your review", "your input"
    ]

    parsed = []
    for i, email in enumerate(email_chunks):
        sender = extract_field(email, "From")
        receiver = extract_field(email, "To")
        cc = extract_field(email, "Cc")
        bcc = extract_field(email, "Bcc")
        subject = extract_field(email, "Subject")
        date_raw = extract_field(email, "Sent")

        date, time = parse_date_time(date_raw)
        body = extract_body(email)

        approval_statement, approval_type = find_matching_statement(body, approval_keywords)
        request_statement, request_type = find_matching_statement(body, request_keywords)

        parsed.append({
            "Email Sequence": i + 1,
            "Sender": sender,
            "Receiver": receiver,
            "cc": cc,
            "bcc": bcc,
            "subject": subject,
            "email body": body,
            "approval statement": approval_statement,
            "approval match type": approval_type,
            "request statement": request_statement,
            "request match type": request_type,
            "date": date,
            "time": time
        })

    return parsed

def save_to_csv(parsed_emails, output_file="parsed_emails.csv"):
    if not parsed_emails:
        print("‚ùå No emails found.")
        return

    fieldnames = parsed_emails[0].keys()
    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in parsed_emails:
            writer.writerow(row)
    print(f"‚úÖ CSV saved: {output_file}")

def save_summary(parsed_emails, summary_file="summary_output.txt"):
    with open(summary_file, "w", encoding="utf-8") as f:
        for email in parsed_emails:
            f.write(f"\n--- Email #{email['Email Sequence']} ---\n")
            f.write(f"From: {email['Sender']}\n")
            f.write(f"To: {email['Receiver']}\n")
            f.write(f"CC: {email['cc']}\n")
            f.write(f"Subject: {email['subject']}\n")
            f.write(f"Date: {email['date']} {email['time']}\n")
            f.write("Body:\n")
            f.write(email["email body"] + "\n")
    print(f"‚úÖ Summary saved: {summary_file}")

def analyze_statement_subject(statement):
    tokens = word_tokenize(statement)
    pos_tags = pos_tag(tokens)

    for i, (word, tag) in enumerate(pos_tags):
        word_lower = word.lower()
        if word_lower in {"approve", "agreed", "proceed"}:
            if i > 0 and pos_tags[i-1][0].lower() == "i":
                return "approver"
        elif word_lower in {"review", "approve", "look"}:
            if i > 1 and pos_tags[i-2][0].lower() in {"can", "could", "would"} and pos_tags[i-1][0].lower() == "you":
                return "requester"

    return None

def identify_requester_approver(parsed_emails):
    role_scores = {}

    for email in parsed_emails:
        body = email["email body"]
        sender = email["Sender"]
        sentences = re.split(r'(?<=[.!?])\s+', body.strip())

        for sentence in sentences:
            role = analyze_statement_subject(sentence)
            if role:
                role_scores.setdefault(sender, {"approver": 0, "requester": 0})
                role_scores[sender][role] += 1

    approver = max(role_scores.items(), key=lambda x: x[1].get("approver", 0))[0] if role_scores else ""
    requester = max(role_scores.items(), key=lambda x: x[1].get("requester", 0) if x[0] != approver else -1)[0] if role_scores else ""

    return requester, approver

def save_roles(requester, approver, output_file="requester_approver.txt"):
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"Requester: {requester}\n")
        f.write(f"Approver: {approver}\n")
    print(f"‚úÖ Roles saved: {output_file}")

def main():
    if len(sys.argv) != 2:
        print("Usage: python email_parser.py <email_chain.txt>")
        return

    filepath = sys.argv[1]
    if not os.path.exists(filepath):
        print(f"‚ùå File not found: {filepath}")
        return

    with open(filepath, "r", encoding="utf-8", errors="replace") as f:
        text = f.read()

    parsed_emails = parse_email_chain(text)

    requester, approver = identify_requester_approver(parsed_emails)

    print("\nüîç Identified Roles:")
    print(f"Requester: {requester}")
    print(f"Approver: {approver}")

    save_to_csv(parsed_emails)
    save_summary(parsed_emails)
    save_roles(requester, approver)

if __name__ == "__main__":
    main()
