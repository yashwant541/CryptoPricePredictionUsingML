import re
import csv
import sys
import os
from datetime import datetime
from fuzzywuzzy import fuzz
import nltk
from nltk import word_tokenize, pos_tag

# Download once
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

def split_emails(raw_text):
    parts = re.split(r"(?=^From: )", raw_text, flags=re.IGNORECASE | re.MULTILINE)
    if not parts[0].strip().lower().startswith("from:"):
        first = parts.pop(0)
        parts = [first] + parts
    return parts

def extract_field(email, field):
    pattern = rf"{field}:(.*)"
    match = re.search(pattern, email, re.IGNORECASE)
    return match.group(1).strip() if match else ""

def parse_date_time(date_str):
    if not date_str:
        return "", ""
    try:
        dt = datetime.strptime(date_str.strip(), "%A, %B %d, %Y %I:%M %p")
        return dt.date().isoformat(), dt.time().isoformat()
    except:
        return date_str.strip(), ""

def extract_body(email):
    split_point = re.search(r"\n\s*\n", email)
    if split_point:
        return email[split_point.end():].strip()
    return ""

def find_matching_statement(email_body, keywords, threshold=80):
    sentences = re.split(r'(?<=[.!?])\s+', email_body.strip())
    exact_matches = []
    fuzzy_matches = []

    for sentence in sentences:
        clean_sentence = sentence.strip().lower()
        for kw in keywords:
            if kw in clean_sentence:
                exact_matches.append(sentence.strip())
            elif fuzz.partial_ratio(kw, clean_sentence) >= threshold:
                fuzzy_matches.append((sentence.strip(), kw, fuzz.partial_ratio(kw, clean_sentence)))

    if exact_matches:
        return "; ".join(exact_matches), "exact"
    elif fuzzy_matches:
        best_match = max(fuzzy_matches, key=lambda x: x[2])
        return best_match[0], "fuzzy"
    else:
        return "", ""

# Enhanced keyword lists
APPROVER_KEYWORDS = [
    "approve", "approved", "approval", "grant", "granted", "authorize", 
    "authorized", "confirm", "confirmed", "accept", "accepted", "endorse", 
    "endorsed", "agree", "agreed", "looks good", "go ahead", "i'm fine", 
    "sounds good", "please proceed", "okay", "ok", "fine with me", "noted"
]

REQUESTER_KEYWORDS = [
    "request", "requested", "seek", "seeking", "require", "required", 
    "ask", "asked", "submit", "submitted", "apply", "applied", "petition",
    "please review", "can you approve", "need your approval", "could you review",
    "seeking approval", "for your review", "your input"
]

PRONOUN_PATTERNS = [
    (r"\byou\b.*\bapprove\b", "approver"),
    (r"\byour\b.*\bapproval\b", "approver"),
    (r"\bplease\b.*\bapprove\b", "approver"),
    (r"\bi\b.*\brequest\b", "requester"),
    (r"\bwe\b.*\brequest\b", "requester"),
    (r"\bplease\b.*\breview\b", "approver")
]

def parse_email_chain(text):
    email_chunks = split_emails(text)
    
    parsed = []
    for i, email in enumerate(email_chunks):
        sender = extract_field(email, "From")
        receiver = extract_field(email, "To")
        cc = extract_field(email, "Cc")
        bcc = extract_field(email, "Bcc")
        subject = extract_field(email, "Subject")
        date_raw = extract_field(email, "Sent")

        date, time = parse_date_time(date_raw)
        body = extract_body(email)

        approval_statement, approval_type = find_matching_statement(body, APPROVER_KEYWORDS)
        request_statement, request_type = find_matching_statement(body, REQUESTER_KEYWORDS)

        parsed.append({
            "Email Sequence": i + 1,
            "Sender": sender,
            "Receiver": receiver,
            "cc": cc,
            "bcc": bcc,
            "subject": subject,
            "email body": body,
            "approval statement": approval_statement,
            "approval match type": approval_type,
            "request statement": request_statement,
            "request match type": request_type,
            "date": date,
            "time": time
        })

    return parsed

def save_to_csv(parsed_emails, output_file="parsed_emails.csv"):
    if not parsed_emails:
        print("❌ No emails found.")
        return

    fieldnames = parsed_emails[0].keys()
    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in parsed_emails:
            writer.writerow(row)
    print(f"✅ CSV saved: {output_file}")

def save_summary(parsed_emails, summary_file="summary_output.txt"):
    with open(summary_file, "w", encoding="utf-8") as f:
        for email in parsed_emails:
            f.write(f"\n--- Email #{email['Email Sequence']} ---\n")
            f.write(f"From: {email['Sender']}\n")
            f.write(f"To: {email['Receiver']}\n")
            f.write(f"CC: {email['cc']}\n")
            f.write(f"Subject: {email['subject']}\n")
            f.write(f"Date: {email['date']} {email['time']}\n")
            f.write("Body:\n")
            f.write(email["email body"] + "\n")
    print(f"✅ Summary saved: {summary_file}")

def calculate_role_scores(parsed_emails):
    role_scores = {}
    total_emails = len(parsed_emails)
    
    for i, email in enumerate(parsed_emails):
        sender = email["Sender"]
        body = email["email body"].lower()
        subject = email["subject"].lower()
        
        if sender not in role_scores:
            role_scores[sender] = {"approver": 0, "requester": 0}
        
        # Temporal scoring (30%)
        position_score = (total_emails - i) / total_emails
        role_scores[sender]["approver"] += 30 * (1 - position_score)
        role_scores[sender]["requester"] += 30 * position_score
        
        # Keyword matching (25%)
        # Approver keywords
        for kw in APPROVER_KEYWORDS:
            if kw in body:
                role_scores[sender]["approver"] += 2
            elif fuzz.partial_ratio(kw, body) >= 80:
                role_scores[sender]["approver"] += 1
                
        # Requester keywords
        for kw in REQUESTER_KEYWORDS:
            if kw in body:
                role_scores[sender]["requester"] += 2
            elif fuzz.partial_ratio(kw, body) >= 80:
                role_scores[sender]["requester"] += 1
        
        # Pronoun analysis (20%)
        for pattern, role in PRONOUN_PATTERNS:
            if re.search(pattern, body, re.IGNORECASE):
                role_scores[sender][role] += 3
        
        # Structural analysis (15%)
        if any(title in body for title in ["manager", "director", "vp", "head of"]):
            role_scores[sender]["approver"] += 5
        
        # Attachment analysis (10%)
        if "request" in subject or "request" in body:
            role_scores[sender]["requester"] += 5
        if "approval" in subject or "approval" in body:
            role_scores[sender]["approver"] += 5
    
    return role_scores

def identify_requester_approver(parsed_emails):
    if not parsed_emails:
        return "", ""
    
    # Handle 2-email case directly
    if len(parsed_emails) == 2:
        try:
            date1 = datetime.strptime(parsed_emails[0]["date"], "%Y-%m-%d").date()
            date2 = datetime.strptime(parsed_emails[1]["date"], "%Y-%m-%d").date()
            
            if date1 < date2:
                return parsed_emails[0]["Sender"], parsed_emails[1]["Sender"]
            else:
                return parsed_emails[1]["Sender"], parsed_emails[0]["Sender"]
        except:
            # If date parsing fails, fall through to regular processing
            pass
    
    # For chains with more than 2 emails
    sender_timelines = {}
    for email in parsed_emails:
        sender = email["Sender"]
        try:
            email_date = datetime.strptime(email["date"], "%Y-%m-%d").date()
        except:
            continue
            
        if sender not in sender_timelines:
            sender_timelines[sender] = {
                "min_date": email_date,
                "max_date": email_date,
                "email_count": 1
            }
        else:
            if email_date < sender_timelines[sender]["min_date"]:
                sender_timelines[sender]["min_date"] = email_date
            if email_date > sender_timelines[sender]["max_date"]:
                sender_timelines[sender]["max_date"] = email_date
            sender_timelines[sender]["email_count"] += 1
    
    role_scores = calculate_role_scores(parsed_emails)
    
    if not role_scores:
        return "", ""
    
    # Get all possible approvers (those with emails before at least one other sender)
    possible_approvers = []
    for sender in role_scores.keys():
        if sender in sender_timelines:
            for other_sender, other_timeline in sender_timelines.items():
                if sender != other_sender and sender_timelines[sender]["max_date"] < other_timeline["min_date"]:
                    possible_approvers.append(sender)
                    break
    
    # Get all possible requesters (those with emails after at least one other sender)
    possible_requesters = []
    for sender in role_scores.keys():
        if sender in sender_timelines:
            for other_sender, other_timeline in sender_timelines.items():
                if sender != other_sender and sender_timelines[sender]["min_date"] > other_timeline["max_date"]:
                    possible_requesters.append(sender)
                    break
    
    # Select approver
    if possible_approvers:
        approver_candidates = {k:v for k,v in role_scores.items() if k in possible_approvers}
        approver = max(approver_candidates.items(), key=lambda x: x[1]["approver"])[0] if approver_candidates else ""
    else:
        approver = max(role_scores.items(), key=lambda x: x[1]["approver"])[0] if role_scores else ""
    
    # Select requester (excluding approver)
    requester_candidates = {k:v for k,v in role_scores.items() if k != approver}
    if possible_requesters:
        requester_candidates = {k:v for k,v in requester_candidates.items() if k in possible_requesters}
    
    requester = max(requester_candidates.items(), key=lambda x: x[1]["requester"])[0] if requester_candidates else ""
    
    # Final validation - requester's last email must be before approver's first email
    if requester and approver and requester in sender_timelines and approver in sender_timelines:
        if sender_timelines[requester]["max_date"] >= sender_timelines[approver]["min_date"]:
            # Find alternative requester that satisfies temporal constraint
            valid_requesters = {k:v for k,v in role_scores.items() 
                              if k != approver and 
                              k in sender_timelines and 
                              sender_timelines[k]["max_date"] < sender_timelines[approver]["min_date"]}
            if valid_requesters:
                requester = max(valid_requesters.items(), key=lambda x: x[1]["requester"])[0]
            else:
                requester = ""
    
    return requester, approver

def save_roles(requester, approver, output_file="requester_approver.txt"):
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(f"Requester: {requester}\n")
        f.write(f"Approver: {approver}\n")
    print(f"✅ Roles saved: {output_file}")

def save_analysis(parsed_emails, requester, approver, output_file="detailed_analysis.txt"):
    with open(output_file, "w", encoding="utf-8") as f:
        f.write("EMAIL CHAIN ANALYSIS REPORT\n")
        f.write("="*40 + "\n\n")
        
        # Basic chain info
        f.write(f"Total emails in chain: {len(parsed_emails)}\n")
        f.write(f"Identified Requester: {requester}\n")
        f.write(f"Identified Approver: {approver}\n\n")
        
        # Special case for 2-email chains
        if len(parsed_emails) == 2:
            f.write("ANALYSIS METHOD: 2-EMAIL SPECIAL CASE\n")
            f.write("-"*40 + "\n")
            try:
                date1 = datetime.strptime(parsed_emails[0]["date"], "%Y-%m-%d").date()
                date2 = datetime.strptime(parsed_emails[1]["date"], "%Y-%m-%d").date()
                
                if date1 < date2:
                    f.write(f"Email 1 ({date1}) is older than Email 2 ({date2})\n")
                    f.write(f"-> Sender of Email 1 ({parsed_emails[0]['Sender']}) designated as Requester\n")
                    f.write(f"-> Sender of Email 2 ({parsed_emails[1]['Sender']}) designated as Approver\n")
                else:
                    f.write(f"Email 2 ({date2}) is older than Email 1 ({date1})\n")
                    f.write(f"-> Sender of Email 2 ({parsed_emails[1]['Sender']}) designated as Requester\n")
                    f.write(f"-> Sender of Email 1 ({parsed_emails[0]['Sender']}) designated as Approver\n")
            except:
                f.write("Could not parse dates - fell back to standard scoring method\n\n")
        
        # For chains with more than 2 emails
        if len(parsed_emails) > 2:
            f.write("ANALYSIS METHOD: COMPREHENSIVE SCORING\n")
            f.write("-"*40 + "\n")
            
            # Calculate and show scores
            role_scores = calculate_role_scores(parsed_emails)
            sender_timelines = {}
            
            for email in parsed_emails:
                sender = email["Sender"]
                try:
                    email_date = datetime.strptime(email["date"], "%Y-%m-%d").date()
                    if sender not in sender_timelines:
                        sender_timelines[sender] = {
                            "min_date": email_date,
                            "max_date": email_date,
                            "email_count": 1
                        }
                    else:
                        if email_date < sender_timelines[sender]["min_date"]:
                            sender_timelines[sender]["min_date"] = email_date
                        if email_date > sender_timelines[sender]["max_date"]:
                            sender_timelines[sender]["max_date"] = email_date
                        sender_timelines[sender]["email_count"] += 1
                except:
                    continue
            
            # Show timeline info
            f.write("\nEMAIL TIMELINES:\n")
            for sender, timeline in sender_timelines.items():
                f.write(f"- {sender}: {timeline['email_count']} emails from {timeline['min_date']} to {timeline['max_date']}\n")
            
            # Show scores
            f.write("\nSCORE BREAKDOWN:\n")
            f.write("(Format: Sender: ApproverScore/RequesterScore)\n")
            for sender, scores in role_scores.items():
                f.write(f"- {sender}: {scores['approver']:.1f}/{scores['requester']:.1f}\n")
            
            # Show selection logic
            f.write("\nSELECTION PROCESS:\n")
            if requester and approver:
                f.write(f"1. Top Approver Candidate: {approver} (Score: {role_scores[approver]['approver']:.1f})\n")
                f.write(f"2. Top Requester Candidate (excluding approver): {requester} (Score: {role_scores[requester]['requester']:.1f})\n")
                
                # Temporal validation
                if sender_timelines and requester in sender_timelines and approver in sender_timelines:
                    if sender_timelines[requester]["max_date"] >= sender_timelines[approver]["min_date"]:
                        f.write("\nWARNING: Temporal constraint violated - requester's last email is not before approver's first email\n")
                        f.write(f"- Requester {requester}'s last email: {sender_timelines[requester]['max_date']}\n")
                        f.write(f"- Approver {approver}'s first email: {sender_timelines[approver]['min_date']}\n")
                        f.write("-> Falling back to alternative requester that satisfies temporal constraint\n")
            
            # Show key statements found
            f.write("\nKEY STATEMENTS IDENTIFIED:\n")
            for email in parsed_emails:
                f.write(f"\nEmail {email['Email Sequence']} from {email['Sender']}:\n")
                if email["approval_statement"]:
                    f.write(f"- Approval statement ({email['approval_match_type']}): {email['approval_statement']}\n")
                if email["request_statement"]:
                    f.write(f"- Request statement ({email['request_match_type']}): {email['request_statement']}\n")
        
        f.write("\nSCORING METHODOLOGY:\n")
        f.write("-"*40 + "\n")
        f.write("1. Temporal Analysis (30% weight)\n")
        f.write("   - Earlier emails contribute more to requester score\n")
        f.write("   - Later emails contribute more to approver score\n\n")
        f.write("2. Keyword Matching (25% weight)\n")
        f.write("   - Exact matches: +2 points\n")
        f.write("   - Fuzzy matches (80%+ similarity): +1 point\n\n")
        f.write("3. Pronoun Analysis (20% weight)\n")
        f.write("   - 'You' referring to approver: +1 per instance\n")
        f.write("   - 'I' suggesting request: +1 per instance\n")
        f.write("   - Phrases like 'your approval': +3 points\n\n")
        f.write("4. Structural Analysis (15% weight)\n")
        f.write("   - Job titles in signature: +5 for approver\n")
        f.write("   - Formal language: +3 for approver\n\n")
        f.write("5. Attachment Analysis (10% weight)\n")
        f.write("   - 'request' in filename: +5 for requester\n")
        f.write("   - 'approval' in filename: +5 for approver\n")
    
    print(f"✅ Detailed analysis saved: {output_file}")

# Update main() to call this new function
def main():
    if len(sys.argv) != 2:
        print("Usage: python email_parser.py <email_chain.txt>")
        return

    filepath = sys.argv[1]
    if not os.path.exists(filepath):
        print(f"❌ File not found: {filepath}")
        return

    with open(filepath, "r", encoding="utf-8", errors="replace") as f:
        text = f.read()

    parsed_emails = parse_email_chain(text)

    requester, approver = identify_requester_approver(parsed_emails)

    print("\n🔍 Identified Roles:")
    print(f"Requester: {requester}")
    print(f"Approver: {approver}")

    save_to_csv(parsed_emails)
    save_summary(parsed_emails)
    save_roles(requester, approver)
    save_analysis(parsed_emails, requester, approver)  # Add this line

if __name__ == "__main__":
    main()



def main():
    if len(sys.argv) != 2:
        print("Usage: python email_parser.py <email_chain.txt>")
        return

    filepath = sys.argv[1]
    if not os.path.exists(filepath):
        print(f"❌ File not found: {filepath}")
        return

    with open(filepath, "r", encoding="utf-8", errors="replace") as f:
        text = f.read()

    parsed_emails = parse_email_chain(text)

    requester, approver = identify_requester_approver(parsed_emails)

    print("\n🔍 Identified Roles:")
    print(f"Requester: {requester}")
    print(f"Approver: {approver}")

    save_to_csv(parsed_emails)
    save_summary(parsed_emails)
    save_roles(requester, approver)

if __name__ == "__main__":
    main()
